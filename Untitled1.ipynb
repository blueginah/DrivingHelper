{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d03d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57751f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0feeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72]\n",
      "102\n",
      "[74]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.7106\n",
      "Epoch: [1/120]Loss: 0.5217\n",
      "Epoch: [2/120]Loss: 0.3404\n",
      "Epoch: [3/120]Loss: 0.2022\n",
      "Epoch: [4/120]Loss: 0.1314\n",
      "Epoch: [5/120]Loss: 0.0835\n",
      "Epoch: [6/120]Loss: 0.0445\n",
      "Epoch: [7/120]Loss: 0.0215\n",
      "Epoch: [8/120]Loss: 0.0110\n",
      "Epoch: [9/120]Loss: 0.0046\n",
      "Epoch: [10/120]Loss: 0.0025\n",
      "Epoch: [11/120]Loss: 0.0017\n",
      "Epoch: [12/120]Loss: 0.0014\n",
      "Epoch: [13/120]Loss: 0.0012\n",
      "Epoch: [14/120]Loss: 0.0010\n",
      "Epoch: [15/120]Loss: 0.0009\n",
      "Epoch: [16/120]Loss: 0.0008\n",
      "Epoch: [17/120]Loss: 0.0007\n",
      "Epoch: [18/120]Loss: 0.0007\n",
      "Epoch: [19/120]Loss: 0.0006\n",
      "Epoch: [20/120]Loss: 0.0006\n",
      "Epoch: [21/120]Loss: 0.0005\n",
      "Epoch: [22/120]Loss: 0.0005\n",
      "Epoch: [23/120]Loss: 0.0004\n",
      "Epoch: [24/120]Loss: 0.0004\n",
      "Epoch: [25/120]Loss: 0.0004\n",
      "Epoch: [26/120]Loss: 0.0004\n",
      "Epoch: [27/120]Loss: 0.0003\n",
      "Epoch: [28/120]Loss: 0.0003\n",
      "Epoch: [29/120]Loss: 0.0003\n",
      "Epoch: [30/120]Loss: 0.0003\n",
      "Epoch: [31/120]Loss: 0.0003\n",
      "Epoch: [32/120]Loss: 0.0003\n",
      "Epoch: [33/120]Loss: 0.0003\n",
      "Epoch: [34/120]Loss: 0.0002\n",
      "Epoch: [35/120]Loss: 0.0002\n",
      "Epoch: [36/120]Loss: 0.0002\n",
      "Epoch: [37/120]Loss: 0.0002\n",
      "Epoch: [38/120]Loss: 0.0002\n",
      "Epoch: [39/120]Loss: 0.0002\n",
      "Epoch: [40/120]Loss: 0.0002\n",
      "Epoch: [41/120]Loss: 0.0002\n",
      "Epoch: [42/120]Loss: 0.0002\n",
      "Epoch: [43/120]Loss: 0.0002\n",
      "Epoch: [44/120]Loss: 0.0002\n",
      "Epoch: [45/120]Loss: 0.0002\n",
      "Epoch: [46/120]Loss: 0.0002\n",
      "Epoch: [47/120]Loss: 0.0001\n",
      "Epoch: [48/120]Loss: 0.0001\n",
      "Epoch: [49/120]Loss: 0.0001\n",
      "Epoch: [50/120]Loss: 0.0001\n",
      "Epoch: [51/120]Loss: 0.0001\n",
      "Epoch: [52/120]Loss: 0.0001\n",
      "Epoch: [53/120]Loss: 0.0001\n",
      "Epoch: [54/120]Loss: 0.0001\n",
      "Epoch: [55/120]Loss: 0.0001\n",
      "Epoch: [56/120]Loss: 0.0001\n",
      "Epoch: [57/120]Loss: 0.0001\n",
      "Epoch: [58/120]Loss: 0.0001\n",
      "Epoch: [59/120]Loss: 0.0001\n",
      "Epoch: [60/120]Loss: 0.0001\n",
      "Epoch: [61/120]Loss: 0.0001\n",
      "Epoch: [62/120]Loss: 0.0001\n",
      "Epoch: [63/120]Loss: 0.0001\n",
      "Epoch: [64/120]Loss: 0.0001\n",
      "Epoch: [65/120]Loss: 0.0001\n",
      "Epoch: [66/120]Loss: 0.0001\n",
      "Epoch: [67/120]Loss: 0.0001\n",
      "Epoch: [68/120]Loss: 0.0001\n",
      "Epoch: [69/120]Loss: 0.0001\n",
      "Epoch: [70/120]Loss: 0.0001\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0000\n",
      "Epoch: [93/120]Loss: 0.0000\n",
      "Epoch: [94/120]Loss: 0.0000\n",
      "Epoch: [95/120]Loss: 0.0000\n",
      "Epoch: [96/120]Loss: 0.0000\n",
      "Epoch: [97/120]Loss: 0.0000\n",
      "Epoch: [98/120]Loss: 0.0000\n",
      "Epoch: [99/120]Loss: 0.0000\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 92.85714285714286 %\n",
      "Loss: 0.0000\n",
      "51 <class 'numpy.int32'>\n",
      "[46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43]\n",
      "69\n",
      "[51]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.9101\n",
      "Epoch: [1/120]Loss: 0.6714\n",
      "Epoch: [2/120]Loss: 0.6128\n",
      "Epoch: [3/120]Loss: 0.5458\n",
      "Epoch: [4/120]Loss: 0.4661\n",
      "Epoch: [5/120]Loss: 0.3907\n",
      "Epoch: [6/120]Loss: 0.3172\n",
      "Epoch: [7/120]Loss: 0.2537\n",
      "Epoch: [8/120]Loss: 0.1958\n",
      "Epoch: [9/120]Loss: 0.1453\n",
      "Epoch: [10/120]Loss: 0.0960\n",
      "Epoch: [11/120]Loss: 0.0583\n",
      "Epoch: [12/120]Loss: 0.0327\n",
      "Epoch: [13/120]Loss: 0.0118\n",
      "Epoch: [14/120]Loss: 0.0119\n",
      "Epoch: [15/120]Loss: 0.0059\n",
      "Epoch: [16/120]Loss: 0.0041\n",
      "Epoch: [17/120]Loss: 0.0029\n",
      "Epoch: [18/120]Loss: 0.0024\n",
      "Epoch: [19/120]Loss: 0.0020\n",
      "Epoch: [20/120]Loss: 0.0017\n",
      "Epoch: [21/120]Loss: 0.0015\n",
      "Epoch: [22/120]Loss: 0.0014\n",
      "Epoch: [23/120]Loss: 0.0012\n",
      "Epoch: [24/120]Loss: 0.0011\n",
      "Epoch: [25/120]Loss: 0.0010\n",
      "Epoch: [26/120]Loss: 0.0009\n",
      "Epoch: [27/120]Loss: 0.0009\n",
      "Epoch: [28/120]Loss: 0.0008\n",
      "Epoch: [29/120]Loss: 0.0008\n",
      "Epoch: [30/120]Loss: 0.0007\n",
      "Epoch: [31/120]Loss: 0.0007\n",
      "Epoch: [32/120]Loss: 0.0006\n",
      "Epoch: [33/120]Loss: 0.0006\n",
      "Epoch: [34/120]Loss: 0.0006\n",
      "Epoch: [35/120]Loss: 0.0005\n",
      "Epoch: [36/120]Loss: 0.0005\n",
      "Epoch: [37/120]Loss: 0.0005\n",
      "Epoch: [38/120]Loss: 0.0005\n",
      "Epoch: [39/120]Loss: 0.0004\n",
      "Epoch: [40/120]Loss: 0.0004\n",
      "Epoch: [41/120]Loss: 0.0004\n",
      "Epoch: [42/120]Loss: 0.0004\n",
      "Epoch: [43/120]Loss: 0.0004\n",
      "Epoch: [44/120]Loss: 0.0004\n",
      "Epoch: [45/120]Loss: 0.0003\n",
      "Epoch: [46/120]Loss: 0.0003\n",
      "Epoch: [47/120]Loss: 0.0003\n",
      "Epoch: [48/120]Loss: 0.0003\n",
      "Epoch: [49/120]Loss: 0.0003\n",
      "Epoch: [50/120]Loss: 0.0003\n",
      "Epoch: [51/120]Loss: 0.0003\n",
      "Epoch: [52/120]Loss: 0.0003\n",
      "Epoch: [53/120]Loss: 0.0003\n",
      "Epoch: [54/120]Loss: 0.0003\n",
      "Epoch: [55/120]Loss: 0.0002\n",
      "Epoch: [56/120]Loss: 0.0002\n",
      "Epoch: [57/120]Loss: 0.0002\n",
      "Epoch: [58/120]Loss: 0.0002\n",
      "Epoch: [59/120]Loss: 0.0002\n",
      "Epoch: [60/120]Loss: 0.0002\n",
      "Epoch: [61/120]Loss: 0.0002\n",
      "Epoch: [62/120]Loss: 0.0002\n",
      "Epoch: [63/120]Loss: 0.0002\n",
      "Epoch: [64/120]Loss: 0.0002\n",
      "Epoch: [65/120]Loss: 0.0002\n",
      "Epoch: [66/120]Loss: 0.0002\n",
      "Epoch: [67/120]Loss: 0.0002\n",
      "Epoch: [68/120]Loss: 0.0002\n",
      "Epoch: [69/120]Loss: 0.0002\n",
      "Epoch: [70/120]Loss: 0.0002\n",
      "Epoch: [71/120]Loss: 0.0002\n",
      "Epoch: [72/120]Loss: 0.0002\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0001\n",
      "Epoch: [101/120]Loss: 0.0001\n",
      "Epoch: [102/120]Loss: 0.0001\n",
      "Epoch: [103/120]Loss: 0.0001\n",
      "Epoch: [104/120]Loss: 0.0001\n",
      "Epoch: [105/120]Loss: 0.0001\n",
      "Epoch: [106/120]Loss: 0.0001\n",
      "Epoch: [107/120]Loss: 0.0001\n",
      "Epoch: [108/120]Loss: 0.0001\n",
      "Epoch: [109/120]Loss: 0.0001\n",
      "Epoch: [110/120]Loss: 0.0001\n",
      "Epoch: [111/120]Loss: 0.0001\n",
      "Epoch: [112/120]Loss: 0.0001\n",
      "Epoch: [113/120]Loss: 0.0001\n",
      "Epoch: [114/120]Loss: 0.0001\n",
      "Epoch: [115/120]Loss: 0.0001\n",
      "Epoch: [116/120]Loss: 0.0001\n",
      "Epoch: [117/120]Loss: 0.0001\n",
      "Epoch: [118/120]Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [119/120]Loss: 0.0001\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0001\n",
      "112 <class 'numpy.int32'>\n",
      "[492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76]\n",
      "833\n",
      "[112]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.7939\n",
      "Epoch: [1/120]Loss: 0.3830\n",
      "Epoch: [2/120]Loss: 0.2126\n",
      "Epoch: [3/120]Loss: 0.1682\n",
      "Epoch: [4/120]Loss: 0.1503\n",
      "Epoch: [5/120]Loss: 0.1483\n",
      "Epoch: [6/120]Loss: 0.1562\n",
      "Epoch: [7/120]Loss: 0.1449\n",
      "Epoch: [8/120]Loss: 0.1694\n",
      "Epoch: [9/120]Loss: 0.1709\n",
      "Epoch: [10/120]Loss: 0.1458\n",
      "Epoch: [11/120]Loss: 0.1442\n",
      "Epoch: [12/120]Loss: 0.1452\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-14f7af2cbcd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;31m# Backward and optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;31m#         optimizer.zero_grad()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ssdkms\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ssdkms\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_list = [0,1,2,3,4,5,0]\n",
    "number_of_corner_list = [1,2,3,4,5,6,6]\n",
    "d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "feature_list = [0, 1]\n",
    "for i in range(2):\n",
    "    feature = feature_list[i]\n",
    "    for i in range(7):\n",
    "        start = start_list[i]\n",
    "        number_of_corner = number_of_corner_list[i]\n",
    "        df_begin = []\n",
    "        num_row = []\n",
    "        num_row_corner = []\n",
    "        percent = []\n",
    "    #     start = 0\n",
    "    #     number_of_corner = 1\n",
    "        f_1 = 'beginner_expert_processedData/beginner/beginner_'\n",
    "        f_3 = '.csv'\n",
    "        num_begin = 19\n",
    "        curveList = [[103.9, 209.3], [316.6, 399.6], [425.3, 517.9], [590.5, 756.9], [1048.7, 1110.5], [1212.3, 1437.1]]\n",
    "\n",
    "        df_concat = pd.DataFrame()\n",
    "\n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "        #     print(num_row)\n",
    "            for idx in range(1, num_begin+1):\n",
    "                tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "                df = pd.read_csv(tmp_file)\n",
    "                df = df.dropna()\n",
    "\n",
    "                tmp = df.astype(float)\n",
    "                tmp['level'] =0\n",
    "                tmp['curve_number'] = curve_num\n",
    "                tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "\n",
    "\n",
    "                num_row.append(np.size(tmpcorner,0)) \n",
    "                num_row_corner.append(np.size(tmpcorner,0)) \n",
    "                df_begin.append(tmpcorner)\n",
    "                df_concat = pd.concat([df_concat,df_begin[idx-1]])      \n",
    "\n",
    "            df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_begin'+'.csv')\n",
    "            df_concat = pd.DataFrame()\n",
    "            df_begin = []\n",
    "\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "        df_exp = []\n",
    "        f_1 = 'beginner_expert_processedData/expert/expert_'\n",
    "        f_3 = '.csv'\n",
    "        num_exp = 19\n",
    "\n",
    "        df_concat = pd.DataFrame()\n",
    "\n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "            for idx in range(1, num_exp+1):\n",
    "                tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "                df = pd.read_csv(tmp_file)\n",
    "                df = df.dropna()\n",
    "\n",
    "                tmp = df.astype(float)\n",
    "                tmp['level'] =1\n",
    "                tmp['curve_number'] = curve_num\n",
    "\n",
    "                tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "                num_row.append(np.size(tmpcorner,0))\n",
    "                num_row_corner.append(np.size(tmpcorner,0)) \n",
    "\n",
    "                df_exp.append(tmpcorner)\n",
    "                df_concat = pd.concat([df_concat,df_exp[idx-1]])\n",
    "            df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_expert'+'.csv')\n",
    "            df_concat = pd.DataFrame()\n",
    "            df_exp = []\n",
    "            num_row_corner = np.array(num_row_corner)\n",
    "            per = np.percentile(num_row_corner, 70).astype('int')\n",
    "        #     np.ndarray.tolist(per)\n",
    "            print(per,type(per))\n",
    "            percent.append(per)\n",
    "            num_row_corner = []\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "\n",
    "        print(num_row)\n",
    "        sequence_length = max(num_row)\n",
    "        print(sequence_length)\n",
    "        mean_row = round(np.mean(num_row))\n",
    "        mean_row = min(num_row)\n",
    "        print(percent)\n",
    "\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "        if feature == 0:\n",
    "            left_column = [\n",
    "            #'Time',\n",
    "            #     'Distance',\n",
    "            #     'Session Time Left',\n",
    "            #     'Corr Dist','Corr Dist (Unstretched)',\n",
    "                'GPS Latitude','GPS Longitude',\n",
    "                'CG Distance',\n",
    "                'Damper Velocity (Calc) FL','Damper Velocity (Calc) FR','Damper Velocity (Calc) RL',\n",
    "            'Damper Velocity (Calc) RR','Corr Speed','Brake Pos',\n",
    "            'CG Accel Lateral','CG Accel Longitudinal','CG Accel Vertical','CG Height','Camber FL','Camber FR','Camber RL','Camber RR','Car Coord X',\n",
    "            'Car Coord Y','Car Coord Z','Car Pos Norm','Chassis Pitch Angle','Chassis Pitch Rate','Chassis Roll Angle','Chassis Roll Rate',\n",
    "            'Chassis Velocity X','Chassis Velocity Y','Chassis Velocity Z','Chassis Yaw Rate','Drive Train Speed','Engine RPM','Ground Speed',\n",
    "            'Ride Height FL','Ride Height FR','Ride Height RL','Ride Height RR','Road Temp','Self Align Torque FL','Self Align Torque FR',\n",
    "            'Self Align Torque RL','Self Align Torque RR','Steering Angle','Suspension Travel FL','Suspension Travel FR',\n",
    "            'Suspension Travel RL','Suspension Travel RR','Tire Load FL','Tire Load FR','Tire Load RL','Tire Load RR','Tire Loaded Radius FL',\n",
    "            'Tire Loaded Radius FR','Tire Loaded Radius RL','Tire Loaded Radius RR','Tire Pressure FL','Tire Pressure FR','Tire Pressure RL','Tire Pressure RR',\n",
    "            'Tire Rubber Grip FL','Tire Rubber Grip FR','Tire Rubber Grip RL','Tire Rubber Grip RR','Tire Slip Angle FL','Tire Slip Angle FR',\n",
    "            'Tire Slip Angle RL','Tire Slip Angle RR','Tire Slip Ratio FL','Tire Slip Ratio FR','Tire Slip Ratio RL','Tire Slip Ratio RR',\n",
    "            'Tire Temp Core FL','Tire Temp Core FR','Tire Temp Core RL','Tire Temp Core RR','Tire Temp Inner FL','Tire Temp Inner FR',\n",
    "            'Tire Temp Inner RL','Tire Temp Inner RR','Tire Temp Middle FL','Tire Temp Middle FR','Tire Temp Middle RL',\n",
    "            'Tire Temp Middle RR','Tire Temp Outer FL','Tire Temp Outer FR','Tire Temp Outer RL','Tire Temp Outer RR','Toe In FL',\n",
    "            'Toe In FR','Toe In RL','Toe In RR','Wheel Angular Speed FL','Wheel Angular Speed FR','Wheel Angular Speed RL','Wheel Angular Speed RR',\n",
    "            'Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration','level']\n",
    "\n",
    "        else:\n",
    "            left_column = ['Brake Pos', 'Ground Speed', 'Steering Angle', 'Throttle Pos', 'Chassis Yaw Rate', 'Chassis Velocity X',\n",
    "                               'Chassis Velocity Y','Chassis Velocity Z','Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration',\n",
    "                               'CG Distance',\n",
    "                           'level']\n",
    "\n",
    "        #Hyper-parameters\n",
    "        num_epochs = 120\n",
    "        batches = 1\n",
    "        learning_rate = 0.001\n",
    "        input_size = len(left_column)-1 # left column except 'level'\n",
    "        output_size = 2 # Expert and Beginner\n",
    "        hidden_size = 62 # ?\n",
    "        num_layers = 2\n",
    "        num_begin_train = round(num_begin*0.65)*(number_of_corner-start)\n",
    "        num_exp_train = round(num_exp*0.65)*(number_of_corner-start)\n",
    "        num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "        num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "\n",
    "        print(num_begin_train, num_exp_train,num_begin_test,num_exp_test)\n",
    "        aug = 1\n",
    "        ## Define GRU, Loss func and Optimizer\n",
    "        class GRU(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "                super(GRU, self).__init__()\n",
    "                self.num_layers = num_layers\n",
    "                self.hidden_size = hidden_size\n",
    "    #             self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "                self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "                self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            def forward(self, x):\n",
    "                h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "                c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "                out, _ = self.gru(x, h0)\n",
    "    #             out, _ = self.lstm(x, (h0,c0)) \n",
    "                out = out[:, -1, :]\n",
    "                out = self.fc(out)\n",
    "                return out\n",
    "\n",
    "        gru = GRU(input_size, hidden_size, num_layers, output_size)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)  \n",
    "\n",
    "        # gru.fc.weight.data.fill_(1)\n",
    "        # gru.fc.bias.data.fill_(1)\n",
    "    #     print(gru.fc.weight,gru.fc.bias)\n",
    "\n",
    "        ## Data Processing\n",
    "        array_x = []\n",
    "        array_y = []\n",
    "        input_x = []\n",
    "        input_y = []\n",
    "        n_row = []\n",
    "\n",
    "        df_tmp_begin = pd.DataFrame() \n",
    "        df_tmp_exp = pd.DataFrame() \n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "            df_tmp_begin = pd.concat([df_tmp_begin,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_begin.csv')])\n",
    "            df_tmp_exp   = pd.concat([df_tmp_exp,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_expert.csv')])    \n",
    "        df_curve1 = pd.concat([df_tmp_begin, df_tmp_exp], ignore_index=True) \n",
    "        df_curve1 = df_curve1.loc[:,left_column]\n",
    "        df_curve1_saved = df_curve1.loc[:,left_column] # data backup\n",
    "        df_curve1.to_csv('cornerData/corner_'+'_dfcurve1'+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "        datum = df_curve1_saved\n",
    "        yyy = datum.pop('level')\n",
    "        left = left_column.remove('level')\n",
    "        for i in range(0,num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "        #     x = df_curve1_saved.loc[0:num_row[i]-1\n",
    "            y = yyy.loc[0:num_row[i]-1]\n",
    "        #     y = y.iloc[0]\n",
    "            x_original = datum.loc[0:num_row[i]-1]\n",
    "\n",
    "        #     print(x_original)\n",
    "        #     print(num_row[i],y[0],x_original.iloc[-1,0])\n",
    "\n",
    "        #     scaler = StandardScaler()\n",
    "            scaler = MinMaxScaler()\n",
    "        #     scaler.fit(x_original)\n",
    "        #     scaler.mean_\n",
    "            x_normal = scaler.fit_transform(x_original)\n",
    "            x_normal = scaler.transform(x_original)\n",
    "\n",
    "\n",
    "            x_normal = np.pad(x_normal,[(0,sequence_length-num_row[i]),(0,0)]) #post padding\n",
    "        #     x_normal = np.pad(x_normal,[(sequence_length-num_row[i],0),(0,0)]) #pre padding\n",
    "\n",
    "\n",
    "            x = pd.DataFrame(x_normal,columns=left)\n",
    "            p = i//(num_begin*2)\n",
    "            x = x.truncate(after=percent[p]-1)\n",
    "        #     print(x.shape)\n",
    "        #     print(datum)\n",
    "        #     print(i)\n",
    "        #     print(num_row)\n",
    "        #     print(num_row[i])\n",
    "            datum.drop(range(0,num_row[i]),inplace=True)\n",
    "            datum.reset_index(drop=True, inplace=True)\n",
    "            yyy.drop(range(0,num_row[i]),inplace=True)\n",
    "            yyy.reset_index(drop=True, inplace=True)\n",
    "            # y = x.pop('level')\n",
    "\n",
    "        #     # DATA Augmentation\n",
    "        #     nan = pd.DataFrame(np.nan,columns=range(x.shape[1]),index=range(x.shape[0]))\n",
    "        #     alter = pd.concat([x,nan]).sort_index()\n",
    "        #     alter = alter.interpolate()\n",
    "        #     alter.reset_index(drop=True, inplace=True)\n",
    "        #     x_aug = alter[alter.index%2==1]\n",
    "\n",
    "\n",
    "            array_x.append(x)\n",
    "        #     array_x.append(x_aug)\n",
    "            array_y.append(y)\n",
    "        #     array_y.append(y)\n",
    "\n",
    "\n",
    "        ## Randomize sequence \n",
    "        # sequence = np.arange((num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug/2)\n",
    "        seq_train_begin = np.arange(num_begin_train)\n",
    "        seq_test_begin = np.arange(num_begin_test) + num_begin_train\n",
    "        seq_train_exp = seq_train_begin + num_begin*(number_of_corner-start)\n",
    "        seq_test_exp = seq_test_begin + num_begin*(number_of_corner-start)\n",
    "        print(seq_train_begin,seq_train_exp)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_train_begin)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_test_begin)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_train_exp)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_test_exp)\n",
    "        # seq_train2 = seq_test\n",
    "\n",
    "\n",
    "        sequence = np.concatenate((seq_train_begin, seq_train_exp, seq_test_begin, seq_test_exp), axis=None)\n",
    "        sequence = sequence.astype('int')\n",
    "        # sequence = [0,1,2,15,4,5,6,7,8,9,18,11,12,13,14,19,20,21,34,23,24,25,26,27,28,37,30,31,32,33,3,16,17,10,22,35,36,29]\n",
    "        print(sequence)\n",
    "\n",
    "        # # Data Augmentation\n",
    "        # num_row = pd.Series(num_row)\n",
    "        # num_row = num_row.repeat(2)\n",
    "        # # sequence = pd.Series(sequence)\n",
    "        # # sequence = sequence.repeat(2)\n",
    "        # num_row.reset_index(drop=True, inplace=True)\n",
    "        # # sequence.reset_index(drop=True, inplace=True)\n",
    "        # print(num_row, sequence)\n",
    "\n",
    "        # for i in range(len(percent)):\n",
    "        #     n_row = n_row + [percent[i]]*num_begin*2\n",
    "        for i in sequence:\n",
    "            input_x.append(array_x[i])\n",
    "            input_y.append(array_y[i])\n",
    "            p = i//(num_begin*2)\n",
    "        #     print(p)\n",
    "            n_row = n_row + [percent[p]]\n",
    "\n",
    "\n",
    "        #     n_row.append(num_row[i])\n",
    "        #     n_row.append(sequence_length)\n",
    "        #     n_row.append(mean_row+1-20)\n",
    "        # input_x = np.array(input_x)\n",
    "        # input_y = np.array(input_y)\n",
    "        print(n_row)\n",
    "\n",
    "        ## Train \n",
    "        loss_list = []\n",
    "        iteration_list = []\n",
    "        accuracy_list = []\n",
    "        test_list=[]\n",
    "        count = 0\n",
    "        # torch.backends.cudnn.benchmark = True\n",
    "        print((num_begin_train + num_exp_train)*aug)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0,(num_begin_train + num_exp_train)*aug):\n",
    "\n",
    "        #         print(i)\n",
    "        #         print(len(input_x))\n",
    "                # array type (numpy) ì•ž\n",
    "                X = np.array(input_x[i])\n",
    "        #         print(X.shape)\n",
    "        #         X = input_x[i]\n",
    "                X = X.reshape(-1,n_row[i],input_size)\n",
    "\n",
    "                Y = np.array(input_y[i])\n",
    "\n",
    "        #         Y = input_y[i]\n",
    "        #         print(X,X.shape,Y[0])\n",
    "        #         time.sleep(300)\n",
    "                # tensor type (pytorch)\n",
    "                X = torch.from_numpy(X)\n",
    "                X = X.float()\n",
    "                Y = torch.tensor([Y[0]])\n",
    "        #         Y = torch.tensor([Y])\n",
    "                Y = Y.type(torch.LongTensor)\n",
    "        #         Y = Y.float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = gru(X)\n",
    "                loss = criterion(output, Y)\n",
    "\n",
    "                # Backward and optimize\n",
    "        #         optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            print (f'Epoch: [{epoch}/{num_epochs}]' f'Loss: {loss.item():.4f}')\n",
    "        ## Test\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_samples = 0\n",
    "\n",
    "            for i in range((num_begin_train + num_exp_train)*aug, (num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug):\n",
    "\n",
    "                # array type (numpy)\n",
    "                X = np.array(input_x[i])\n",
    "        #         X = input_x[i]\n",
    "                X = X.reshape(-1,n_row[i],input_size)\n",
    "                Y = np.array(input_y[i])\n",
    "        #         Y = input_y[i]\n",
    "\n",
    "                # tensor type (pytorch)\n",
    "                X = torch.from_numpy(X)\n",
    "                X = X.float()\n",
    "                Y = torch.tensor([Y[0]])\n",
    "        #         Y = torch.tensor(Y)\n",
    "                Y = Y.type(torch.LongTensor)\n",
    "        #         Y = Y.float()\n",
    "                output = gru(X)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                n_samples += Y.size(0)\n",
    "                n_correct += (predicted == Y).sum().item()\n",
    "                print(Y, predicted)\n",
    "\n",
    "\n",
    "\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "        #     print(f'Accuracy of the network on the {(num_begin_test + num_exp_test)*aug} test images: {acc} %')\n",
    "\n",
    "        plt.plot(iteration_list,loss_list)\n",
    "        plt.xlabel(\"Number of iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "    #     plt.show()\n",
    "        if feature == 0:\n",
    "            plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_allFeat.png')\n",
    "        else:\n",
    "            plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_selectedFeat.png')\n",
    "        print(f'Accuracy of the network on the {num_begin_test + num_exp_test} test images: {acc} %')\n",
    "        print(f'Loss: {loss.item():.4f}')\n",
    "\n",
    "        d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df2 = df2.append(df)\n",
    "\n",
    "    if feature == 0:\n",
    "        df2.to_csv('cornerData/result_gru_allFeature.csv')\n",
    "    else:\n",
    "        df2.to_csv('cornerData/result_gru_selectedFeature.csv')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9dae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2.to_csv('cornerData/result_gru.csv')\n",
    "# d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "# df2 = pd.DataFrame(data=d2)\n",
    "d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df2 = df2.append(df+4)\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
