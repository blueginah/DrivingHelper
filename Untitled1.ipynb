{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00175dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6151f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ed86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72]\n",
      "102\n",
      "[74]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[-0.0147,  0.0770,  0.0459,  0.0786,  0.1026,  0.0781, -0.0600,  0.0066,\n",
      "          0.1171, -0.0171,  0.0488, -0.0520,  0.0249,  0.0589, -0.0431,  0.0936,\n",
      "          0.1125,  0.0478, -0.0877,  0.0740,  0.0924,  0.0980,  0.0883, -0.0290,\n",
      "         -0.0768,  0.1117, -0.0493, -0.0261, -0.0456, -0.0028, -0.0409,  0.0948,\n",
      "          0.0538, -0.1265, -0.0123, -0.0859, -0.0261, -0.0732, -0.1101, -0.1176,\n",
      "         -0.1103, -0.1060,  0.0555, -0.0563,  0.0734,  0.1229,  0.1054,  0.0777,\n",
      "          0.1261, -0.0751, -0.0638,  0.1031,  0.0423, -0.1160, -0.0407,  0.0664,\n",
      "         -0.0696, -0.1063,  0.1071, -0.0978, -0.0629,  0.0149],\n",
      "        [ 0.0208, -0.0201, -0.0561,  0.0078, -0.0173, -0.1073,  0.0903,  0.0480,\n",
      "         -0.0693,  0.1010, -0.0788,  0.0385,  0.0787, -0.0502, -0.0823, -0.0368,\n",
      "          0.1236,  0.0017, -0.0093, -0.0473, -0.1120, -0.0841, -0.0908, -0.0014,\n",
      "         -0.0723, -0.0045,  0.0633, -0.0875,  0.0509,  0.0926,  0.0892,  0.0251,\n",
      "          0.0541, -0.0853, -0.0792,  0.0742,  0.1213, -0.0526,  0.0973, -0.0236,\n",
      "         -0.1077,  0.0647,  0.0662,  0.0126, -0.1085,  0.0244, -0.1215,  0.1267,\n",
      "          0.0292,  0.1140,  0.1122, -0.0155,  0.0210,  0.0454, -0.1180,  0.0478,\n",
      "         -0.0086, -0.0161, -0.0571,  0.0117, -0.0713, -0.0525]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0580, -0.0700], requires_grad=True)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.7827\n",
      "Epoch: [1/100]Loss: 0.6567\n",
      "Epoch: [2/100]Loss: 0.4904\n",
      "Epoch: [3/100]Loss: 0.2852\n",
      "Epoch: [4/100]Loss: 0.1484\n",
      "Epoch: [5/100]Loss: 0.1065\n",
      "Epoch: [6/100]Loss: 0.0835\n",
      "Epoch: [7/100]Loss: 0.0642\n",
      "Epoch: [8/100]Loss: 0.0403\n",
      "Epoch: [9/100]Loss: 0.0209\n",
      "Epoch: [10/100]Loss: 0.0095\n",
      "Epoch: [11/100]Loss: 0.0044\n",
      "Epoch: [12/100]Loss: 0.0029\n",
      "Epoch: [13/100]Loss: 0.0131\n",
      "Epoch: [14/100]Loss: 0.0090\n",
      "Epoch: [15/100]Loss: 0.0059\n",
      "Epoch: [16/100]Loss: 0.0043\n",
      "Epoch: [17/100]Loss: 0.0033\n",
      "Epoch: [18/100]Loss: 0.0026\n",
      "Epoch: [19/100]Loss: 0.0022\n",
      "Epoch: [20/100]Loss: 0.0019\n",
      "Epoch: [21/100]Loss: 0.0016\n",
      "Epoch: [22/100]Loss: 0.0014\n",
      "Epoch: [23/100]Loss: 0.0013\n",
      "Epoch: [24/100]Loss: 0.0011\n",
      "Epoch: [25/100]Loss: 0.0010\n",
      "Epoch: [26/100]Loss: 0.0009\n",
      "Epoch: [27/100]Loss: 0.0009\n",
      "Epoch: [28/100]Loss: 0.0008\n",
      "Epoch: [29/100]Loss: 0.0007\n",
      "Epoch: [30/100]Loss: 0.0007\n",
      "Epoch: [31/100]Loss: 0.0006\n",
      "Epoch: [32/100]Loss: 0.0006\n",
      "Epoch: [33/100]Loss: 0.0006\n",
      "Epoch: [34/100]Loss: 0.0005\n",
      "Epoch: [35/100]Loss: 0.0005\n",
      "Epoch: [36/100]Loss: 0.0005\n",
      "Epoch: [37/100]Loss: 0.0004\n",
      "Epoch: [38/100]Loss: 0.0004\n",
      "Epoch: [39/100]Loss: 0.0004\n",
      "Epoch: [40/100]Loss: 0.0004\n",
      "Epoch: [41/100]Loss: 0.0004\n",
      "Epoch: [42/100]Loss: 0.0003\n",
      "Epoch: [43/100]Loss: 0.0003\n",
      "Epoch: [44/100]Loss: 0.0003\n",
      "Epoch: [45/100]Loss: 0.0003\n",
      "Epoch: [46/100]Loss: 0.0003\n",
      "Epoch: [47/100]Loss: 0.0003\n",
      "Epoch: [48/100]Loss: 0.0003\n",
      "Epoch: [49/100]Loss: 0.0003\n",
      "Epoch: [50/100]Loss: 0.0002\n",
      "Epoch: [51/100]Loss: 0.0002\n",
      "Epoch: [52/100]Loss: 0.0002\n",
      "Epoch: [53/100]Loss: 0.0002\n",
      "Epoch: [54/100]Loss: 0.0002\n",
      "Epoch: [55/100]Loss: 0.0002\n",
      "Epoch: [56/100]Loss: 0.0002\n",
      "Epoch: [57/100]Loss: 0.0002\n",
      "Epoch: [58/100]Loss: 0.0002\n",
      "Epoch: [59/100]Loss: 0.0002\n",
      "Epoch: [60/100]Loss: 0.0002\n",
      "Epoch: [61/100]Loss: 0.0002\n",
      "Epoch: [62/100]Loss: 0.0002\n",
      "Epoch: [63/100]Loss: 0.0002\n",
      "Epoch: [64/100]Loss: 0.0002\n",
      "Epoch: [65/100]Loss: 0.0001\n",
      "Epoch: [66/100]Loss: 0.0001\n",
      "Epoch: [67/100]Loss: 0.0001\n",
      "Epoch: [68/100]Loss: 0.0001\n",
      "Epoch: [69/100]Loss: 0.0001\n",
      "Epoch: [70/100]Loss: 0.0001\n",
      "Epoch: [71/100]Loss: 0.0001\n",
      "Epoch: [72/100]Loss: 0.0001\n",
      "Epoch: [73/100]Loss: 0.0001\n",
      "Epoch: [74/100]Loss: 0.0001\n",
      "Epoch: [75/100]Loss: 0.0001\n",
      "Epoch: [76/100]Loss: 0.0001\n",
      "Epoch: [77/100]Loss: 0.0001\n",
      "Epoch: [78/100]Loss: 0.0001\n",
      "Epoch: [79/100]Loss: 0.0001\n",
      "Epoch: [80/100]Loss: 0.0001\n",
      "Epoch: [81/100]Loss: 0.0001\n",
      "Epoch: [82/100]Loss: 0.0001\n",
      "Epoch: [83/100]Loss: 0.0001\n",
      "Epoch: [84/100]Loss: 0.0001\n",
      "Epoch: [85/100]Loss: 0.0001\n",
      "Epoch: [86/100]Loss: 0.0001\n",
      "Epoch: [87/100]Loss: 0.0001\n",
      "Epoch: [88/100]Loss: 0.0001\n",
      "Epoch: [89/100]Loss: 0.0001\n",
      "Epoch: [90/100]Loss: 0.0001\n",
      "Epoch: [91/100]Loss: 0.0001\n",
      "Epoch: [92/100]Loss: 0.0001\n",
      "Epoch: [93/100]Loss: 0.0001\n",
      "Epoch: [94/100]Loss: 0.0001\n",
      "Epoch: [95/100]Loss: 0.0001\n",
      "Epoch: [96/100]Loss: 0.0001\n",
      "Epoch: [97/100]Loss: 0.0001\n",
      "Epoch: [98/100]Loss: 0.0001\n",
      "Epoch: [99/100]Loss: 0.0001\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0001\n",
      "51 <class 'numpy.int32'>\n",
      "[46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43]\n",
      "69\n",
      "[51]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[-0.0834,  0.0693, -0.0361, -0.0541, -0.1253,  0.1013, -0.1094,  0.0546,\n",
      "         -0.0040,  0.0620,  0.0791,  0.0614,  0.0114, -0.0730, -0.0609, -0.0897,\n",
      "          0.1044,  0.0487, -0.0680, -0.0598, -0.1183, -0.0433,  0.1022, -0.0066,\n",
      "         -0.1076, -0.0021, -0.0577,  0.1058,  0.1176, -0.0376, -0.0677, -0.0936,\n",
      "          0.0207,  0.0738, -0.0437,  0.0622, -0.0837,  0.0205, -0.0089,  0.0943,\n",
      "          0.0756,  0.0470, -0.0458, -0.0088,  0.0562, -0.0395,  0.0385, -0.0802,\n",
      "         -0.0036, -0.0141, -0.0294,  0.0474,  0.0349, -0.0781,  0.0148,  0.0156,\n",
      "         -0.0478, -0.1117,  0.0363,  0.0793,  0.0222, -0.1261],\n",
      "        [-0.0316, -0.0197, -0.0525,  0.0360, -0.0100, -0.0375, -0.0379,  0.0715,\n",
      "         -0.0607,  0.0533, -0.0132, -0.0941, -0.0006,  0.0605,  0.0081, -0.1174,\n",
      "          0.0837,  0.0380,  0.0364,  0.0248, -0.1035, -0.0621, -0.0063, -0.1112,\n",
      "          0.1036, -0.1034,  0.1077,  0.0515,  0.0518,  0.0838,  0.1027,  0.1198,\n",
      "         -0.1180, -0.0585, -0.0524, -0.0290, -0.0249,  0.0591, -0.0541,  0.0941,\n",
      "         -0.0730, -0.0818,  0.0922, -0.0164, -0.0320, -0.1035, -0.0388, -0.0565,\n",
      "         -0.0060, -0.0709, -0.0566,  0.0479, -0.0209,  0.0147,  0.1006,  0.1105,\n",
      "         -0.0882,  0.0619, -0.0235,  0.1246, -0.0321, -0.0377]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([ 0.1155, -0.0197], requires_grad=True)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.9383\n",
      "Epoch: [1/100]Loss: 0.8103\n",
      "Epoch: [2/100]Loss: 0.7708\n",
      "Epoch: [3/100]Loss: 0.7238\n",
      "Epoch: [4/100]Loss: 0.6457\n",
      "Epoch: [5/100]Loss: 0.5378\n",
      "Epoch: [6/100]Loss: 0.4114\n",
      "Epoch: [7/100]Loss: 0.3007\n",
      "Epoch: [8/100]Loss: 0.1867\n",
      "Epoch: [9/100]Loss: 0.1125\n",
      "Epoch: [10/100]Loss: 0.0373\n",
      "Epoch: [11/100]Loss: 0.0388\n",
      "Epoch: [12/100]Loss: 0.0132\n",
      "Epoch: [13/100]Loss: 0.0061\n",
      "Epoch: [14/100]Loss: 0.0035\n",
      "Epoch: [15/100]Loss: 0.0036\n",
      "Epoch: [16/100]Loss: 0.0015\n",
      "Epoch: [17/100]Loss: 0.0009\n",
      "Epoch: [18/100]Loss: 0.0007\n",
      "Epoch: [19/100]Loss: 0.0006\n",
      "Epoch: [20/100]Loss: 0.0006\n",
      "Epoch: [21/100]Loss: 0.0005\n",
      "Epoch: [22/100]Loss: 0.0005\n",
      "Epoch: [23/100]Loss: 0.0005\n",
      "Epoch: [24/100]Loss: 0.0005\n",
      "Epoch: [25/100]Loss: 0.0004\n",
      "Epoch: [26/100]Loss: 0.0004\n",
      "Epoch: [27/100]Loss: 0.0004\n",
      "Epoch: [28/100]Loss: 0.0004\n",
      "Epoch: [29/100]Loss: 0.0004\n",
      "Epoch: [30/100]Loss: 0.0003\n",
      "Epoch: [31/100]Loss: 0.0003\n",
      "Epoch: [32/100]Loss: 0.0003\n",
      "Epoch: [33/100]Loss: 0.0003\n",
      "Epoch: [34/100]Loss: 0.0003\n",
      "Epoch: [35/100]Loss: 0.0003\n",
      "Epoch: [36/100]Loss: 0.0003\n",
      "Epoch: [37/100]Loss: 0.0003\n",
      "Epoch: [38/100]Loss: 0.0002\n",
      "Epoch: [39/100]Loss: 0.0002\n",
      "Epoch: [40/100]Loss: 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41/100]Loss: 0.0002\n",
      "Epoch: [42/100]Loss: 0.0002\n",
      "Epoch: [43/100]Loss: 0.0002\n",
      "Epoch: [44/100]Loss: 0.0002\n",
      "Epoch: [45/100]Loss: 0.0002\n",
      "Epoch: [46/100]Loss: 0.0002\n",
      "Epoch: [47/100]Loss: 0.0002\n",
      "Epoch: [48/100]Loss: 0.0002\n",
      "Epoch: [49/100]Loss: 0.0002\n",
      "Epoch: [50/100]Loss: 0.0002\n",
      "Epoch: [51/100]Loss: 0.0002\n",
      "Epoch: [52/100]Loss: 0.0002\n",
      "Epoch: [53/100]Loss: 0.0002\n",
      "Epoch: [54/100]Loss: 0.0002\n",
      "Epoch: [55/100]Loss: 0.0001\n",
      "Epoch: [56/100]Loss: 0.0001\n",
      "Epoch: [57/100]Loss: 0.0001\n",
      "Epoch: [58/100]Loss: 0.0001\n",
      "Epoch: [59/100]Loss: 0.0001\n",
      "Epoch: [60/100]Loss: 0.0001\n",
      "Epoch: [61/100]Loss: 0.0001\n",
      "Epoch: [62/100]Loss: 0.0001\n",
      "Epoch: [63/100]Loss: 0.0001\n",
      "Epoch: [64/100]Loss: 0.0001\n",
      "Epoch: [65/100]Loss: 0.0001\n",
      "Epoch: [66/100]Loss: 0.0001\n",
      "Epoch: [67/100]Loss: 0.0001\n",
      "Epoch: [68/100]Loss: 0.0001\n",
      "Epoch: [69/100]Loss: 0.0001\n",
      "Epoch: [70/100]Loss: 0.0001\n",
      "Epoch: [71/100]Loss: 0.0001\n",
      "Epoch: [72/100]Loss: 0.0001\n",
      "Epoch: [73/100]Loss: 0.0001\n",
      "Epoch: [74/100]Loss: 0.0001\n",
      "Epoch: [75/100]Loss: 0.0001\n",
      "Epoch: [76/100]Loss: 0.0001\n",
      "Epoch: [77/100]Loss: 0.0001\n",
      "Epoch: [78/100]Loss: 0.0001\n",
      "Epoch: [79/100]Loss: 0.0001\n",
      "Epoch: [80/100]Loss: 0.0001\n",
      "Epoch: [81/100]Loss: 0.0001\n",
      "Epoch: [82/100]Loss: 0.0001\n",
      "Epoch: [83/100]Loss: 0.0001\n",
      "Epoch: [84/100]Loss: 0.0001\n",
      "Epoch: [85/100]Loss: 0.0001\n",
      "Epoch: [86/100]Loss: 0.0001\n",
      "Epoch: [87/100]Loss: 0.0001\n",
      "Epoch: [88/100]Loss: 0.0001\n",
      "Epoch: [89/100]Loss: 0.0001\n",
      "Epoch: [90/100]Loss: 0.0001\n",
      "Epoch: [91/100]Loss: 0.0001\n",
      "Epoch: [92/100]Loss: 0.0001\n",
      "Epoch: [93/100]Loss: 0.0001\n",
      "Epoch: [94/100]Loss: 0.0001\n",
      "Epoch: [95/100]Loss: 0.0001\n",
      "Epoch: [96/100]Loss: 0.0001\n",
      "Epoch: [97/100]Loss: 0.0001\n",
      "Epoch: [98/100]Loss: 0.0001\n",
      "Epoch: [99/100]Loss: 0.0001\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 92.85714285714286 %\n",
      "Loss: 0.0001\n",
      "112 <class 'numpy.int32'>\n",
      "[492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76]\n",
      "833\n",
      "[112]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[-0.0688,  0.0581, -0.1154, -0.0043,  0.0966, -0.0466,  0.1173,  0.0716,\n",
      "         -0.1264, -0.0507, -0.1109,  0.0156,  0.0728,  0.0609,  0.0764,  0.0002,\n",
      "          0.0299,  0.0913,  0.0392, -0.0129,  0.0644, -0.0637,  0.0708,  0.0036,\n",
      "          0.0016, -0.1088,  0.0882,  0.0541, -0.0776,  0.0515,  0.1137,  0.0530,\n",
      "          0.0977,  0.0579,  0.0186, -0.1259, -0.0310, -0.0095,  0.0779, -0.1078,\n",
      "          0.0775, -0.0111, -0.0126, -0.0688,  0.1225, -0.0080, -0.0977,  0.1051,\n",
      "         -0.0868,  0.0454,  0.0344,  0.0701,  0.0272,  0.0580,  0.0590, -0.0897,\n",
      "          0.0134,  0.0477,  0.0259,  0.0870, -0.1123,  0.0065],\n",
      "        [ 0.1118,  0.0426,  0.0013, -0.0883,  0.0621, -0.0801,  0.1214,  0.1214,\n",
      "          0.0824, -0.1166, -0.1181, -0.0064,  0.0352,  0.0693,  0.1260,  0.0060,\n",
      "         -0.0881,  0.0162,  0.0042, -0.0546, -0.0356, -0.0743,  0.0700, -0.0553,\n",
      "          0.0302,  0.0720, -0.0662, -0.0987, -0.0058,  0.0711,  0.0798, -0.1158,\n",
      "         -0.1133, -0.1027,  0.0239,  0.0382, -0.0499, -0.0101,  0.0930, -0.1225,\n",
      "         -0.0347,  0.1003,  0.0784, -0.1236, -0.0141, -0.0453, -0.0057, -0.0472,\n",
      "         -0.0729,  0.0207, -0.0678, -0.0281, -0.0279, -0.0360, -0.0450, -0.0003,\n",
      "         -0.0189, -0.0947,  0.0711, -0.0245, -0.1048, -0.0622]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0212,  0.0132], requires_grad=True)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.7167\n",
      "Epoch: [1/100]Loss: 0.5295\n",
      "Epoch: [2/100]Loss: 0.4019\n",
      "Epoch: [3/100]Loss: 0.3356\n",
      "Epoch: [4/100]Loss: 0.2661\n",
      "Epoch: [5/100]Loss: 0.2245\n",
      "Epoch: [6/100]Loss: 0.2025\n",
      "Epoch: [7/100]Loss: 0.1837\n",
      "Epoch: [8/100]Loss: 0.1679\n",
      "Epoch: [9/100]Loss: 0.1598\n",
      "Epoch: [10/100]Loss: 0.1559\n",
      "Epoch: [11/100]Loss: 0.1540\n",
      "Epoch: [12/100]Loss: 0.1530\n",
      "Epoch: [13/100]Loss: 0.1526\n",
      "Epoch: [14/100]Loss: 0.1525\n",
      "Epoch: [15/100]Loss: 0.1525\n",
      "Epoch: [16/100]Loss: 0.1525\n",
      "Epoch: [17/100]Loss: 0.1524\n",
      "Epoch: [18/100]Loss: 0.1523\n",
      "Epoch: [19/100]Loss: 0.1522\n",
      "Epoch: [20/100]Loss: 0.1354\n",
      "Epoch: [21/100]Loss: 0.1399\n",
      "Epoch: [22/100]Loss: 0.1490\n",
      "Epoch: [23/100]Loss: 0.1523\n",
      "Epoch: [24/100]Loss: 0.1535\n",
      "Epoch: [25/100]Loss: 0.1539\n",
      "Epoch: [26/100]Loss: 0.1542\n",
      "Epoch: [27/100]Loss: 0.1542\n",
      "Epoch: [28/100]Loss: 0.1520\n",
      "Epoch: [29/100]Loss: 0.1372\n",
      "Epoch: [30/100]Loss: 0.1231\n",
      "Epoch: [31/100]Loss: 0.1296\n",
      "Epoch: [32/100]Loss: 0.1403\n",
      "Epoch: [33/100]Loss: 0.1468\n",
      "Epoch: [34/100]Loss: 0.1503\n",
      "Epoch: [35/100]Loss: 0.1520\n",
      "Epoch: [36/100]Loss: 0.1526\n",
      "Epoch: [37/100]Loss: 0.1523\n",
      "Epoch: [38/100]Loss: 0.1509\n",
      "Epoch: [39/100]Loss: 0.1475\n",
      "Epoch: [40/100]Loss: 0.1440\n",
      "Epoch: [41/100]Loss: 0.1367\n",
      "Epoch: [42/100]Loss: 0.1331\n",
      "Epoch: [43/100]Loss: 0.1208\n",
      "Epoch: [44/100]Loss: 0.1101\n",
      "Epoch: [45/100]Loss: 0.0956\n",
      "Epoch: [46/100]Loss: 0.0829\n",
      "Epoch: [47/100]Loss: 0.1091\n",
      "Epoch: [48/100]Loss: 0.0827\n",
      "Epoch: [49/100]Loss: 0.0697\n",
      "Epoch: [50/100]Loss: 0.0558\n",
      "Epoch: [51/100]Loss: 0.0365\n",
      "Epoch: [52/100]Loss: 0.0237\n",
      "Epoch: [53/100]Loss: 0.0268\n",
      "Epoch: [54/100]Loss: 0.0369\n",
      "Epoch: [55/100]Loss: 0.0257\n",
      "Epoch: [56/100]Loss: 0.0222\n",
      "Epoch: [57/100]Loss: 0.0174\n",
      "Epoch: [58/100]Loss: 0.0122\n",
      "Epoch: [59/100]Loss: 0.0103\n",
      "Epoch: [60/100]Loss: 0.0133\n",
      "Epoch: [61/100]Loss: 0.0104\n",
      "Epoch: [62/100]Loss: 0.0088\n",
      "Epoch: [63/100]Loss: 0.0066\n",
      "Epoch: [64/100]Loss: 0.0053\n",
      "Epoch: [65/100]Loss: 0.0042\n",
      "Epoch: [66/100]Loss: 0.0034\n",
      "Epoch: [67/100]Loss: 0.0028\n",
      "Epoch: [68/100]Loss: 0.0024\n",
      "Epoch: [69/100]Loss: 0.0021\n",
      "Epoch: [70/100]Loss: 0.0019\n",
      "Epoch: [71/100]Loss: 0.0018\n",
      "Epoch: [72/100]Loss: 0.0016\n",
      "Epoch: [73/100]Loss: 0.0015\n",
      "Epoch: [74/100]Loss: 0.0014\n",
      "Epoch: [75/100]Loss: 0.0013\n",
      "Epoch: [76/100]Loss: 0.0013\n",
      "Epoch: [77/100]Loss: 0.0012\n",
      "Epoch: [78/100]Loss: 0.0011\n",
      "Epoch: [79/100]Loss: 0.0011\n",
      "Epoch: [80/100]Loss: 0.0010\n",
      "Epoch: [81/100]Loss: 0.0010\n",
      "Epoch: [82/100]Loss: 0.0009\n",
      "Epoch: [83/100]Loss: 0.0009\n",
      "Epoch: [84/100]Loss: 0.0009\n",
      "Epoch: [85/100]Loss: 0.0008\n",
      "Epoch: [86/100]Loss: 0.0008\n",
      "Epoch: [87/100]Loss: 0.0008\n",
      "Epoch: [88/100]Loss: 0.0007\n",
      "Epoch: [89/100]Loss: 0.0007\n",
      "Epoch: [90/100]Loss: 0.0007\n",
      "Epoch: [91/100]Loss: 0.0007\n",
      "Epoch: [92/100]Loss: 0.0006\n",
      "Epoch: [93/100]Loss: 0.0006\n",
      "Epoch: [94/100]Loss: 0.0006\n",
      "Epoch: [95/100]Loss: 0.0006\n",
      "Epoch: [96/100]Loss: 0.0006\n",
      "Epoch: [97/100]Loss: 0.0005\n",
      "Epoch: [98/100]Loss: 0.0005\n",
      "Epoch: [99/100]Loss: 0.0005\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0005\n",
      "98 <class 'numpy.int32'>\n",
      "[111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84]\n",
      "140\n",
      "[98]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[ 0.0481, -0.1156,  0.0256,  0.0597, -0.0463, -0.1238,  0.0211, -0.0911,\n",
      "         -0.0193,  0.0452,  0.1009,  0.0834,  0.0376, -0.0240, -0.1131,  0.0499,\n",
      "         -0.1137, -0.0471, -0.0883, -0.0713,  0.0787,  0.0022, -0.0506, -0.0322,\n",
      "         -0.0845,  0.0182, -0.0237,  0.0810,  0.1007, -0.0963, -0.0987, -0.0401,\n",
      "         -0.1024,  0.0165, -0.1015, -0.0559,  0.0312, -0.0576,  0.0097, -0.0701,\n",
      "          0.0138,  0.0396,  0.1061, -0.0449, -0.0518, -0.1255, -0.0703, -0.0594,\n",
      "          0.0958, -0.0988,  0.0737, -0.0383,  0.0280, -0.0322,  0.1017,  0.0317,\n",
      "         -0.0072, -0.0938, -0.0082,  0.0231,  0.0265, -0.0344],\n",
      "        [-0.0935,  0.1234,  0.1134,  0.0915, -0.0434,  0.0105,  0.0142, -0.0822,\n",
      "          0.0299,  0.1248, -0.0341,  0.0906, -0.0323,  0.0960,  0.0139,  0.0841,\n",
      "          0.0539, -0.0951,  0.0842,  0.0863, -0.0631, -0.0961, -0.1126,  0.0947,\n",
      "          0.1032, -0.1005, -0.0330, -0.0655, -0.0457, -0.0029,  0.0725,  0.0983,\n",
      "         -0.0599, -0.0281,  0.0186,  0.1248, -0.0849, -0.1214, -0.0255,  0.1157,\n",
      "          0.0013, -0.1108, -0.0656,  0.0748,  0.0365, -0.1044, -0.0458, -0.0040,\n",
      "          0.0236, -0.1245,  0.0692, -0.1051, -0.0345,  0.0665,  0.0872, -0.0853,\n",
      "          0.0665,  0.1204,  0.0111,  0.0574,  0.1049,  0.0404]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0185,  0.0268], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.6788\n",
      "Epoch: [1/100]Loss: 0.5031\n",
      "Epoch: [2/100]Loss: 0.2202\n",
      "Epoch: [3/100]Loss: 0.0540\n",
      "Epoch: [4/100]Loss: 0.0210\n",
      "Epoch: [5/100]Loss: 0.0101\n",
      "Epoch: [6/100]Loss: 0.0060\n",
      "Epoch: [7/100]Loss: 0.0045\n",
      "Epoch: [8/100]Loss: 0.0036\n",
      "Epoch: [9/100]Loss: 0.0030\n",
      "Epoch: [10/100]Loss: 0.0026\n",
      "Epoch: [11/100]Loss: 0.0022\n",
      "Epoch: [12/100]Loss: 0.0019\n",
      "Epoch: [13/100]Loss: 0.0017\n",
      "Epoch: [14/100]Loss: 0.0015\n",
      "Epoch: [15/100]Loss: 0.0014\n",
      "Epoch: [16/100]Loss: 0.0014\n",
      "Epoch: [17/100]Loss: 0.0013\n",
      "Epoch: [18/100]Loss: 0.0011\n",
      "Epoch: [19/100]Loss: 0.0009\n",
      "Epoch: [20/100]Loss: 0.0007\n",
      "Epoch: [21/100]Loss: 0.0006\n",
      "Epoch: [22/100]Loss: 0.0006\n",
      "Epoch: [23/100]Loss: 0.0005\n",
      "Epoch: [24/100]Loss: 0.0005\n",
      "Epoch: [25/100]Loss: 0.0004\n",
      "Epoch: [26/100]Loss: 0.0040\n",
      "Epoch: [27/100]Loss: 0.0086\n",
      "Epoch: [28/100]Loss: 0.0055\n",
      "Epoch: [29/100]Loss: 0.0037\n",
      "Epoch: [30/100]Loss: 0.0028\n",
      "Epoch: [31/100]Loss: 0.0024\n",
      "Epoch: [32/100]Loss: 0.0022\n",
      "Epoch: [33/100]Loss: 0.0019\n",
      "Epoch: [34/100]Loss: 0.0017\n",
      "Epoch: [35/100]Loss: 0.0016\n",
      "Epoch: [36/100]Loss: 0.0015\n",
      "Epoch: [37/100]Loss: 0.0013\n",
      "Epoch: [38/100]Loss: 0.0012\n",
      "Epoch: [39/100]Loss: 0.0012\n",
      "Epoch: [40/100]Loss: 0.0011\n",
      "Epoch: [41/100]Loss: 0.0010\n",
      "Epoch: [42/100]Loss: 0.0009\n",
      "Epoch: [43/100]Loss: 0.0009\n",
      "Epoch: [44/100]Loss: 0.0008\n",
      "Epoch: [45/100]Loss: 0.0008\n",
      "Epoch: [46/100]Loss: 0.0007\n",
      "Epoch: [47/100]Loss: 0.0007\n",
      "Epoch: [48/100]Loss: 0.0007\n",
      "Epoch: [49/100]Loss: 0.0006\n",
      "Epoch: [50/100]Loss: 0.0006\n",
      "Epoch: [51/100]Loss: 0.0006\n",
      "Epoch: [52/100]Loss: 0.0006\n",
      "Epoch: [53/100]Loss: 0.0005\n",
      "Epoch: [54/100]Loss: 0.0005\n",
      "Epoch: [55/100]Loss: 0.0005\n",
      "Epoch: [56/100]Loss: 0.0005\n",
      "Epoch: [57/100]Loss: 0.0004\n",
      "Epoch: [58/100]Loss: 0.0004\n",
      "Epoch: [59/100]Loss: 0.0004\n",
      "Epoch: [60/100]Loss: 0.0004\n",
      "Epoch: [61/100]Loss: 0.0004\n",
      "Epoch: [62/100]Loss: 0.0004\n",
      "Epoch: [63/100]Loss: 0.0004\n",
      "Epoch: [64/100]Loss: 0.0003\n",
      "Epoch: [65/100]Loss: 0.0003\n",
      "Epoch: [66/100]Loss: 0.0003\n",
      "Epoch: [67/100]Loss: 0.0003\n",
      "Epoch: [68/100]Loss: 0.0003\n",
      "Epoch: [69/100]Loss: 0.0003\n",
      "Epoch: [70/100]Loss: 0.0003\n",
      "Epoch: [71/100]Loss: 0.0003\n",
      "Epoch: [72/100]Loss: 0.0003\n",
      "Epoch: [73/100]Loss: 0.0003\n",
      "Epoch: [74/100]Loss: 0.0002\n",
      "Epoch: [75/100]Loss: 0.0002\n",
      "Epoch: [76/100]Loss: 0.0002\n",
      "Epoch: [77/100]Loss: 0.0002\n",
      "Epoch: [78/100]Loss: 0.0002\n",
      "Epoch: [79/100]Loss: 0.0002\n",
      "Epoch: [80/100]Loss: 0.0002\n",
      "Epoch: [81/100]Loss: 0.0002\n",
      "Epoch: [82/100]Loss: 0.0002\n",
      "Epoch: [83/100]Loss: 0.0002\n",
      "Epoch: [84/100]Loss: 0.0002\n",
      "Epoch: [85/100]Loss: 0.0002\n",
      "Epoch: [86/100]Loss: 0.0002\n",
      "Epoch: [87/100]Loss: 0.0002\n",
      "Epoch: [88/100]Loss: 0.0002\n",
      "Epoch: [89/100]Loss: 0.0002\n",
      "Epoch: [90/100]Loss: 0.0002\n",
      "Epoch: [91/100]Loss: 0.0002\n",
      "Epoch: [92/100]Loss: 0.0002\n",
      "Epoch: [93/100]Loss: 0.0001\n",
      "Epoch: [94/100]Loss: 0.0001\n",
      "Epoch: [95/100]Loss: 0.0001\n",
      "Epoch: [96/100]Loss: 0.0001\n",
      "Epoch: [97/100]Loss: 0.0001\n",
      "Epoch: [98/100]Loss: 0.0001\n",
      "Epoch: [99/100]Loss: 0.0001\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0001\n",
      "29 <class 'numpy.int32'>\n",
      "[28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25]\n",
      "41\n",
      "[29]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[ 0.0108, -0.0651,  0.0628,  0.1025,  0.1256, -0.1033, -0.0811, -0.0964,\n",
      "         -0.0664,  0.0753, -0.0575, -0.0225, -0.0747, -0.0507, -0.0893,  0.0224,\n",
      "         -0.0242,  0.0008,  0.1171, -0.1060, -0.1105, -0.0108,  0.1007, -0.0314,\n",
      "          0.1130, -0.0247, -0.0382,  0.0482,  0.1106,  0.0164,  0.0449,  0.0206,\n",
      "         -0.0090, -0.0562,  0.0113,  0.0033, -0.0957, -0.1054,  0.1248,  0.0043,\n",
      "          0.1180, -0.0569,  0.0426,  0.0139, -0.0765, -0.0969,  0.0686,  0.0489,\n",
      "         -0.0623,  0.1090, -0.0050,  0.0486,  0.0730,  0.1210, -0.0731,  0.0215,\n",
      "          0.1033, -0.0853, -0.0929, -0.0069, -0.0753,  0.0957],\n",
      "        [ 0.0318, -0.1020,  0.0010, -0.1028,  0.0927,  0.0587,  0.0928, -0.0129,\n",
      "          0.0373,  0.0092, -0.1006,  0.0052,  0.0605, -0.0395,  0.0631,  0.0576,\n",
      "         -0.0039,  0.0450,  0.1002, -0.1217,  0.0578, -0.0281,  0.0027,  0.0395,\n",
      "         -0.0370, -0.0999,  0.1044,  0.0811,  0.0380,  0.1243, -0.1093,  0.0749,\n",
      "          0.1001, -0.0949,  0.0352, -0.0039, -0.0624,  0.0943, -0.0027, -0.0946,\n",
      "          0.0600,  0.0996,  0.0508,  0.0801,  0.0652, -0.0560, -0.0024,  0.0115,\n",
      "          0.0454, -0.0031,  0.0371,  0.0303, -0.0709, -0.0719,  0.0607,  0.0533,\n",
      "         -0.0928,  0.1041,  0.1086, -0.0477, -0.0515, -0.0409]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0350, -0.1184], requires_grad=True)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.8980\n",
      "Epoch: [1/100]Loss: 0.7564\n",
      "Epoch: [2/100]Loss: 0.6509\n",
      "Epoch: [3/100]Loss: 0.4263\n",
      "Epoch: [4/100]Loss: 0.2549\n",
      "Epoch: [5/100]Loss: 0.1255\n",
      "Epoch: [6/100]Loss: 0.0604\n",
      "Epoch: [7/100]Loss: 0.0364\n",
      "Epoch: [8/100]Loss: 0.0133\n",
      "Epoch: [9/100]Loss: 0.0071\n",
      "Epoch: [10/100]Loss: 0.0049\n",
      "Epoch: [11/100]Loss: 0.0037\n",
      "Epoch: [12/100]Loss: 0.0029\n",
      "Epoch: [13/100]Loss: 0.0024\n",
      "Epoch: [14/100]Loss: 0.0020\n",
      "Epoch: [15/100]Loss: 0.0017\n",
      "Epoch: [16/100]Loss: 0.0015\n",
      "Epoch: [17/100]Loss: 0.0013\n",
      "Epoch: [18/100]Loss: 0.0011\n",
      "Epoch: [19/100]Loss: 0.0010\n",
      "Epoch: [20/100]Loss: 0.0009\n",
      "Epoch: [21/100]Loss: 0.0008\n",
      "Epoch: [22/100]Loss: 0.0008\n",
      "Epoch: [23/100]Loss: 0.0007\n",
      "Epoch: [24/100]Loss: 0.0006\n",
      "Epoch: [25/100]Loss: 0.0006\n",
      "Epoch: [26/100]Loss: 0.0006\n",
      "Epoch: [27/100]Loss: 0.0005\n",
      "Epoch: [28/100]Loss: 0.0005\n",
      "Epoch: [29/100]Loss: 0.0005\n",
      "Epoch: [30/100]Loss: 0.0004\n",
      "Epoch: [31/100]Loss: 0.0004\n",
      "Epoch: [32/100]Loss: 0.0004\n",
      "Epoch: [33/100]Loss: 0.0004\n",
      "Epoch: [34/100]Loss: 0.0003\n",
      "Epoch: [35/100]Loss: 0.0003\n",
      "Epoch: [36/100]Loss: 0.0003\n",
      "Epoch: [37/100]Loss: 0.0003\n",
      "Epoch: [38/100]Loss: 0.0003\n",
      "Epoch: [39/100]Loss: 0.0003\n",
      "Epoch: [40/100]Loss: 0.0003\n",
      "Epoch: [41/100]Loss: 0.0002\n",
      "Epoch: [42/100]Loss: 0.0002\n",
      "Epoch: [43/100]Loss: 0.0002\n",
      "Epoch: [44/100]Loss: 0.0002\n",
      "Epoch: [45/100]Loss: 0.0002\n",
      "Epoch: [46/100]Loss: 0.0002\n",
      "Epoch: [47/100]Loss: 0.0002\n",
      "Epoch: [48/100]Loss: 0.0002\n",
      "Epoch: [49/100]Loss: 0.0002\n",
      "Epoch: [50/100]Loss: 0.0002\n",
      "Epoch: [51/100]Loss: 0.0002\n",
      "Epoch: [52/100]Loss: 0.0002\n",
      "Epoch: [53/100]Loss: 0.0002\n",
      "Epoch: [54/100]Loss: 0.0002\n",
      "Epoch: [55/100]Loss: 0.0001\n",
      "Epoch: [56/100]Loss: 0.0001\n",
      "Epoch: [57/100]Loss: 0.0001\n",
      "Epoch: [58/100]Loss: 0.0001\n",
      "Epoch: [59/100]Loss: 0.0001\n",
      "Epoch: [60/100]Loss: 0.0001\n",
      "Epoch: [61/100]Loss: 0.0001\n",
      "Epoch: [62/100]Loss: 0.0001\n",
      "Epoch: [63/100]Loss: 0.0001\n",
      "Epoch: [64/100]Loss: 0.0001\n",
      "Epoch: [65/100]Loss: 0.0001\n",
      "Epoch: [66/100]Loss: 0.0001\n",
      "Epoch: [67/100]Loss: 0.0001\n",
      "Epoch: [68/100]Loss: 0.0001\n",
      "Epoch: [69/100]Loss: 0.0001\n",
      "Epoch: [70/100]Loss: 0.0001\n",
      "Epoch: [71/100]Loss: 0.0001\n",
      "Epoch: [72/100]Loss: 0.0001\n",
      "Epoch: [73/100]Loss: 0.0001\n",
      "Epoch: [74/100]Loss: 0.0001\n",
      "Epoch: [75/100]Loss: 0.0001\n",
      "Epoch: [76/100]Loss: 0.0001\n",
      "Epoch: [77/100]Loss: 0.0001\n",
      "Epoch: [78/100]Loss: 0.0001\n",
      "Epoch: [79/100]Loss: 0.0001\n",
      "Epoch: [80/100]Loss: 0.0001\n",
      "Epoch: [81/100]Loss: 0.0001\n",
      "Epoch: [82/100]Loss: 0.0001\n",
      "Epoch: [83/100]Loss: 0.0001\n",
      "Epoch: [84/100]Loss: 0.0001\n",
      "Epoch: [85/100]Loss: 0.0001\n",
      "Epoch: [86/100]Loss: 0.0001\n",
      "Epoch: [87/100]Loss: 0.0001\n",
      "Epoch: [88/100]Loss: 0.0001\n",
      "Epoch: [89/100]Loss: 0.0001\n",
      "Epoch: [90/100]Loss: 0.0001\n",
      "Epoch: [91/100]Loss: 0.0001\n",
      "Epoch: [92/100]Loss: 0.0001\n",
      "Epoch: [93/100]Loss: 0.0001\n",
      "Epoch: [94/100]Loss: 0.0001\n",
      "Epoch: [95/100]Loss: 0.0001\n",
      "Epoch: [96/100]Loss: 0.0001\n",
      "Epoch: [97/100]Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [98/100]Loss: 0.0001\n",
      "Epoch: [99/100]Loss: 0.0001\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0001\n",
      "145 <class 'numpy.int32'>\n",
      "[125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "494\n",
      "[145]\n",
      "12 12 7 7\n",
      "Parameter containing:\n",
      "tensor([[ 0.0782,  0.0641, -0.0249, -0.0777, -0.0353, -0.0994,  0.0708, -0.0540,\n",
      "         -0.0745, -0.0869, -0.0342,  0.0617,  0.1226, -0.1255, -0.1011, -0.0734,\n",
      "         -0.0587, -0.0944, -0.0495,  0.1147,  0.0721, -0.0962, -0.0159,  0.0019,\n",
      "          0.0124,  0.0664, -0.0076, -0.0661,  0.0807, -0.0514,  0.0345, -0.0039,\n",
      "         -0.1124, -0.1126,  0.0608,  0.0947, -0.0740,  0.0494, -0.1158, -0.0133,\n",
      "          0.0479, -0.0889,  0.0863,  0.0819,  0.0764, -0.0641, -0.0597,  0.0212,\n",
      "         -0.0024, -0.0669,  0.1107,  0.0193, -0.0318, -0.0195, -0.0983, -0.0807,\n",
      "          0.0954, -0.0614,  0.1121, -0.0053,  0.0594, -0.0869],\n",
      "        [-0.0541, -0.1212, -0.0157, -0.1199,  0.0185,  0.1035,  0.1216, -0.0477,\n",
      "          0.0376,  0.0334,  0.0949,  0.0931,  0.1001, -0.1249,  0.1043,  0.1035,\n",
      "         -0.0229, -0.0529, -0.0480, -0.0884, -0.0815,  0.1259, -0.0985,  0.0222,\n",
      "         -0.0681,  0.1003, -0.0756, -0.0517, -0.0275,  0.0809, -0.1243,  0.0747,\n",
      "          0.0685,  0.0443,  0.0988, -0.0792, -0.1252, -0.0544,  0.0760,  0.1168,\n",
      "         -0.0854, -0.1173,  0.0972,  0.1250, -0.0971,  0.0871, -0.1131,  0.0344,\n",
      "          0.0565, -0.0240,  0.1212,  0.0815,  0.0215, -0.0267,  0.0029,  0.0299,\n",
      "          0.0153,  0.0267, -0.0647,  0.0943,  0.0450, -0.0430]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([ 0.0702, -0.1242], requires_grad=True)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 19 20 21 22 23 24 25 26 27 28 29 30\n",
      " 16 17 12 14 13 18 15 32 37 35 31 36 34 33]\n",
      "[145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145]\n",
      "24\n",
      "Epoch: [0/100]Loss: 0.8561\n",
      "Epoch: [1/100]Loss: 0.6096\n",
      "Epoch: [2/100]Loss: 0.4123\n",
      "Epoch: [3/100]Loss: 0.3091\n",
      "Epoch: [4/100]Loss: 0.2661\n",
      "Epoch: [5/100]Loss: 0.2483\n",
      "Epoch: [6/100]Loss: 0.2400\n",
      "Epoch: [7/100]Loss: 0.2354\n",
      "Epoch: [8/100]Loss: 0.2324\n",
      "Epoch: [9/100]Loss: 0.2301\n",
      "Epoch: [10/100]Loss: 0.2280\n",
      "Epoch: [11/100]Loss: 0.2247\n",
      "Epoch: [12/100]Loss: 0.2132\n",
      "Epoch: [13/100]Loss: 0.2101\n",
      "Epoch: [14/100]Loss: 0.2151\n",
      "Epoch: [15/100]Loss: 0.2159\n",
      "Epoch: [16/100]Loss: 0.2152\n",
      "Epoch: [17/100]Loss: 0.2126\n",
      "Epoch: [18/100]Loss: 0.2084\n",
      "Epoch: [19/100]Loss: 0.1985\n",
      "Epoch: [20/100]Loss: 0.1734\n",
      "Epoch: [21/100]Loss: 0.1482\n",
      "Epoch: [22/100]Loss: 0.1191\n",
      "Epoch: [23/100]Loss: 0.0454\n",
      "Epoch: [24/100]Loss: 0.0400\n",
      "Epoch: [25/100]Loss: 0.0368\n",
      "Epoch: [26/100]Loss: 0.0102\n",
      "Epoch: [27/100]Loss: 0.0181\n",
      "Epoch: [28/100]Loss: 0.0066\n",
      "Epoch: [29/100]Loss: 0.0078\n",
      "Epoch: [30/100]Loss: 0.0044\n",
      "Epoch: [31/100]Loss: 0.0034\n",
      "Epoch: [32/100]Loss: 0.0415\n",
      "Epoch: [33/100]Loss: 0.0070\n",
      "Epoch: [34/100]Loss: 0.0079\n",
      "Epoch: [35/100]Loss: 0.0059\n",
      "Epoch: [36/100]Loss: 0.0043\n",
      "Epoch: [37/100]Loss: 0.0035\n",
      "Epoch: [38/100]Loss: 0.0029\n",
      "Epoch: [39/100]Loss: 0.0025\n",
      "Epoch: [40/100]Loss: 0.0022\n",
      "Epoch: [41/100]Loss: 0.0020\n",
      "Epoch: [42/100]Loss: 0.0018\n",
      "Epoch: [43/100]Loss: 0.0016\n",
      "Epoch: [44/100]Loss: 0.0015\n",
      "Epoch: [45/100]Loss: 0.0014\n",
      "Epoch: [46/100]Loss: 0.0013\n",
      "Epoch: [47/100]Loss: 0.0012\n",
      "Epoch: [48/100]Loss: 0.0011\n",
      "Epoch: [49/100]Loss: 0.0011\n",
      "Epoch: [50/100]Loss: 0.0010\n",
      "Epoch: [51/100]Loss: 0.0009\n",
      "Epoch: [52/100]Loss: 0.0009\n",
      "Epoch: [53/100]Loss: 0.0008\n",
      "Epoch: [54/100]Loss: 0.0008\n",
      "Epoch: [55/100]Loss: 0.0008\n",
      "Epoch: [56/100]Loss: 0.0007\n",
      "Epoch: [57/100]Loss: 0.0007\n",
      "Epoch: [58/100]Loss: 0.0007\n",
      "Epoch: [59/100]Loss: 0.0006\n",
      "Epoch: [60/100]Loss: 0.0006\n",
      "Epoch: [61/100]Loss: 0.0006\n",
      "Epoch: [62/100]Loss: 0.0006\n",
      "Epoch: [63/100]Loss: 0.0006\n",
      "Epoch: [64/100]Loss: 0.0005\n",
      "Epoch: [65/100]Loss: 0.0005\n",
      "Epoch: [66/100]Loss: 0.0005\n",
      "Epoch: [67/100]Loss: 0.0005\n",
      "Epoch: [68/100]Loss: 0.0005\n",
      "Epoch: [69/100]Loss: 0.0004\n",
      "Epoch: [70/100]Loss: 0.0004\n",
      "Epoch: [71/100]Loss: 0.0004\n",
      "Epoch: [72/100]Loss: 0.0004\n",
      "Epoch: [73/100]Loss: 0.0004\n",
      "Epoch: [74/100]Loss: 0.0004\n",
      "Epoch: [75/100]Loss: 0.0004\n",
      "Epoch: [76/100]Loss: 0.0004\n",
      "Epoch: [77/100]Loss: 0.0004\n",
      "Epoch: [78/100]Loss: 0.0003\n",
      "Epoch: [79/100]Loss: 0.0003\n",
      "Epoch: [80/100]Loss: 0.0003\n",
      "Epoch: [81/100]Loss: 0.0003\n",
      "Epoch: [82/100]Loss: 0.0003\n",
      "Epoch: [83/100]Loss: 0.0003\n",
      "Epoch: [84/100]Loss: 0.0003\n",
      "Epoch: [85/100]Loss: 0.0003\n",
      "Epoch: [86/100]Loss: 0.0003\n",
      "Epoch: [87/100]Loss: 0.0003\n",
      "Epoch: [88/100]Loss: 0.0003\n",
      "Epoch: [89/100]Loss: 0.0003\n",
      "Epoch: [90/100]Loss: 0.0003\n",
      "Epoch: [91/100]Loss: 0.0002\n",
      "Epoch: [92/100]Loss: 0.0002\n",
      "Epoch: [93/100]Loss: 0.0002\n",
      "Epoch: [94/100]Loss: 0.0002\n",
      "Epoch: [95/100]Loss: 0.0002\n",
      "Epoch: [96/100]Loss: 0.0002\n",
      "Epoch: [97/100]Loss: 0.0002\n",
      "Epoch: [98/100]Loss: 0.0002\n",
      "Epoch: [99/100]Loss: 0.0002\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "Accuracy of the network on the 14 test images: 92.85714285714286 %\n",
      "Loss: 0.0002\n",
      "105 <class 'numpy.int32'>\n",
      "47 <class 'numpy.int32'>\n",
      "76 <class 'numpy.int32'>\n",
      "84 <class 'numpy.int32'>\n",
      "26 <class 'numpy.int32'>\n",
      "128 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "833\n",
      "[105, 47, 76, 84, 26, 128]\n",
      "72 72 42 42\n",
      "Parameter containing:\n",
      "tensor([[-0.0126, -0.0787,  0.0376, -0.0011,  0.0266,  0.0243, -0.0701, -0.1068,\n",
      "         -0.0982,  0.0469, -0.0718,  0.0965, -0.1163,  0.0765, -0.0219, -0.0982,\n",
      "         -0.0099,  0.1010,  0.0439,  0.0891, -0.0725, -0.0055,  0.0688, -0.0513,\n",
      "         -0.0341, -0.0637,  0.0320,  0.0982,  0.0092, -0.0298, -0.0425,  0.1182,\n",
      "          0.0627, -0.0629, -0.0448, -0.0545,  0.0342,  0.0401,  0.0160, -0.0228,\n",
      "         -0.1011,  0.0716,  0.0471,  0.1072,  0.0983,  0.1042, -0.0531,  0.0299,\n",
      "         -0.0746, -0.0493, -0.0526, -0.1077,  0.0605,  0.0647, -0.0537,  0.0791,\n",
      "         -0.0783, -0.0230,  0.0230, -0.0706,  0.0187, -0.0026],\n",
      "        [-0.0932, -0.1021,  0.0936,  0.0824,  0.1256, -0.1113, -0.0539, -0.1239,\n",
      "          0.1235, -0.0910, -0.0220,  0.1234, -0.1083, -0.0117, -0.0009, -0.0101,\n",
      "         -0.0661,  0.1077,  0.1130, -0.0171, -0.1269, -0.0388,  0.0643, -0.0937,\n",
      "         -0.0589, -0.1248, -0.0873,  0.1151,  0.1089,  0.0033, -0.0702,  0.1226,\n",
      "         -0.0586, -0.0546,  0.0673,  0.0946, -0.1091,  0.0072,  0.0717,  0.0134,\n",
      "          0.0778, -0.0894, -0.0340,  0.0095, -0.0650,  0.0653, -0.0830, -0.0758,\n",
      "         -0.0170,  0.0655,  0.0397, -0.0400, -0.1125, -0.0290,  0.1029,  0.0871,\n",
      "          0.0460, -0.0168, -0.0745, -0.0403, -0.1016, -0.1163]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0843, -0.1209], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71] [114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185]\n",
      "[ 39   7  23  51  37  14   8  42  69  68  57  38  56  47  21  31  17  19\n",
      "  59  29  62  63  58  28  26  55   4  46   1  41  45  15  24  64  71  43\n",
      "  44   9  70  20  16  65  50  32  30  33  66  36  35  60  18  61  12  40\n",
      "  53   0  10  54  11  34  25  13   5  52  49  22  48  67   3   2   6  27\n",
      " 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185\n",
      " 100 101  79  89 105 103 112  96  95  81  86  91  88  87 111 102  98  73\n",
      "  92  76 108  90 104 107  80  93  72  82 106 113 110  97  85  77  94  84\n",
      " 109  75  74  78  99  83 220 227 210 187 191 211 213 194 221 195 225 190\n",
      " 212 216 192 224 186 215 222 219 223 206 199 198 209 204 214 200 208 197\n",
      " 188 207 201 217 218 202 189 203 193 226 196 205]\n",
      "[47, 105, 105, 47, 105, 105, 105, 47, 47, 47, 47, 47, 47, 47, 105, 105, 105, 105, 47, 105, 47, 47, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 47, 47, 47, 105, 47, 105, 105, 47, 47, 105, 105, 105, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 105, 105, 105, 105, 105, 47, 47, 105, 47, 47, 105, 105, 105, 105, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 47, 76, 76, 76, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128]\n",
      "144\n",
      "Epoch: [0/100]Loss: 0.0609\n",
      "Epoch: [1/100]Loss: 0.0596\n",
      "Epoch: [2/100]Loss: 0.5625\n",
      "Epoch: [3/100]Loss: 0.5293\n",
      "Epoch: [4/100]Loss: 0.6382\n",
      "Epoch: [5/100]Loss: 0.6507\n",
      "Epoch: [6/100]Loss: 0.6583\n",
      "Epoch: [7/100]Loss: 0.6600\n",
      "Epoch: [8/100]Loss: 0.6630\n",
      "Epoch: [9/100]Loss: 0.6635\n",
      "Epoch: [10/100]Loss: 0.6637\n",
      "Epoch: [11/100]Loss: 0.0339\n",
      "Epoch: [12/100]Loss: 0.0341\n",
      "Epoch: [13/100]Loss: 0.3681\n",
      "Epoch: [14/100]Loss: 0.5550\n",
      "Epoch: [15/100]Loss: 0.6535\n",
      "Epoch: [16/100]Loss: 0.6632\n",
      "Epoch: [17/100]Loss: 0.6647\n",
      "Epoch: [18/100]Loss: 0.6654\n",
      "Epoch: [19/100]Loss: 0.6659\n",
      "Epoch: [20/100]Loss: 0.6662\n",
      "Epoch: [21/100]Loss: 0.6665\n",
      "Epoch: [22/100]Loss: 0.6666\n",
      "Epoch: [23/100]Loss: 0.6666\n",
      "Epoch: [24/100]Loss: 0.6665\n",
      "Epoch: [25/100]Loss: 0.6664\n",
      "Epoch: [26/100]Loss: 0.6655\n",
      "Epoch: [27/100]Loss: 0.6248\n",
      "Epoch: [28/100]Loss: 0.6302\n",
      "Epoch: [29/100]Loss: 0.6611\n",
      "Epoch: [30/100]Loss: 0.6547\n",
      "Epoch: [31/100]Loss: 0.6512\n",
      "Epoch: [32/100]Loss: 0.6589\n",
      "Epoch: [33/100]Loss: 0.6549\n",
      "Epoch: [34/100]Loss: 0.6554\n",
      "Epoch: [35/100]Loss: 0.6532\n",
      "Epoch: [36/100]Loss: 0.6510\n",
      "Epoch: [37/100]Loss: 0.6507\n",
      "Epoch: [38/100]Loss: 0.6476\n",
      "Epoch: [39/100]Loss: 0.5969\n",
      "Epoch: [40/100]Loss: 0.6522\n",
      "Epoch: [41/100]Loss: 0.6340\n",
      "Epoch: [42/100]Loss: 0.0045\n",
      "Epoch: [43/100]Loss: 0.2139\n",
      "Epoch: [44/100]Loss: 0.6034\n",
      "Epoch: [45/100]Loss: 0.6440\n",
      "Epoch: [46/100]Loss: 0.0436\n",
      "Epoch: [47/100]Loss: 0.0072\n",
      "Epoch: [48/100]Loss: 0.2140\n",
      "Epoch: [49/100]Loss: 0.5367\n",
      "Epoch: [50/100]Loss: 0.6240\n",
      "Epoch: [51/100]Loss: 0.6475\n",
      "Epoch: [52/100]Loss: 0.6615\n",
      "Epoch: [53/100]Loss: 0.6774\n",
      "Epoch: [54/100]Loss: 0.6833\n",
      "Epoch: [55/100]Loss: 0.6793\n",
      "Epoch: [56/100]Loss: 0.6734\n",
      "Epoch: [57/100]Loss: 0.6653\n",
      "Epoch: [58/100]Loss: 0.6322\n",
      "Epoch: [59/100]Loss: 0.6461\n",
      "Epoch: [60/100]Loss: 0.6345\n",
      "Epoch: [61/100]Loss: 0.6479\n",
      "Epoch: [62/100]Loss: 0.6390\n",
      "Epoch: [63/100]Loss: 0.6214\n",
      "Epoch: [64/100]Loss: 0.6342\n",
      "Epoch: [65/100]Loss: 0.6154\n",
      "Epoch: [66/100]Loss: 0.5919\n",
      "Epoch: [67/100]Loss: 0.6072\n",
      "Epoch: [68/100]Loss: 0.4819\n",
      "Epoch: [69/100]Loss: 0.0388\n",
      "Epoch: [70/100]Loss: 0.2646\n",
      "Epoch: [71/100]Loss: 0.4393\n",
      "Epoch: [72/100]Loss: 0.5857\n",
      "Epoch: [73/100]Loss: 0.6342\n",
      "Epoch: [74/100]Loss: 0.6330\n",
      "Epoch: [75/100]Loss: 0.6411\n",
      "Epoch: [76/100]Loss: 0.6328\n",
      "Epoch: [77/100]Loss: 0.6199\n",
      "Epoch: [78/100]Loss: 0.5399\n",
      "Epoch: [79/100]Loss: 0.3722\n",
      "Epoch: [80/100]Loss: 0.2238\n",
      "Epoch: [81/100]Loss: 0.0887\n",
      "Epoch: [82/100]Loss: 0.0421\n",
      "Epoch: [83/100]Loss: 0.3192\n",
      "Epoch: [84/100]Loss: 0.1831\n",
      "Epoch: [85/100]Loss: 0.1127\n",
      "Epoch: [86/100]Loss: 0.2665\n",
      "Epoch: [87/100]Loss: 0.3341\n",
      "Epoch: [88/100]Loss: 0.1207\n",
      "Epoch: [89/100]Loss: 0.0233\n",
      "Epoch: [90/100]Loss: 0.0480\n",
      "Epoch: [91/100]Loss: 0.0102\n",
      "Epoch: [92/100]Loss: 0.0054\n",
      "Epoch: [93/100]Loss: 0.0029\n",
      "Epoch: [94/100]Loss: 0.0341\n",
      "Epoch: [95/100]Loss: 0.0078\n",
      "Epoch: [96/100]Loss: 0.0025\n",
      "Epoch: [97/100]Loss: 0.0011\n",
      "Epoch: [98/100]Loss: 0.0006\n",
      "Epoch: [99/100]Loss: 0.0006\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 84 test images: 41.666666666666664 %\n",
      "Loss: 0.0006\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-590c17b82477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cornerData/result.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ssdkms\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'DataFrame'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_list = [0,1,2,3,4,5,0]\n",
    "number_of_corner_list = [1,2,3,4,5,6,6]\n",
    "d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "feature =0\n",
    "for i in range(7):\n",
    "    start = start_list[i]\n",
    "    number_of_corner = number_of_corner_list[i]\n",
    "    df_begin = []\n",
    "    num_row = []\n",
    "    num_row_corner = []\n",
    "    percent = []\n",
    "#     start = 0\n",
    "#     number_of_corner = 1\n",
    "    f_1 = 'beginner_expert_processedData/beginner/beginner_'\n",
    "    f_3 = '.csv'\n",
    "    num_begin = 19\n",
    "    curveList = [[103.9, 209.3], [316.6, 399.6], [425.3, 517.9], [590.5, 756.9], [1048.7, 1110.5], [1212.3, 1437.1]]\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "\n",
    "    for curve_num in range(start,number_of_corner):\n",
    "    # for curve_num in [0,3]:\n",
    "    #     print(num_row)\n",
    "        for idx in range(1, num_begin+1):\n",
    "            tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "            df = pd.read_csv(tmp_file)\n",
    "            df = df.dropna()\n",
    "\n",
    "            tmp = df.astype(float)\n",
    "            tmp['level'] =0\n",
    "\n",
    "            tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "            num_row.append(np.size(tmpcorner,0)) \n",
    "            num_row_corner.append(np.size(tmpcorner,0)) \n",
    "            df_begin.append(tmpcorner)\n",
    "            df_concat = pd.concat([df_concat,df_begin[idx-1]])      \n",
    "\n",
    "        df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_begin'+'.csv')\n",
    "        df_concat = pd.DataFrame()\n",
    "        df_begin = []\n",
    "\n",
    "\n",
    "      #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "    df_exp = []\n",
    "    f_1 = 'beginner_expert_processedData/expert/expert_'\n",
    "    f_3 = '.csv'\n",
    "    num_exp = 19\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "\n",
    "    for curve_num in range(start,number_of_corner):\n",
    "    # for curve_num in [0,3]:\n",
    "        for idx in range(1, num_exp+1):\n",
    "            tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "            df = pd.read_csv(tmp_file)\n",
    "            df = df.dropna()\n",
    "\n",
    "            tmp = df.astype(float)\n",
    "            tmp['level'] =1\n",
    "\n",
    "            tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "            num_row.append(np.size(tmpcorner,0))\n",
    "            num_row_corner.append(np.size(tmpcorner,0)) \n",
    "\n",
    "            df_exp.append(tmpcorner)\n",
    "            df_concat = pd.concat([df_concat,df_exp[idx-1]])\n",
    "        df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_expert'+'.csv')\n",
    "        df_concat = pd.DataFrame()\n",
    "        df_exp = []\n",
    "        num_row_corner = np.array(num_row_corner)\n",
    "        per = np.percentile(num_row_corner, 70).astype('int')\n",
    "    #     np.ndarray.tolist(per)\n",
    "        print(per,type(per))\n",
    "        percent.append(per)\n",
    "        num_row_corner = []\n",
    "\n",
    "      #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "\n",
    "    print(num_row)\n",
    "    sequence_length = max(num_row)\n",
    "    print(sequence_length)\n",
    "    mean_row = round(np.mean(num_row))\n",
    "    mean_row = min(num_row)\n",
    "    print(percent)\n",
    "\n",
    "\n",
    "      #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "\n",
    "    left_column = [\n",
    "    #'Time',\n",
    "    #     'Distance',\n",
    "    #     'Session Time Left',\n",
    "    #     'Corr Dist','Corr Dist (Unstretched)',\n",
    "    #     'GPS Latitude','GPS Longitude',\n",
    "    #     'CG Distance',\n",
    "        'Damper Velocity (Calc) FL','Damper Velocity (Calc) FR','Damper Velocity (Calc) RL',\n",
    "    'Damper Velocity (Calc) RR','Corr Speed','Brake Pos',\n",
    "    'CG Accel Lateral','CG Accel Longitudinal','CG Accel Vertical','CG Height','Camber FL','Camber FR','Camber RL','Camber RR','Car Coord X',\n",
    "    'Car Coord Y','Car Coord Z','Car Pos Norm','Chassis Pitch Angle','Chassis Pitch Rate','Chassis Roll Angle','Chassis Roll Rate',\n",
    "    'Chassis Velocity X','Chassis Velocity Y','Chassis Velocity Z','Chassis Yaw Rate','Drive Train Speed','Engine RPM','Ground Speed',\n",
    "    'Ride Height FL','Ride Height FR','Ride Height RL','Ride Height RR','Road Temp','Self Align Torque FL','Self Align Torque FR',\n",
    "    'Self Align Torque RL','Self Align Torque RR','Steering Angle','Suspension Travel FL','Suspension Travel FR',\n",
    "    'Suspension Travel RL','Suspension Travel RR','Tire Load FL','Tire Load FR','Tire Load RL','Tire Load RR','Tire Loaded Radius FL',\n",
    "    'Tire Loaded Radius FR','Tire Loaded Radius RL','Tire Loaded Radius RR','Tire Pressure FL','Tire Pressure FR','Tire Pressure RL','Tire Pressure RR',\n",
    "    'Tire Rubber Grip FL','Tire Rubber Grip FR','Tire Rubber Grip RL','Tire Rubber Grip RR','Tire Slip Angle FL','Tire Slip Angle FR',\n",
    "    'Tire Slip Angle RL','Tire Slip Angle RR','Tire Slip Ratio FL','Tire Slip Ratio FR','Tire Slip Ratio RL','Tire Slip Ratio RR',\n",
    "    'Tire Temp Core FL','Tire Temp Core FR','Tire Temp Core RL','Tire Temp Core RR','Tire Temp Inner FL','Tire Temp Inner FR',\n",
    "    'Tire Temp Inner RL','Tire Temp Inner RR','Tire Temp Middle FL','Tire Temp Middle FR','Tire Temp Middle RL',\n",
    "    'Tire Temp Middle RR','Tire Temp Outer FL','Tire Temp Outer FR','Tire Temp Outer RL','Tire Temp Outer RR','Toe In FL',\n",
    "    'Toe In FR','Toe In RL','Toe In RR','Wheel Angular Speed FL','Wheel Angular Speed FR','Wheel Angular Speed RL','Wheel Angular Speed RR',\n",
    "    'Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration','level']\n",
    "\n",
    "    # left_column = ['Brake Pos', 'Ground Speed', 'Steering Angle', 'Throttle Pos', 'Chassis Yaw Rate', 'Chassis Velocity X',\n",
    "    #                    'Chassis Velocity Y','Chassis Velocity Z','Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration',\n",
    "    # #                    'CG Distance',\n",
    "    #                'level']\n",
    "\n",
    "    #Hyper-parameters\n",
    "    num_epochs = 100\n",
    "    batches = 1\n",
    "    learning_rate = 0.001\n",
    "    input_size = len(left_column)-1 # left column except 'level'\n",
    "    output_size = 2 # Expert and Beginner\n",
    "    hidden_size = 62 # ?\n",
    "    num_layers = 2\n",
    "    num_begin_train = round(num_begin*0.65)*(number_of_corner-start)\n",
    "    num_exp_train = round(num_exp*0.65)*(number_of_corner-start)\n",
    "    num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "    num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "\n",
    "    print(num_begin_train, num_exp_train,num_begin_test,num_exp_test)\n",
    "    aug = 1\n",
    "    ## Define GRU, Loss func and Optimizer\n",
    "    class GRU(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "            super(GRU, self).__init__()\n",
    "            self.num_layers = num_layers\n",
    "            self.hidden_size = hidden_size\n",
    "#             self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "            self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "            out, _ = self.gru(x, h0)\n",
    "#             out, _ = self.lstm(x, (h0,c0)) \n",
    "            out = out[:, -1, :]\n",
    "            out = self.fc(out)\n",
    "            return out\n",
    "\n",
    "    gru = GRU(input_size, hidden_size, num_layers, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)  \n",
    "\n",
    "    # gru.fc.weight.data.fill_(1)\n",
    "    # gru.fc.bias.data.fill_(1)\n",
    "#     print(gru.fc.weight,gru.fc.bias)\n",
    "\n",
    "    ## Data Processing\n",
    "    array_x = []\n",
    "    array_y = []\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    n_row = []\n",
    "\n",
    "    df_tmp_begin = pd.DataFrame() \n",
    "    df_tmp_exp = pd.DataFrame() \n",
    "    for curve_num in range(start,number_of_corner):\n",
    "    # for curve_num in [0,3]:\n",
    "        df_tmp_begin = pd.concat([df_tmp_begin,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_begin.csv')])\n",
    "        df_tmp_exp   = pd.concat([df_tmp_exp,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_expert.csv')])    \n",
    "    df_curve1 = pd.concat([df_tmp_begin, df_tmp_exp], ignore_index=True) \n",
    "    df_curve1 = df_curve1.loc[:,left_column]\n",
    "    df_curve1_saved = df_curve1.loc[:,left_column] # data backup\n",
    "    df_curve1.to_csv('cornerData/corner_'+'_dfcurve1'+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "    datum = df_curve1_saved\n",
    "    yyy = datum.pop('level')\n",
    "    left = left_column.remove('level')\n",
    "    for i in range(0,num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "    #     x = df_curve1_saved.loc[0:num_row[i]-1\n",
    "        y = yyy.loc[0:num_row[i]-1]\n",
    "    #     y = y.iloc[0]\n",
    "        x_original = datum.loc[0:num_row[i]-1]\n",
    "\n",
    "    #     print(x_original)\n",
    "    #     print(num_row[i],y[0],x_original.iloc[-1,0])\n",
    "\n",
    "    #     scaler = StandardScaler()\n",
    "        scaler = MinMaxScaler()\n",
    "    #     scaler.fit(x_original)\n",
    "    #     scaler.mean_\n",
    "        x_normal = scaler.fit_transform(x_original)\n",
    "        x_normal = scaler.transform(x_original)\n",
    "\n",
    "\n",
    "        x_normal = np.pad(x_normal,[(0,sequence_length-num_row[i]),(0,0)]) #post padding\n",
    "    #     x_normal = np.pad(x_normal,[(sequence_length-num_row[i],0),(0,0)]) #pre padding\n",
    "\n",
    "\n",
    "        x = pd.DataFrame(x_normal,columns=left)\n",
    "        p = i//(num_begin*2)\n",
    "        x = x.truncate(after=percent[p]-1)\n",
    "    #     print(x.shape)\n",
    "    #     print(datum)\n",
    "    #     print(i)\n",
    "    #     print(num_row)\n",
    "    #     print(num_row[i])\n",
    "        datum.drop(range(0,num_row[i]),inplace=True)\n",
    "        datum.reset_index(drop=True, inplace=True)\n",
    "        yyy.drop(range(0,num_row[i]),inplace=True)\n",
    "        yyy.reset_index(drop=True, inplace=True)\n",
    "        # y = x.pop('level')\n",
    "\n",
    "    #     # DATA Augmentation\n",
    "    #     nan = pd.DataFrame(np.nan,columns=range(x.shape[1]),index=range(x.shape[0]))\n",
    "    #     alter = pd.concat([x,nan]).sort_index()\n",
    "    #     alter = alter.interpolate()\n",
    "    #     alter.reset_index(drop=True, inplace=True)\n",
    "    #     x_aug = alter[alter.index%2==1]\n",
    "\n",
    "\n",
    "        array_x.append(x)\n",
    "    #     array_x.append(x_aug)\n",
    "        array_y.append(y)\n",
    "    #     array_y.append(y)\n",
    "\n",
    "\n",
    "    ## Randomize sequence \n",
    "    # sequence = np.arange((num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug/2)\n",
    "    seq_train_begin = np.arange(num_begin_train)\n",
    "    seq_test_begin = np.arange(num_begin_test) + num_begin_train\n",
    "    seq_train_exp = seq_train_begin + num_begin*(number_of_corner-start)\n",
    "    seq_test_exp = seq_test_begin + num_begin*(number_of_corner-start)\n",
    "    print(seq_train_begin,seq_train_exp)\n",
    "    np.random.seed(12)\n",
    "    np.random.shuffle(seq_train_begin)\n",
    "    np.random.seed(12)\n",
    "    np.random.shuffle(seq_test_begin)\n",
    "    np.random.seed(12)\n",
    "    np.random.shuffle(seq_train_exp)\n",
    "    np.random.seed(12)\n",
    "    np.random.shuffle(seq_test_exp)\n",
    "    # seq_train2 = seq_test\n",
    "\n",
    "\n",
    "    sequence = np.concatenate((seq_train_begin, seq_train_exp, seq_test_begin, seq_test_exp), axis=None)\n",
    "    sequence = sequence.astype('int')\n",
    "    # sequence = [0,1,2,15,4,5,6,7,8,9,18,11,12,13,14,19,20,21,34,23,24,25,26,27,28,37,30,31,32,33,3,16,17,10,22,35,36,29]\n",
    "    print(sequence)\n",
    "\n",
    "    # # Data Augmentation\n",
    "    # num_row = pd.Series(num_row)\n",
    "    # num_row = num_row.repeat(2)\n",
    "    # # sequence = pd.Series(sequence)\n",
    "    # # sequence = sequence.repeat(2)\n",
    "    # num_row.reset_index(drop=True, inplace=True)\n",
    "    # # sequence.reset_index(drop=True, inplace=True)\n",
    "    # print(num_row, sequence)\n",
    "\n",
    "    # for i in range(len(percent)):\n",
    "    #     n_row = n_row + [percent[i]]*num_begin*2\n",
    "    for i in sequence:\n",
    "        input_x.append(array_x[i])\n",
    "        input_y.append(array_y[i])\n",
    "        p = i//(num_begin*2)\n",
    "    #     print(p)\n",
    "        n_row = n_row + [percent[p]]\n",
    "\n",
    "\n",
    "    #     n_row.append(num_row[i])\n",
    "    #     n_row.append(sequence_length)\n",
    "    #     n_row.append(mean_row+1-20)\n",
    "    # input_x = np.array(input_x)\n",
    "    # input_y = np.array(input_y)\n",
    "    print(n_row)\n",
    "\n",
    "    ## Train \n",
    "    loss_list = []\n",
    "    iteration_list = []\n",
    "    accuracy_list = []\n",
    "    test_list=[]\n",
    "    count = 0\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "    print((num_begin_train + num_exp_train)*aug)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0,(num_begin_train + num_exp_train)*aug):\n",
    "\n",
    "    #         print(i)\n",
    "    #         print(len(input_x))\n",
    "            # array type (numpy) 앞\n",
    "            X = np.array(input_x[i])\n",
    "    #         print(X.shape)\n",
    "    #         X = input_x[i]\n",
    "            X = X.reshape(-1,n_row[i],input_size)\n",
    "\n",
    "            Y = np.array(input_y[i])\n",
    "\n",
    "    #         Y = input_y[i]\n",
    "    #         print(X,X.shape,Y[0])\n",
    "    #         time.sleep(300)\n",
    "            # tensor type (pytorch)\n",
    "            X = torch.from_numpy(X)\n",
    "            X = X.float()\n",
    "            Y = torch.tensor([Y[0]])\n",
    "    #         Y = torch.tensor([Y])\n",
    "            Y = Y.type(torch.LongTensor)\n",
    "    #         Y = Y.float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = gru(X)\n",
    "            loss = criterion(output, Y)\n",
    "\n",
    "            # Backward and optimize\n",
    "    #         optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        loss_list.append(loss.data)\n",
    "        iteration_list.append(count)\n",
    "        print (f'Epoch: [{epoch}/{num_epochs}]' f'Loss: {loss.item():.4f}')\n",
    "    ## Test\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "\n",
    "        for i in range((num_begin_train + num_exp_train)*aug, (num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug):\n",
    "\n",
    "            # array type (numpy)\n",
    "            X = np.array(input_x[i])\n",
    "    #         X = input_x[i]\n",
    "            X = X.reshape(-1,n_row[i],input_size)\n",
    "            Y = np.array(input_y[i])\n",
    "    #         Y = input_y[i]\n",
    "\n",
    "            # tensor type (pytorch)\n",
    "            X = torch.from_numpy(X)\n",
    "            X = X.float()\n",
    "            Y = torch.tensor([Y[0]])\n",
    "    #         Y = torch.tensor(Y)\n",
    "            Y = Y.type(torch.LongTensor)\n",
    "    #         Y = Y.float()\n",
    "            output = gru(X)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            n_samples += Y.size(0)\n",
    "            n_correct += (predicted == Y).sum().item()\n",
    "            print(Y, predicted)\n",
    "\n",
    "\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "    #     print(f'Accuracy of the network on the {(num_begin_test + num_exp_test)*aug} test images: {acc} %')\n",
    "\n",
    "    plt.plot(iteration_list,loss_list)\n",
    "    plt.xlabel(\"Number of iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "#     plt.show()\n",
    "    if feature == 0:\n",
    "        plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_allFeat.png')\n",
    "    else:\n",
    "        plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_selectedFeat.png')\n",
    "    print(f'Accuracy of the network on the {num_begin_test + num_exp_test} test images: {acc} %')\n",
    "    print(f'Loss: {loss.item():.4f}')\n",
    "    \n",
    "    d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df2 = df2.append(df)\n",
    "df2.to_csv('cornerData/result_gru.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78e290fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test sample      loss   accuracy  epoch  batch  learning rate  hidden size  \\\n",
      "0         88.0  4.000555  45.666667  104.0    5.0          4.001         66.0   \n",
      "0         88.0  4.000555  45.666667  104.0    5.0          4.001         66.0   \n",
      "0         88.0  4.000555  45.666667  104.0    5.0          4.001         66.0   \n",
      "0         88.0  4.000555  45.666667  104.0    5.0          4.001         66.0   \n",
      "\n",
      "   hidden_layer  \n",
      "0           6.0  \n",
      "0           6.0  \n",
      "0           6.0  \n",
      "0           6.0  \n"
     ]
    }
   ],
   "source": [
    "# df2.to_csv('cornerData/result_gru.csv')\n",
    "# d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "# df2 = pd.DataFrame(data=d2)\n",
    "d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df2 = df2.append(df+4)\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
