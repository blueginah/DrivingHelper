{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make each level to each Curve CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_begin = []\n",
    "num_row = []\n",
    "start = 0\n",
    "number_of_corner =1\n",
    "f_1 = 'beginner_expert_processedData/beginner/beginner_'\n",
    "f_3 = '.csv'\n",
    "num_begin = 25\n",
    "curveList = [[103.9, 209.3], [316.6, 399.6], [425.3, 517.9], [590.5, 756.9], [1048.7, 1110.5], [1212.3, 1437.1]]\n",
    "\n",
    "df_concat = pd.DataFrame()\n",
    "\n",
    "for curve_num in range(start,number_of_corner):\n",
    "#     print(num_row)\n",
    "    for idx in range(1, num_begin+1):\n",
    "        tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "        df = pd.read_csv(tmp_file)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        tmp = df.astype(float)\n",
    "        tmp['level'] =0\n",
    "        \n",
    "        tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "        num_row.append(np.size(tmpcorner,0)) \n",
    "        \n",
    "        df_begin.append(tmpcorner)\n",
    "        df_concat = pd.concat([df_concat,df_begin[idx-1]])      \n",
    "           \n",
    "    df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_begin'+'.csv')\n",
    "    df_concat = pd.DataFrame()\n",
    "    df_begin = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = []\n",
    "f_1 = 'beginner_expert_processedData/expert/expert_'\n",
    "f_3 = '.csv'\n",
    "num_exp = 19\n",
    "\n",
    "df_concat = pd.DataFrame()\n",
    "\n",
    "for curve_num in range(start,number_of_corner):\n",
    "    for idx in range(1, num_exp+1):\n",
    "        tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "        df = pd.read_csv(tmp_file)\n",
    "        df = df.dropna()\n",
    "\n",
    "        tmp = df.astype(float)\n",
    "        tmp['level'] =1\n",
    "\n",
    "        tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "        num_row.append(np.size(tmpcorner,0)) \n",
    "\n",
    "        df_exp.append(tmpcorner)\n",
    "        df_concat = pd.concat([df_concat,df_exp[idx-1]])\n",
    "    df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_expert'+'.csv')\n",
    "    df_concat = pd.DataFrame()\n",
    "    df_exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 88, 82, 75, 80, 78, 82, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72]\n"
     ]
    }
   ],
   "source": [
    "print(num_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 14 6 5\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True) Parameter containing:\n",
      "tensor([1., 1.], requires_grad=True)\n",
      "[26 10 27 39  3 33  7 18  2 23 32 38 30 34  6 12 21 20  5 13 19 17 14 31\n",
      " 35  1 42 24 22 11 41  4 16 40 43  8 37 29 25 28  0 15 36  9]\n",
      "33\n",
      "Epoch: [0/num_epochs]Loss: 0.6731\n",
      "Epoch: [1/num_epochs]Loss: 0.6523\n",
      "Epoch: [2/num_epochs]Loss: 0.6337\n",
      "Epoch: [3/num_epochs]Loss: 0.6169\n",
      "Epoch: [4/num_epochs]Loss: 0.6018\n",
      "Epoch: [5/num_epochs]Loss: 0.5880\n",
      "Epoch: [6/num_epochs]Loss: 0.5756\n",
      "Epoch: [7/num_epochs]Loss: 0.5642\n",
      "Epoch: [8/num_epochs]Loss: 0.5537\n",
      "Epoch: [9/num_epochs]Loss: 0.5442\n",
      "Epoch: [10/num_epochs]Loss: 0.5354\n",
      "Epoch: [11/num_epochs]Loss: 0.5272\n",
      "Epoch: [12/num_epochs]Loss: 0.5197\n",
      "Epoch: [13/num_epochs]Loss: 0.5126\n",
      "Epoch: [14/num_epochs]Loss: 0.5058\n",
      "Epoch: [15/num_epochs]Loss: 0.4994\n",
      "Epoch: [16/num_epochs]Loss: 0.4930\n",
      "Epoch: [17/num_epochs]Loss: 0.4867\n",
      "Epoch: [18/num_epochs]Loss: 0.4801\n",
      "Epoch: [19/num_epochs]Loss: 0.4732\n",
      "Epoch: [20/num_epochs]Loss: 0.4658\n",
      "Epoch: [21/num_epochs]Loss: 0.4575\n",
      "Epoch: [22/num_epochs]Loss: 0.4483\n",
      "Epoch: [23/num_epochs]Loss: 0.4381\n",
      "Epoch: [24/num_epochs]Loss: 0.4266\n",
      "Epoch: [25/num_epochs]Loss: 0.4138\n",
      "Epoch: [26/num_epochs]Loss: 0.3999\n",
      "Epoch: [27/num_epochs]Loss: 0.3848\n",
      "Epoch: [28/num_epochs]Loss: 0.3689\n",
      "Epoch: [29/num_epochs]Loss: 0.3523\n",
      "Epoch: [30/num_epochs]Loss: 0.3353\n",
      "Epoch: [31/num_epochs]Loss: 0.3181\n",
      "Epoch: [32/num_epochs]Loss: 0.3010\n",
      "Epoch: [33/num_epochs]Loss: 0.2842\n",
      "Epoch: [34/num_epochs]Loss: 0.2676\n",
      "Epoch: [35/num_epochs]Loss: 0.2516\n",
      "Epoch: [36/num_epochs]Loss: 0.2361\n",
      "Epoch: [37/num_epochs]Loss: 0.2212\n",
      "Epoch: [38/num_epochs]Loss: 0.2069\n",
      "Epoch: [39/num_epochs]Loss: 0.1934\n",
      "Epoch: [40/num_epochs]Loss: 0.1807\n",
      "Epoch: [41/num_epochs]Loss: 0.1687\n",
      "Epoch: [42/num_epochs]Loss: 0.1575\n",
      "Epoch: [43/num_epochs]Loss: 0.1471\n",
      "Epoch: [44/num_epochs]Loss: 0.1375\n",
      "Epoch: [45/num_epochs]Loss: 0.1286\n",
      "Epoch: [46/num_epochs]Loss: 0.1204\n",
      "Epoch: [47/num_epochs]Loss: 0.1129\n",
      "Epoch: [48/num_epochs]Loss: 0.1060\n",
      "Epoch: [49/num_epochs]Loss: 0.0997\n",
      "Epoch: [50/num_epochs]Loss: 0.0938\n",
      "Epoch: [51/num_epochs]Loss: 0.0885\n",
      "Epoch: [52/num_epochs]Loss: 0.0836\n",
      "Epoch: [53/num_epochs]Loss: 0.0790\n",
      "Epoch: [54/num_epochs]Loss: 0.0749\n",
      "Epoch: [55/num_epochs]Loss: 0.0710\n",
      "Epoch: [56/num_epochs]Loss: 0.0674\n",
      "Epoch: [57/num_epochs]Loss: 0.0641\n",
      "Epoch: [58/num_epochs]Loss: 0.0611\n",
      "Epoch: [59/num_epochs]Loss: 0.0582\n",
      "Epoch: [60/num_epochs]Loss: 0.0556\n",
      "Epoch: [61/num_epochs]Loss: 0.0531\n",
      "Epoch: [62/num_epochs]Loss: 0.0508\n",
      "Epoch: [63/num_epochs]Loss: 0.0487\n",
      "Epoch: [64/num_epochs]Loss: 0.0467\n",
      "Epoch: [65/num_epochs]Loss: 0.0448\n",
      "Epoch: [66/num_epochs]Loss: 0.0430\n",
      "Epoch: [67/num_epochs]Loss: 0.0414\n",
      "Epoch: [68/num_epochs]Loss: 0.0398\n",
      "Epoch: [69/num_epochs]Loss: 0.0384\n",
      "Epoch: [70/num_epochs]Loss: 0.0370\n",
      "Epoch: [71/num_epochs]Loss: 0.0357\n",
      "Epoch: [72/num_epochs]Loss: 0.0345\n",
      "Epoch: [73/num_epochs]Loss: 0.0333\n",
      "Epoch: [74/num_epochs]Loss: 0.0322\n",
      "Epoch: [75/num_epochs]Loss: 0.0312\n",
      "Epoch: [76/num_epochs]Loss: 0.0302\n",
      "Epoch: [77/num_epochs]Loss: 0.0293\n",
      "Epoch: [78/num_epochs]Loss: 0.0284\n",
      "Epoch: [79/num_epochs]Loss: 0.0275\n",
      "Epoch: [80/num_epochs]Loss: 0.0267\n",
      "Epoch: [81/num_epochs]Loss: 0.0260\n",
      "Epoch: [82/num_epochs]Loss: 0.0253\n",
      "Epoch: [83/num_epochs]Loss: 0.0246\n",
      "Epoch: [84/num_epochs]Loss: 0.0239\n",
      "Epoch: [85/num_epochs]Loss: 0.0233\n",
      "Epoch: [86/num_epochs]Loss: 0.0227\n",
      "Epoch: [87/num_epochs]Loss: 0.0221\n",
      "Epoch: [88/num_epochs]Loss: 0.0215\n",
      "Epoch: [89/num_epochs]Loss: 0.0210\n",
      "Epoch: [90/num_epochs]Loss: 0.0205\n",
      "Epoch: [91/num_epochs]Loss: 0.0200\n",
      "Epoch: [92/num_epochs]Loss: 0.0195\n",
      "Epoch: [93/num_epochs]Loss: 0.0191\n",
      "Epoch: [94/num_epochs]Loss: 0.0187\n",
      "Epoch: [95/num_epochs]Loss: 0.0182\n",
      "Epoch: [96/num_epochs]Loss: 0.0179\n",
      "Epoch: [97/num_epochs]Loss: 0.0175\n",
      "Epoch: [98/num_epochs]Loss: 0.0171\n",
      "Epoch: [99/num_epochs]Loss: 0.0167\n",
      "Epoch: [100/num_epochs]Loss: 0.0164\n",
      "Epoch: [101/num_epochs]Loss: 0.0161\n",
      "Epoch: [102/num_epochs]Loss: 0.0157\n",
      "Epoch: [103/num_epochs]Loss: 0.0154\n",
      "Epoch: [104/num_epochs]Loss: 0.0151\n",
      "Epoch: [105/num_epochs]Loss: 0.0148\n",
      "Epoch: [106/num_epochs]Loss: 0.0146\n",
      "Epoch: [107/num_epochs]Loss: 0.0143\n",
      "Epoch: [108/num_epochs]Loss: 0.0140\n",
      "Epoch: [109/num_epochs]Loss: 0.0138\n",
      "Epoch: [110/num_epochs]Loss: 0.0135\n",
      "Epoch: [111/num_epochs]Loss: 0.0133\n",
      "Epoch: [112/num_epochs]Loss: 0.0131\n",
      "Epoch: [113/num_epochs]Loss: 0.0128\n",
      "Epoch: [114/num_epochs]Loss: 0.0126\n",
      "Epoch: [115/num_epochs]Loss: 0.0124\n",
      "Epoch: [116/num_epochs]Loss: 0.0122\n",
      "Epoch: [117/num_epochs]Loss: 0.0120\n",
      "Epoch: [118/num_epochs]Loss: 0.0118\n",
      "Epoch: [119/num_epochs]Loss: 0.0116\n",
      "Epoch: [120/num_epochs]Loss: 0.0115\n",
      "Epoch: [121/num_epochs]Loss: 0.0113\n",
      "Epoch: [122/num_epochs]Loss: 0.0111\n",
      "Epoch: [123/num_epochs]Loss: 0.0109\n",
      "Epoch: [124/num_epochs]Loss: 0.0108\n",
      "Epoch: [125/num_epochs]Loss: 0.0106\n",
      "Epoch: [126/num_epochs]Loss: 0.0105\n",
      "Epoch: [127/num_epochs]Loss: 0.0103\n",
      "Epoch: [128/num_epochs]Loss: 0.0102\n",
      "Epoch: [129/num_epochs]Loss: 0.0100\n",
      "Epoch: [130/num_epochs]Loss: 0.0099\n",
      "Epoch: [131/num_epochs]Loss: 0.0097\n",
      "Epoch: [132/num_epochs]Loss: 0.0096\n",
      "Epoch: [133/num_epochs]Loss: 0.0095\n",
      "Epoch: [134/num_epochs]Loss: 0.0094\n",
      "Epoch: [135/num_epochs]Loss: 0.0092\n",
      "Epoch: [136/num_epochs]Loss: 0.0091\n",
      "Epoch: [137/num_epochs]Loss: 0.0090\n",
      "Epoch: [138/num_epochs]Loss: 0.0089\n",
      "Epoch: [139/num_epochs]Loss: 0.0088\n",
      "Epoch: [140/num_epochs]Loss: 0.0087\n",
      "Epoch: [141/num_epochs]Loss: 0.0086\n",
      "Epoch: [142/num_epochs]Loss: 0.0084\n",
      "Epoch: [143/num_epochs]Loss: 0.0083\n",
      "Epoch: [144/num_epochs]Loss: 0.0082\n",
      "Epoch: [145/num_epochs]Loss: 0.0081\n",
      "Epoch: [146/num_epochs]Loss: 0.0081\n",
      "Epoch: [147/num_epochs]Loss: 0.0080\n",
      "Epoch: [148/num_epochs]Loss: 0.0079\n",
      "Epoch: [149/num_epochs]Loss: 0.0078\n",
      "Epoch: [150/num_epochs]Loss: 0.0077\n",
      "Epoch: [151/num_epochs]Loss: 0.0076\n",
      "Epoch: [152/num_epochs]Loss: 0.0075\n",
      "Epoch: [153/num_epochs]Loss: 0.0074\n",
      "Epoch: [154/num_epochs]Loss: 0.0074\n",
      "Epoch: [155/num_epochs]Loss: 0.0073\n",
      "Epoch: [156/num_epochs]Loss: 0.0072\n",
      "Epoch: [157/num_epochs]Loss: 0.0071\n",
      "Epoch: [158/num_epochs]Loss: 0.0070\n",
      "Epoch: [159/num_epochs]Loss: 0.0070\n",
      "Epoch: [160/num_epochs]Loss: 0.0069\n",
      "Epoch: [161/num_epochs]Loss: 0.0068\n",
      "Epoch: [162/num_epochs]Loss: 0.0068\n",
      "Epoch: [163/num_epochs]Loss: 0.0067\n",
      "Epoch: [164/num_epochs]Loss: 0.0066\n",
      "Epoch: [165/num_epochs]Loss: 0.0066\n",
      "Epoch: [166/num_epochs]Loss: 0.0065\n",
      "Epoch: [167/num_epochs]Loss: 0.0064\n",
      "Epoch: [168/num_epochs]Loss: 0.0064\n",
      "Epoch: [169/num_epochs]Loss: 0.0063\n",
      "Epoch: [170/num_epochs]Loss: 0.0062\n",
      "Epoch: [171/num_epochs]Loss: 0.0062\n",
      "Epoch: [172/num_epochs]Loss: 0.0061\n",
      "Epoch: [173/num_epochs]Loss: 0.0061\n",
      "Epoch: [174/num_epochs]Loss: 0.0060\n",
      "Epoch: [175/num_epochs]Loss: 0.0060\n",
      "Epoch: [176/num_epochs]Loss: 0.0059\n",
      "Epoch: [177/num_epochs]Loss: 0.0058\n",
      "Epoch: [178/num_epochs]Loss: 0.0058\n",
      "Epoch: [179/num_epochs]Loss: 0.0057\n",
      "Epoch: [180/num_epochs]Loss: 0.0057\n",
      "Epoch: [181/num_epochs]Loss: 0.0056\n",
      "Epoch: [182/num_epochs]Loss: 0.0056\n",
      "Epoch: [183/num_epochs]Loss: 0.0055\n",
      "Epoch: [184/num_epochs]Loss: 0.0055\n",
      "Epoch: [185/num_epochs]Loss: 0.0054\n",
      "Epoch: [186/num_epochs]Loss: 0.0054\n",
      "Epoch: [187/num_epochs]Loss: 0.0054\n",
      "Epoch: [188/num_epochs]Loss: 0.0053\n",
      "Epoch: [189/num_epochs]Loss: 0.0053\n",
      "Epoch: [190/num_epochs]Loss: 0.0052\n",
      "Epoch: [191/num_epochs]Loss: 0.0052\n",
      "Epoch: [192/num_epochs]Loss: 0.0051\n",
      "Epoch: [193/num_epochs]Loss: 0.0051\n",
      "Epoch: [194/num_epochs]Loss: 0.0051\n",
      "Epoch: [195/num_epochs]Loss: 0.0050\n",
      "Epoch: [196/num_epochs]Loss: 0.0050\n",
      "Epoch: [197/num_epochs]Loss: 0.0049\n",
      "Epoch: [198/num_epochs]Loss: 0.0049\n",
      "Epoch: [199/num_epochs]Loss: 0.0049\n",
      "Epoch: [200/num_epochs]Loss: 0.0048\n",
      "Epoch: [201/num_epochs]Loss: 0.0048\n",
      "Epoch: [202/num_epochs]Loss: 0.0048\n",
      "Epoch: [203/num_epochs]Loss: 0.0047\n",
      "Epoch: [204/num_epochs]Loss: 0.0047\n",
      "Epoch: [205/num_epochs]Loss: 0.0046\n",
      "Epoch: [206/num_epochs]Loss: 0.0046\n",
      "Epoch: [207/num_epochs]Loss: 0.0046\n",
      "Epoch: [208/num_epochs]Loss: 0.0045\n",
      "Epoch: [209/num_epochs]Loss: 0.0045\n",
      "Epoch: [210/num_epochs]Loss: 0.0045\n",
      "Epoch: [211/num_epochs]Loss: 0.0044\n",
      "Epoch: [212/num_epochs]Loss: 0.0044\n",
      "Epoch: [213/num_epochs]Loss: 0.0044\n",
      "Epoch: [214/num_epochs]Loss: 0.0044\n",
      "Epoch: [215/num_epochs]Loss: 0.0043\n",
      "Epoch: [216/num_epochs]Loss: 0.0043\n",
      "Epoch: [217/num_epochs]Loss: 0.0043\n",
      "Epoch: [218/num_epochs]Loss: 0.0042\n",
      "Epoch: [219/num_epochs]Loss: 0.0042\n",
      "Epoch: [220/num_epochs]Loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [221/num_epochs]Loss: 0.0041\n",
      "Epoch: [222/num_epochs]Loss: 0.0041\n",
      "Epoch: [223/num_epochs]Loss: 0.0041\n",
      "Epoch: [224/num_epochs]Loss: 0.0041\n",
      "Epoch: [225/num_epochs]Loss: 0.0040\n",
      "Epoch: [226/num_epochs]Loss: 0.0040\n",
      "Epoch: [227/num_epochs]Loss: 0.0040\n",
      "Epoch: [228/num_epochs]Loss: 0.0040\n",
      "Epoch: [229/num_epochs]Loss: 0.0039\n",
      "Epoch: [230/num_epochs]Loss: 0.0039\n",
      "Epoch: [231/num_epochs]Loss: 0.0039\n",
      "Epoch: [232/num_epochs]Loss: 0.0039\n",
      "Epoch: [233/num_epochs]Loss: 0.0038\n",
      "Epoch: [234/num_epochs]Loss: 0.0038\n",
      "Epoch: [235/num_epochs]Loss: 0.0038\n",
      "Epoch: [236/num_epochs]Loss: 0.0038\n",
      "Epoch: [237/num_epochs]Loss: 0.0037\n",
      "Epoch: [238/num_epochs]Loss: 0.0037\n",
      "Epoch: [239/num_epochs]Loss: 0.0037\n",
      "Epoch: [240/num_epochs]Loss: 0.0037\n",
      "Epoch: [241/num_epochs]Loss: 0.0036\n",
      "Epoch: [242/num_epochs]Loss: 0.0036\n",
      "Epoch: [243/num_epochs]Loss: 0.0036\n",
      "Epoch: [244/num_epochs]Loss: 0.0036\n",
      "Epoch: [245/num_epochs]Loss: 0.0036\n",
      "Epoch: [246/num_epochs]Loss: 0.0035\n",
      "Epoch: [247/num_epochs]Loss: 0.0035\n",
      "Epoch: [248/num_epochs]Loss: 0.0035\n",
      "Epoch: [249/num_epochs]Loss: 0.0035\n",
      "33\n",
      "tensor([1]) tensor([1])\n",
      "34\n",
      "tensor([1]) tensor([1])\n",
      "35\n",
      "tensor([0]) tensor([0])\n",
      "36\n",
      "tensor([1]) tensor([1])\n",
      "37\n",
      "tensor([1]) tensor([0])\n",
      "38\n",
      "tensor([1]) tensor([1])\n",
      "39\n",
      "tensor([1]) tensor([0])\n",
      "40\n",
      "tensor([0]) tensor([0])\n",
      "41\n",
      "tensor([0]) tensor([0])\n",
      "42\n",
      "tensor([1]) tensor([1])\n",
      "43\n",
      "tensor([0]) tensor([0])\n",
      "Accuracy of the network on the 11 test images: 81.81818181818181 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import time\n",
    "\n",
    "left_column = [\n",
    "#'Time',\n",
    "    'Distance','GPS Latitude','GPS Longitude','Damper Velocity (Calc) FL','Damper Velocity (Calc) FR','Damper Velocity (Calc) RL',\n",
    "'Damper Velocity (Calc) RR','Corr Dist','Corr Dist (Unstretched)','Corr Speed','Brake Pos',\n",
    "'CG Accel Lateral','CG Accel Longitudinal','CG Accel Vertical','CG Height','Camber FL','Camber FR','Camber RL','Camber RR','Car Coord X',\n",
    "'Car Coord Y','Car Coord Z','Car Pos Norm','Chassis Pitch Angle','Chassis Pitch Rate','Chassis Roll Angle','Chassis Roll Rate',\n",
    "'Chassis Velocity X','Chassis Velocity Y','Chassis Velocity Z','Chassis Yaw Rate','Drive Train Speed','Engine RPM','Ground Speed',\n",
    "'Ride Height FL','Ride Height FR','Ride Height RL','Ride Height RR','Road Temp','Self Align Torque FL','Self Align Torque FR',\n",
    "'Self Align Torque RL','Self Align Torque RR','Session Time Left','Steering Angle','Suspension Travel FL','Suspension Travel FR',\n",
    "'Suspension Travel RL','Suspension Travel RR','Tire Load FL','Tire Load FR','Tire Load RL','Tire Load RR','Tire Loaded Radius FL',\n",
    "'Tire Loaded Radius FR','Tire Loaded Radius RL','Tire Loaded Radius RR','Tire Pressure FL','Tire Pressure FR','Tire Pressure RL','Tire Pressure RR',\n",
    "'Tire Rubber Grip FL','Tire Rubber Grip FR','Tire Rubber Grip RL','Tire Rubber Grip RR','Tire Slip Angle FL','Tire Slip Angle FR',\n",
    "'Tire Slip Angle RL','Tire Slip Angle RR','Tire Slip Ratio FL','Tire Slip Ratio FR','Tire Slip Ratio RL','Tire Slip Ratio RR',\n",
    "'Tire Temp Core FL','Tire Temp Core FR','Tire Temp Core RL','Tire Temp Core RR','Tire Temp Inner FL','Tire Temp Inner FR',\n",
    "'Tire Temp Inner RL','Tire Temp Inner RR','Tire Temp Middle FL','Tire Temp Middle FR','Tire Temp Middle RL',\n",
    "'Tire Temp Middle RR','Tire Temp Outer FL','Tire Temp Outer FR','Tire Temp Outer RL','Tire Temp Outer RR','Toe In FL',\n",
    "'Toe In FR','Toe In RL','Toe In RR','Wheel Angular Speed FL','Wheel Angular Speed FR','Wheel Angular Speed RL','Wheel Angular Speed RR',\n",
    "'CG Distance','Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration','level']\n",
    "\n",
    "\n",
    "#Hyper-parameters\n",
    "num_epochs = 250\n",
    "batches = 10\n",
    "learning_rate = 0.003\n",
    "input_size = len(left_column)-1 # left column except 'level'\n",
    "output_size = 2 # Expert and Beginner\n",
    "hidden_size = 10 # ?\n",
    "num_layers = 2\n",
    "num_begin_train = round(num_begin*0.75)*(number_of_corner-start)\n",
    "num_exp_train = round(num_exp*0.75)*(number_of_corner-start)\n",
    "num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "\n",
    "print(num_begin_train, num_exp_train,num_begin_test,num_exp_test)\n",
    "aug = 1\n",
    "## Define GRU, Loss func and Optimizer\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.gru(x, h0)\n",
    "#         out, _ = self.lstm(x, (h0,c0)) \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "gru = GRU(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(gru.parameters(), lr=learning_rate)  \n",
    "\n",
    "gru.fc.weight.data.fill_(1)\n",
    "gru.fc.bias.data.fill_(1)\n",
    "print(gru.fc.weight,gru.fc.bias)\n",
    "\n",
    "## Data Processing\n",
    "array_x = []\n",
    "array_y = []\n",
    "input_x = []\n",
    "input_y = []\n",
    "n_row = []\n",
    "\n",
    "df_tmp_begin = pd.DataFrame() \n",
    "df_tmp_exp = pd.DataFrame() \n",
    "for curve_num in range(start,number_of_corner):\n",
    "    df_tmp_begin = pd.concat([df_tmp_begin,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_begin.csv')])\n",
    "    df_tmp_exp   = pd.concat([df_tmp_exp,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_expert.csv')])    \n",
    "df_curve1 = pd.concat([df_tmp_begin, df_tmp_exp], ignore_index=True) \n",
    "df_curve1 = df_curve1.loc[:,left_column]\n",
    "df_curve1_saved = df_curve1.loc[:,left_column] # data backup\n",
    "df_curve1.to_csv('cornerData/corner_'+'_dfcurve1'+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x)\n",
    "# scaler.mean_\n",
    "# x = scaler.transform(x)\n",
    "# print(x_normal)\n",
    "# # print(x)\n",
    "# # print(x['Distance'])\n",
    "# print(type(x))\n",
    "# print(type(x_normal))\n",
    "\n",
    "datum = df_curve1_saved\n",
    "yyy = datum.pop('level')\n",
    "left = left_column.remove('level')\n",
    "for i in range(0,num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "#     x = df_curve1_saved.loc[0:num_row[i]-1\n",
    "    y = yyy.loc[0:num_row[i]-1]\n",
    "    x_original = datum.loc[0:num_row[i]-1]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_original)\n",
    "    scaler.mean_\n",
    "    x_normal = scaler.transform(x_original)\n",
    "    x = pd.DataFrame(x_normal,columns=left)\n",
    "#     print(datum)\n",
    "#     print(i)\n",
    "#     print(num_row)\n",
    "#     print(num_row[i])\n",
    "    datum.drop(range(0,num_row[i]),inplace=True)\n",
    "    datum.reset_index(drop=True, inplace=True)\n",
    "    yyy.drop(range(0,num_row[i]),inplace=True)\n",
    "    yyy.reset_index(drop=True, inplace=True)\n",
    "    # y = x.pop('level')\n",
    "    \n",
    "#     # DATA Augmentation\n",
    "#     nan = pd.DataFrame(np.nan,columns=range(x.shape[1]),index=range(x.shape[0]))\n",
    "#     alter = pd.concat([x,nan]).sort_index()\n",
    "#     alter = alter.interpolate()\n",
    "#     alter.reset_index(drop=True, inplace=True)\n",
    "#     x_aug = alter[alter.index%2==1]\n",
    "\n",
    "    \n",
    "    array_x.append(x)\n",
    "#     array_x.append(x_aug)\n",
    "    array_y.append(y)\n",
    "#     array_y.append(y)\n",
    "\n",
    "    \n",
    "## Randomize sequence \n",
    "sequence = np.arange((num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug)\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(sequence)\n",
    "\n",
    "# sequence = [0,1,2,15,4,5,6,7,8,9,18,11,12,13,14,19,20,21,34,23,24,25,26,27,28,37,30,31,32,33,3,16,17,10,22,35,36,29]\n",
    "print(sequence)\n",
    "\n",
    "# # Data Augmentation\n",
    "# num_row = pd.Series(num_row)\n",
    "# num_row = num_row.repeat(2)\n",
    "# # sequence = pd.Series(sequence)\n",
    "# # sequence = sequence.repeat(2)\n",
    "# num_row.reset_index(drop=True, inplace=True)\n",
    "# # sequence.reset_index(drop=True, inplace=True)\n",
    "# print(num_row, sequence)\n",
    "\n",
    "for i in sequence:\n",
    "    input_x.append(array_x[i])\n",
    "    input_y.append(array_y[i])\n",
    "    n_row.append(num_row[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Train \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "test_list=[]\n",
    "count = 0\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "print((num_begin_train + num_exp_train)*aug)\n",
    "\n",
    "# start = time.time()  # 시작 시간 저장\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0,(num_begin_train + num_exp_train)*aug):\n",
    "        \n",
    "#         print(i)\n",
    "#         print(len(input_x))\n",
    "        # array type (numpy) 앞\n",
    "        X = np.array(input_x[i])\n",
    "        X = X.reshape(-1,n_row[i],input_size)\n",
    "        Y = np.array(input_y[i])   \n",
    "        \n",
    "        # tensor type (pytorch)\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        Y = torch.tensor([Y[0]])\n",
    "        Y = Y.type(torch.LongTensor)\n",
    "#         Y = Y.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = gru(X)\n",
    "        loss = criterion(output, Y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         count += 1\n",
    "#         loss_list.append(loss.data)\n",
    "#         iteration_list.append(count)\n",
    "#         accuracy_list.append(accuracy)\n",
    "#         print (f'Loss: {loss.item():.4f}')\n",
    "    count += 1\n",
    "    loss_list.append(loss.data)\n",
    "    iteration_list.append(count)\n",
    "    print (f'Epoch: [{epoch}/num_epochs]' f'Loss: {loss.item():.4f}')\n",
    "## Test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for i in range((num_begin_train + num_exp_train)*aug, (num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug):\n",
    "        \n",
    "        # array type (numpy)\n",
    "        print(i)\n",
    "        X = np.array(input_x[i])\n",
    "        X = X.reshape(-1,n_row[i],input_size)\n",
    "        Y = np.array(input_y[i])   \n",
    "\n",
    "        # tensor type (pytorch)\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        Y = torch.tensor([Y[0]])\n",
    "        Y = Y.type(torch.LongTensor)\n",
    "#         Y = Y.float()\n",
    "        output = gru(X)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        n_samples += Y.size(0)\n",
    "        n_correct += (predicted == Y).sum().item()\n",
    "        print(Y, predicted)\n",
    "        \n",
    "\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {(num_begin_test + num_exp_test)*aug} test images: {acc} %')\n",
    "#     print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 11 test images: 81.81818181818181 %\n",
      "tensor([0]) tensor([0]) tensor([[8.5634, 2.1933]])\n"
     ]
    }
   ],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "print(f'Accuracy of the network on the {num_begin_test + num_exp_test} test images: {acc} %')\n",
    "print(predicted, Y, output)\n",
    "# print(iteration_list)\n",
    "# # visualization accuracy \n",
    "# plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "# plt.savefig('graph.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "food = 'bread'\n",
    "vars()['cat'] = 123\n",
    "print(cat)\n",
    "print(type(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame() \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     1.0\n",
       "2     5.5\n",
       "3    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([0, 1, np.nan, 10])\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread\n"
     ]
    }
   ],
   "source": [
    "print(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \\\n",
      "0   -1.939161  2.419064 -1.456527 -2.844837 -0.616704  0.059867  1.066608   \n",
      "2   -1.862023  2.298240 -1.427066  1.342429  0.564276 -1.030766 -1.424866   \n",
      "4   -1.788239  2.187168 -1.399030  0.411926  0.917171  0.798914 -0.055242   \n",
      "6   -1.717808  2.065260 -1.367193  1.350688  0.399389  0.603269  1.660401   \n",
      "8   -1.644024  1.953105 -1.335831 -1.460093 -0.915447  0.373184  0.221428   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "134  1.414660 -0.792619  1.631987  0.626963  0.902568 -0.676310 -0.123867   \n",
      "136  1.449875 -0.773294  1.678238  0.398620  0.198605  0.140468  0.426222   \n",
      "138  1.491798 -0.748100  1.732884 -0.419012 -0.400403  0.615706  1.008457   \n",
      "140  1.532044 -0.721822  1.784916 -0.807181 -0.473112  0.426998  0.497737   \n",
      "142  1.592413 -0.681186  1.859282 -0.098291  0.092736 -0.429005 -0.240170   \n",
      "\n",
      "          7         8         9    ...       92        93        94   \\\n",
      "0   -1.937520 -1.948490  2.625023  ...  0.072190  2.589704  2.792199   \n",
      "2   -1.863738 -1.847827  2.500819  ...  1.227224  3.045647  2.946045   \n",
      "4   -1.789956 -1.780718  2.362815  ...  0.649707  2.604688  2.796513   \n",
      "6   -1.716174 -1.713609  2.183409  ... -0.505328  2.503367  2.682925   \n",
      "8   -1.645746 -1.646500  2.040804  ... -1.660363  1.804825  1.985584   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "134  1.416202  1.418143 -0.898690  ...  0.072190 -0.853060 -0.943487   \n",
      "136  1.449739  1.457290 -0.914790  ... -0.505328 -0.840930 -0.915210   \n",
      "138  1.489984  1.490844 -0.928591  ... -1.082845 -0.828800 -0.919883   \n",
      "140  1.530229  1.524399 -0.940091  ... -1.371604 -0.824519 -0.958704   \n",
      "142  1.590596  1.608285 -0.949292  ... -1.082845 -0.824519 -0.982787   \n",
      "\n",
      "          95        96        97        98        99        100       101  \n",
      "0    2.996786  2.899331 -0.417685  2.025898 -1.616804 -0.379193  0.257369  \n",
      "2    1.461067  2.747900  0.345582  1.862180 -1.638599 -0.547376  0.147068  \n",
      "4    2.687463  2.386628  1.217205  1.877772 -1.529622  0.742034  1.029474  \n",
      "6    2.663153  2.396723  1.169822  1.893364 -1.377053 -1.276174  0.036767  \n",
      "8    2.797277  2.225822  0.422403  1.628298 -1.464235 -2.509523 -1.066241  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "134 -0.553587 -0.744157 -0.111251 -0.827467  0.846090  1.321334 -0.808873  \n",
      "136 -0.599832 -0.751248  0.369910 -0.780691  0.780704  1.246586 -1.507445  \n",
      "138 -0.767068 -0.980919  0.392356 -0.733914  0.617237  1.022340 -2.279550  \n",
      "140 -0.826166 -1.077547 -0.116352 -0.710526  0.388384  1.022340 -1.783197  \n",
      "142 -0.832454 -0.941980 -0.256480 -0.624769  0.366589  1.639015  0.588271  \n",
      "\n",
      "[72 rows x 102 columns]\n",
      "          0         1         2         3         4         5         6    \\\n",
      "1   -1.900592  2.358652 -1.441796 -0.751204 -0.026214 -0.485450 -0.179129   \n",
      "3   -1.825131  2.242704 -1.413048  0.877177  0.740724 -0.115926 -0.740054   \n",
      "5   -1.753023  2.126214 -1.383111  0.881307  0.658280  0.701092  0.802580   \n",
      "7   -1.680916  2.009183 -1.351512 -0.054703 -0.258029  0.488227  0.940915   \n",
      "9   -1.610486  1.901362 -1.320863 -1.502764 -1.173729 -0.000644  0.031082   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "135  1.428076 -0.785214  1.650678  0.252254  0.594090 -0.605515 -0.242337   \n",
      "137  1.471675 -0.761374  1.705798  0.544986 -0.196881  0.886451  1.094781   \n",
      "139  1.511921 -0.734825  1.759969 -1.383010 -0.603926  0.344962  0.922133   \n",
      "141  1.552167 -0.708818  1.809863 -0.231351 -0.342298  0.509035  0.073341   \n",
      "143  1.592413 -0.681186  1.859282 -0.098291  0.092736 -0.429005 -0.240170   \n",
      "\n",
      "          7         8         9    ...       92        93        94   \\\n",
      "1   -1.900629 -1.898158  2.562921  ...  0.649707  2.817676  2.869122   \n",
      "3   -1.826847 -1.814272  2.431817  ...  0.938466  2.825168  2.871279   \n",
      "5   -1.753065 -1.747163  2.273112  ...  0.072190  2.554028  2.739719   \n",
      "7   -1.680960 -1.680054  2.112107  ... -1.082845  2.154096  2.334255   \n",
      "9   -1.610532 -1.612945  1.990203  ... -1.082845  1.984634  1.933463   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "135  1.429617  1.440513 -0.907890  ...  0.072190 -0.848779 -0.926712   \n",
      "137  1.469862  1.474067 -0.921691  ... -1.082845 -0.833082 -0.903707   \n",
      "139  1.510106  1.507622 -0.935491  ... -1.082845 -0.824519 -0.936058   \n",
      "141  1.550351  1.541176 -0.944691  ... -1.660363 -0.824519 -0.981349   \n",
      "143  1.590596  1.608285 -0.949292  ... -1.082845 -0.824519 -0.982787   \n",
      "\n",
      "          95        96        97        98        99        100       101  \n",
      "1    2.228926  2.823615 -0.036051  1.944039 -1.627702 -0.463285  0.202218  \n",
      "3    2.074265  2.567264  0.781394  1.869976 -1.584111  0.097329  0.588271  \n",
      "5    2.675308  2.391675  1.193514  1.885568 -1.453338 -0.267070  0.533121  \n",
      "7    2.730215  2.311272  0.796112  1.760831 -1.420644 -1.892848 -0.514737  \n",
      "9    2.612437  2.088091  0.296277  1.550337 -1.496929 -1.444358 -0.569888  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "135 -0.476187 -0.654260 -0.105650 -0.811875  0.824295  1.302647 -1.066241  \n",
      "137 -0.723478 -0.848236  0.845470 -0.749506  0.737112  1.190524 -1.948648  \n",
      "139 -0.810658 -1.113602 -0.060758 -0.718322  0.497362  0.854156 -2.610453  \n",
      "141 -0.841675 -1.041492 -0.171946 -0.702730  0.279406  1.190524 -0.955940  \n",
      "143 -0.832454 -0.941980 -0.256480 -0.624769  0.366589  1.639015  0.588271  \n",
      "\n",
      "[72 rows x 102 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(x)\n",
    "x.shape\n",
    "nan = pd.DataFrame(np.nan,columns=range(x.shape[1]),index=range(x.shape[0]))\n",
    "alter = pd.concat([x,nan]).sort_index()\n",
    "alter = alter.interpolate()\n",
    "alter.reset_index(drop=True, inplace=True)\n",
    "print(alter[alter.index%2==0])\n",
    "print(alter[alter.index%2==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Distance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-abb11a84e6cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ssdkms\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ssdkms\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Distance'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "print(x['Distance'])\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(x))\n",
    "print(scaler.mean_)\n",
    "# print(scaler.transform(x))\n",
    "x_normal = scaler.transform(x)\n",
    "print(x_normal)\n",
    "# print(x)\n",
    "# print(x['Distance'])\n",
    "print(type(x))\n",
    "print(type(x_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f\n",
    "print(gru.fc.weight,gru.fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "a = np.array([1,2,3])\n",
    "a = pd.DataFrame([1,2,3])\n",
    "print(a)\n",
    "# a.repeat(2)\n",
    "# np.array(num_row).repeat(2)\n",
    "# num_row = pd.Series(num_row)\n",
    "# num_row.repeat(2)\n",
    "print(num_row)\n",
    "type(num_row)\n",
    "abc = pd.Series(num_row)\n",
    "abc.repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_begin_train = round(num_begin*0.75)*(number_of_corner-start)\n",
    "num_exp_train = round(num_exp*0.75)*(number_of_corner-start)\n",
    "num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "# print(num_begin_train, num_exp_train,num_begin_test,num_exp_test)\n",
    "num_begin_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
