{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5b9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16885f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6354de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72]\n",
      "102\n",
      "[74]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.8024\n",
      "Epoch: [1/120]Loss: 0.6172\n",
      "Epoch: [2/120]Loss: 0.4551\n",
      "Epoch: [3/120]Loss: 0.2985\n",
      "Epoch: [4/120]Loss: 0.1937\n",
      "Epoch: [5/120]Loss: 0.1250\n",
      "Epoch: [6/120]Loss: 0.0734\n",
      "Epoch: [7/120]Loss: 0.0384\n",
      "Epoch: [8/120]Loss: 0.0201\n",
      "Epoch: [9/120]Loss: 0.0110\n",
      "Epoch: [10/120]Loss: 0.0037\n",
      "Epoch: [11/120]Loss: 0.0023\n",
      "Epoch: [12/120]Loss: 0.0018\n",
      "Epoch: [13/120]Loss: 0.0015\n",
      "Epoch: [14/120]Loss: 0.0012\n",
      "Epoch: [15/120]Loss: 0.0011\n",
      "Epoch: [16/120]Loss: 0.0010\n",
      "Epoch: [17/120]Loss: 0.0008\n",
      "Epoch: [18/120]Loss: 0.0008\n",
      "Epoch: [19/120]Loss: 0.0007\n",
      "Epoch: [20/120]Loss: 0.0006\n",
      "Epoch: [21/120]Loss: 0.0006\n",
      "Epoch: [22/120]Loss: 0.0005\n",
      "Epoch: [23/120]Loss: 0.0005\n",
      "Epoch: [24/120]Loss: 0.0005\n",
      "Epoch: [25/120]Loss: 0.0004\n",
      "Epoch: [26/120]Loss: 0.0004\n",
      "Epoch: [27/120]Loss: 0.0004\n",
      "Epoch: [28/120]Loss: 0.0003\n",
      "Epoch: [29/120]Loss: 0.0003\n",
      "Epoch: [30/120]Loss: 0.0003\n",
      "Epoch: [31/120]Loss: 0.0003\n",
      "Epoch: [32/120]Loss: 0.0003\n",
      "Epoch: [33/120]Loss: 0.0003\n",
      "Epoch: [34/120]Loss: 0.0003\n",
      "Epoch: [35/120]Loss: 0.0002\n",
      "Epoch: [36/120]Loss: 0.0002\n",
      "Epoch: [37/120]Loss: 0.0002\n",
      "Epoch: [38/120]Loss: 0.0002\n",
      "Epoch: [39/120]Loss: 0.0002\n",
      "Epoch: [40/120]Loss: 0.0002\n",
      "Epoch: [41/120]Loss: 0.0002\n",
      "Epoch: [42/120]Loss: 0.0002\n",
      "Epoch: [43/120]Loss: 0.0002\n",
      "Epoch: [44/120]Loss: 0.0002\n",
      "Epoch: [45/120]Loss: 0.0002\n",
      "Epoch: [46/120]Loss: 0.0002\n",
      "Epoch: [47/120]Loss: 0.0001\n",
      "Epoch: [48/120]Loss: 0.0001\n",
      "Epoch: [49/120]Loss: 0.0001\n",
      "Epoch: [50/120]Loss: 0.0001\n",
      "Epoch: [51/120]Loss: 0.0001\n",
      "Epoch: [52/120]Loss: 0.0001\n",
      "Epoch: [53/120]Loss: 0.0001\n",
      "Epoch: [54/120]Loss: 0.0001\n",
      "Epoch: [55/120]Loss: 0.0001\n",
      "Epoch: [56/120]Loss: 0.0001\n",
      "Epoch: [57/120]Loss: 0.0001\n",
      "Epoch: [58/120]Loss: 0.0001\n",
      "Epoch: [59/120]Loss: 0.0001\n",
      "Epoch: [60/120]Loss: 0.0001\n",
      "Epoch: [61/120]Loss: 0.0001\n",
      "Epoch: [62/120]Loss: 0.0001\n",
      "Epoch: [63/120]Loss: 0.0001\n",
      "Epoch: [64/120]Loss: 0.0001\n",
      "Epoch: [65/120]Loss: 0.0001\n",
      "Epoch: [66/120]Loss: 0.0001\n",
      "Epoch: [67/120]Loss: 0.0001\n",
      "Epoch: [68/120]Loss: 0.0001\n",
      "Epoch: [69/120]Loss: 0.0001\n",
      "Epoch: [70/120]Loss: 0.0001\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0000\n",
      "Epoch: [89/120]Loss: 0.0000\n",
      "Epoch: [90/120]Loss: 0.0000\n",
      "Epoch: [91/120]Loss: 0.0000\n",
      "Epoch: [92/120]Loss: 0.0000\n",
      "Epoch: [93/120]Loss: 0.0000\n",
      "Epoch: [94/120]Loss: 0.0000\n",
      "Epoch: [95/120]Loss: 0.0000\n",
      "Epoch: [96/120]Loss: 0.0000\n",
      "Epoch: [97/120]Loss: 0.0000\n",
      "Epoch: [98/120]Loss: 0.0000\n",
      "Epoch: [99/120]Loss: 0.0000\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0000\n",
      "51 <class 'numpy.int32'>\n",
      "[46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43]\n",
      "69\n",
      "[51]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.8271\n",
      "Epoch: [1/120]Loss: 0.6247\n",
      "Epoch: [2/120]Loss: 0.5794\n",
      "Epoch: [3/120]Loss: 0.5274\n",
      "Epoch: [4/120]Loss: 0.4680\n",
      "Epoch: [5/120]Loss: 0.4067\n",
      "Epoch: [6/120]Loss: 0.3434\n",
      "Epoch: [7/120]Loss: 0.2852\n",
      "Epoch: [8/120]Loss: 0.2232\n",
      "Epoch: [9/120]Loss: 0.1691\n",
      "Epoch: [10/120]Loss: 0.0800\n",
      "Epoch: [11/120]Loss: 0.0445\n",
      "Epoch: [12/120]Loss: 0.0263\n",
      "Epoch: [13/120]Loss: 0.0626\n",
      "Epoch: [14/120]Loss: 0.3292\n",
      "Epoch: [15/120]Loss: 0.1133\n",
      "Epoch: [16/120]Loss: 0.0405\n",
      "Epoch: [17/120]Loss: 0.0174\n",
      "Epoch: [18/120]Loss: 0.0095\n",
      "Epoch: [19/120]Loss: 0.0060\n",
      "Epoch: [20/120]Loss: 0.0043\n",
      "Epoch: [21/120]Loss: 0.0034\n",
      "Epoch: [22/120]Loss: 0.0028\n",
      "Epoch: [23/120]Loss: 0.0023\n",
      "Epoch: [24/120]Loss: 0.0020\n",
      "Epoch: [25/120]Loss: 0.0018\n",
      "Epoch: [26/120]Loss: 0.0016\n",
      "Epoch: [27/120]Loss: 0.0014\n",
      "Epoch: [28/120]Loss: 0.0013\n",
      "Epoch: [29/120]Loss: 0.0012\n",
      "Epoch: [30/120]Loss: 0.0011\n",
      "Epoch: [31/120]Loss: 0.0010\n",
      "Epoch: [32/120]Loss: 0.0009\n",
      "Epoch: [33/120]Loss: 0.0008\n",
      "Epoch: [34/120]Loss: 0.0008\n",
      "Epoch: [35/120]Loss: 0.0007\n",
      "Epoch: [36/120]Loss: 0.0007\n",
      "Epoch: [37/120]Loss: 0.0007\n",
      "Epoch: [38/120]Loss: 0.0006\n",
      "Epoch: [39/120]Loss: 0.0006\n",
      "Epoch: [40/120]Loss: 0.0006\n",
      "Epoch: [41/120]Loss: 0.0005\n",
      "Epoch: [42/120]Loss: 0.0005\n",
      "Epoch: [43/120]Loss: 0.0005\n",
      "Epoch: [44/120]Loss: 0.0005\n",
      "Epoch: [45/120]Loss: 0.0004\n",
      "Epoch: [46/120]Loss: 0.0004\n",
      "Epoch: [47/120]Loss: 0.0004\n",
      "Epoch: [48/120]Loss: 0.0004\n",
      "Epoch: [49/120]Loss: 0.0004\n",
      "Epoch: [50/120]Loss: 0.0004\n",
      "Epoch: [51/120]Loss: 0.0003\n",
      "Epoch: [52/120]Loss: 0.0003\n",
      "Epoch: [53/120]Loss: 0.0003\n",
      "Epoch: [54/120]Loss: 0.0003\n",
      "Epoch: [55/120]Loss: 0.0003\n",
      "Epoch: [56/120]Loss: 0.0003\n",
      "Epoch: [57/120]Loss: 0.0003\n",
      "Epoch: [58/120]Loss: 0.0003\n",
      "Epoch: [59/120]Loss: 0.0003\n",
      "Epoch: [60/120]Loss: 0.0002\n",
      "Epoch: [61/120]Loss: 0.0002\n",
      "Epoch: [62/120]Loss: 0.0002\n",
      "Epoch: [63/120]Loss: 0.0002\n",
      "Epoch: [64/120]Loss: 0.0002\n",
      "Epoch: [65/120]Loss: 0.0002\n",
      "Epoch: [66/120]Loss: 0.0002\n",
      "Epoch: [67/120]Loss: 0.0002\n",
      "Epoch: [68/120]Loss: 0.0002\n",
      "Epoch: [69/120]Loss: 0.0002\n",
      "Epoch: [70/120]Loss: 0.0002\n",
      "Epoch: [71/120]Loss: 0.0002\n",
      "Epoch: [72/120]Loss: 0.0002\n",
      "Epoch: [73/120]Loss: 0.0002\n",
      "Epoch: [74/120]Loss: 0.0002\n",
      "Epoch: [75/120]Loss: 0.0002\n",
      "Epoch: [76/120]Loss: 0.0002\n",
      "Epoch: [77/120]Loss: 0.0002\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0001\n",
      "Epoch: [101/120]Loss: 0.0001\n",
      "Epoch: [102/120]Loss: 0.0001\n",
      "Epoch: [103/120]Loss: 0.0001\n",
      "Epoch: [104/120]Loss: 0.0001\n",
      "Epoch: [105/120]Loss: 0.0001\n",
      "Epoch: [106/120]Loss: 0.0001\n",
      "Epoch: [107/120]Loss: 0.0001\n",
      "Epoch: [108/120]Loss: 0.0001\n",
      "Epoch: [109/120]Loss: 0.0001\n",
      "Epoch: [110/120]Loss: 0.0001\n",
      "Epoch: [111/120]Loss: 0.0001\n",
      "Epoch: [112/120]Loss: 0.0001\n",
      "Epoch: [113/120]Loss: 0.0001\n",
      "Epoch: [114/120]Loss: 0.0001\n",
      "Epoch: [115/120]Loss: 0.0001\n",
      "Epoch: [116/120]Loss: 0.0001\n",
      "Epoch: [117/120]Loss: 0.0001\n",
      "Epoch: [118/120]Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [119/120]Loss: 0.0001\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 92.85714285714286 %\n",
      "Loss: 0.0001\n",
      "112 <class 'numpy.int32'>\n",
      "[492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76]\n",
      "833\n",
      "[112]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.7892\n",
      "Epoch: [1/120]Loss: 0.4401\n",
      "Epoch: [2/120]Loss: 0.2046\n",
      "Epoch: [3/120]Loss: 0.4737\n",
      "Epoch: [4/120]Loss: 0.4372\n",
      "Epoch: [5/120]Loss: 0.2571\n",
      "Epoch: [6/120]Loss: 0.1727\n",
      "Epoch: [7/120]Loss: 0.1461\n",
      "Epoch: [8/120]Loss: 0.1349\n",
      "Epoch: [9/120]Loss: 0.1379\n",
      "Epoch: [10/120]Loss: 0.1366\n",
      "Epoch: [11/120]Loss: 0.1344\n",
      "Epoch: [12/120]Loss: 0.1332\n",
      "Epoch: [13/120]Loss: 0.1328\n",
      "Epoch: [14/120]Loss: 0.1301\n",
      "Epoch: [15/120]Loss: 0.1301\n",
      "Epoch: [16/120]Loss: 0.1225\n",
      "Epoch: [17/120]Loss: 0.1244\n",
      "Epoch: [18/120]Loss: 0.1074\n",
      "Epoch: [19/120]Loss: 0.1156\n",
      "Epoch: [20/120]Loss: 0.1088\n",
      "Epoch: [21/120]Loss: 0.1431\n",
      "Epoch: [22/120]Loss: 0.1385\n",
      "Epoch: [23/120]Loss: 0.1254\n",
      "Epoch: [24/120]Loss: 0.1166\n",
      "Epoch: [25/120]Loss: 0.0697\n",
      "Epoch: [26/120]Loss: 0.0420\n",
      "Epoch: [27/120]Loss: 0.0998\n",
      "Epoch: [28/120]Loss: 0.1387\n",
      "Epoch: [29/120]Loss: 0.1269\n",
      "Epoch: [30/120]Loss: 0.1133\n",
      "Epoch: [31/120]Loss: 0.0904\n",
      "Epoch: [32/120]Loss: 0.0410\n",
      "Epoch: [33/120]Loss: 0.0178\n",
      "Epoch: [34/120]Loss: 0.0126\n",
      "Epoch: [35/120]Loss: 0.0099\n",
      "Epoch: [36/120]Loss: 0.0081\n",
      "Epoch: [37/120]Loss: 0.0068\n",
      "Epoch: [38/120]Loss: 0.0059\n",
      "Epoch: [39/120]Loss: 0.0051\n",
      "Epoch: [40/120]Loss: 0.0045\n",
      "Epoch: [41/120]Loss: 0.0040\n",
      "Epoch: [42/120]Loss: 0.0036\n",
      "Epoch: [43/120]Loss: 0.0033\n",
      "Epoch: [44/120]Loss: 0.0030\n",
      "Epoch: [45/120]Loss: 0.0028\n",
      "Epoch: [46/120]Loss: 0.0025\n",
      "Epoch: [47/120]Loss: 0.0024\n",
      "Epoch: [48/120]Loss: 0.0022\n",
      "Epoch: [49/120]Loss: 0.0020\n",
      "Epoch: [50/120]Loss: 0.0019\n",
      "Epoch: [51/120]Loss: 0.0018\n",
      "Epoch: [52/120]Loss: 0.0017\n",
      "Epoch: [53/120]Loss: 0.0016\n",
      "Epoch: [54/120]Loss: 0.0015\n",
      "Epoch: [55/120]Loss: 0.0014\n",
      "Epoch: [56/120]Loss: 0.0014\n",
      "Epoch: [57/120]Loss: 0.0013\n",
      "Epoch: [58/120]Loss: 0.0012\n",
      "Epoch: [59/120]Loss: 0.0012\n",
      "Epoch: [60/120]Loss: 0.0011\n",
      "Epoch: [61/120]Loss: 0.0011\n",
      "Epoch: [62/120]Loss: 0.0010\n",
      "Epoch: [63/120]Loss: 0.0010\n",
      "Epoch: [64/120]Loss: 0.0009\n",
      "Epoch: [65/120]Loss: 0.0009\n",
      "Epoch: [66/120]Loss: 0.0009\n",
      "Epoch: [67/120]Loss: 0.0008\n",
      "Epoch: [68/120]Loss: 0.0008\n",
      "Epoch: [69/120]Loss: 0.0008\n",
      "Epoch: [70/120]Loss: 0.0008\n",
      "Epoch: [71/120]Loss: 0.0007\n",
      "Epoch: [72/120]Loss: 0.0007\n",
      "Epoch: [73/120]Loss: 0.0007\n",
      "Epoch: [74/120]Loss: 0.0007\n",
      "Epoch: [75/120]Loss: 0.0006\n",
      "Epoch: [76/120]Loss: 0.0006\n",
      "Epoch: [77/120]Loss: 0.0006\n",
      "Epoch: [78/120]Loss: 0.0006\n",
      "Epoch: [79/120]Loss: 0.0006\n",
      "Epoch: [80/120]Loss: 0.0006\n",
      "Epoch: [81/120]Loss: 0.0005\n",
      "Epoch: [82/120]Loss: 0.0005\n",
      "Epoch: [83/120]Loss: 0.0005\n",
      "Epoch: [84/120]Loss: 0.0005\n",
      "Epoch: [85/120]Loss: 0.0005\n",
      "Epoch: [86/120]Loss: 0.0005\n",
      "Epoch: [87/120]Loss: 0.0005\n",
      "Epoch: [88/120]Loss: 0.0004\n",
      "Epoch: [89/120]Loss: 0.0004\n",
      "Epoch: [90/120]Loss: 0.0004\n",
      "Epoch: [91/120]Loss: 0.0004\n",
      "Epoch: [92/120]Loss: 0.0004\n",
      "Epoch: [93/120]Loss: 0.0004\n",
      "Epoch: [94/120]Loss: 0.0004\n",
      "Epoch: [95/120]Loss: 0.0004\n",
      "Epoch: [96/120]Loss: 0.0004\n",
      "Epoch: [97/120]Loss: 0.0004\n",
      "Epoch: [98/120]Loss: 0.0003\n",
      "Epoch: [99/120]Loss: 0.0003\n",
      "Epoch: [100/120]Loss: 0.0003\n",
      "Epoch: [101/120]Loss: 0.0003\n",
      "Epoch: [102/120]Loss: 0.0003\n",
      "Epoch: [103/120]Loss: 0.0003\n",
      "Epoch: [104/120]Loss: 0.0003\n",
      "Epoch: [105/120]Loss: 0.0003\n",
      "Epoch: [106/120]Loss: 0.0003\n",
      "Epoch: [107/120]Loss: 0.0003\n",
      "Epoch: [108/120]Loss: 0.0003\n",
      "Epoch: [109/120]Loss: 0.0003\n",
      "Epoch: [110/120]Loss: 0.0003\n",
      "Epoch: [111/120]Loss: 0.0003\n",
      "Epoch: [112/120]Loss: 0.0003\n",
      "Epoch: [113/120]Loss: 0.0002\n",
      "Epoch: [114/120]Loss: 0.0002\n",
      "Epoch: [115/120]Loss: 0.0002\n",
      "Epoch: [116/120]Loss: 0.0002\n",
      "Epoch: [117/120]Loss: 0.0002\n",
      "Epoch: [118/120]Loss: 0.0002\n",
      "Epoch: [119/120]Loss: 0.0002\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0002\n",
      "98 <class 'numpy.int32'>\n",
      "[111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84]\n",
      "140\n",
      "[98]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.6832\n",
      "Epoch: [1/120]Loss: 0.3929\n",
      "Epoch: [2/120]Loss: 0.1710\n",
      "Epoch: [3/120]Loss: 0.0577\n",
      "Epoch: [4/120]Loss: 0.0285\n",
      "Epoch: [5/120]Loss: 0.0153\n",
      "Epoch: [6/120]Loss: 0.0071\n",
      "Epoch: [7/120]Loss: 0.0035\n",
      "Epoch: [8/120]Loss: 0.0023\n",
      "Epoch: [9/120]Loss: 0.0019\n",
      "Epoch: [10/120]Loss: 0.0017\n",
      "Epoch: [11/120]Loss: 0.0015\n",
      "Epoch: [12/120]Loss: 0.0014\n",
      "Epoch: [13/120]Loss: 0.0013\n",
      "Epoch: [14/120]Loss: 0.0011\n",
      "Epoch: [15/120]Loss: 0.0011\n",
      "Epoch: [16/120]Loss: 0.0010\n",
      "Epoch: [17/120]Loss: 0.0009\n",
      "Epoch: [18/120]Loss: 0.0008\n",
      "Epoch: [19/120]Loss: 0.0008\n",
      "Epoch: [20/120]Loss: 0.0007\n",
      "Epoch: [21/120]Loss: 0.0007\n",
      "Epoch: [22/120]Loss: 0.0006\n",
      "Epoch: [23/120]Loss: 0.0006\n",
      "Epoch: [24/120]Loss: 0.0006\n",
      "Epoch: [25/120]Loss: 0.0005\n",
      "Epoch: [26/120]Loss: 0.0005\n",
      "Epoch: [27/120]Loss: 0.0005\n",
      "Epoch: [28/120]Loss: 0.0005\n",
      "Epoch: [29/120]Loss: 0.0004\n",
      "Epoch: [30/120]Loss: 0.0004\n",
      "Epoch: [31/120]Loss: 0.0004\n",
      "Epoch: [32/120]Loss: 0.0004\n",
      "Epoch: [33/120]Loss: 0.0004\n",
      "Epoch: [34/120]Loss: 0.0004\n",
      "Epoch: [35/120]Loss: 0.0003\n",
      "Epoch: [36/120]Loss: 0.0003\n",
      "Epoch: [37/120]Loss: 0.0003\n",
      "Epoch: [38/120]Loss: 0.0003\n",
      "Epoch: [39/120]Loss: 0.0003\n",
      "Epoch: [40/120]Loss: 0.0003\n",
      "Epoch: [41/120]Loss: 0.0003\n",
      "Epoch: [42/120]Loss: 0.0003\n",
      "Epoch: [43/120]Loss: 0.0003\n",
      "Epoch: [44/120]Loss: 0.0002\n",
      "Epoch: [45/120]Loss: 0.0002\n",
      "Epoch: [46/120]Loss: 0.0002\n",
      "Epoch: [47/120]Loss: 0.0002\n",
      "Epoch: [48/120]Loss: 0.0002\n",
      "Epoch: [49/120]Loss: 0.0002\n",
      "Epoch: [50/120]Loss: 0.0002\n",
      "Epoch: [51/120]Loss: 0.0002\n",
      "Epoch: [52/120]Loss: 0.0002\n",
      "Epoch: [53/120]Loss: 0.0002\n",
      "Epoch: [54/120]Loss: 0.0002\n",
      "Epoch: [55/120]Loss: 0.0002\n",
      "Epoch: [56/120]Loss: 0.0002\n",
      "Epoch: [57/120]Loss: 0.0002\n",
      "Epoch: [58/120]Loss: 0.0002\n",
      "Epoch: [59/120]Loss: 0.0002\n",
      "Epoch: [60/120]Loss: 0.0002\n",
      "Epoch: [61/120]Loss: 0.0001\n",
      "Epoch: [62/120]Loss: 0.0001\n",
      "Epoch: [63/120]Loss: 0.0001\n",
      "Epoch: [64/120]Loss: 0.0001\n",
      "Epoch: [65/120]Loss: 0.0001\n",
      "Epoch: [66/120]Loss: 0.0001\n",
      "Epoch: [67/120]Loss: 0.0001\n",
      "Epoch: [68/120]Loss: 0.0001\n",
      "Epoch: [69/120]Loss: 0.0001\n",
      "Epoch: [70/120]Loss: 0.0001\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [101/120]Loss: 0.0001\n",
      "Epoch: [102/120]Loss: 0.0001\n",
      "Epoch: [103/120]Loss: 0.0001\n",
      "Epoch: [104/120]Loss: 0.0001\n",
      "Epoch: [105/120]Loss: 0.0001\n",
      "Epoch: [106/120]Loss: 0.0001\n",
      "Epoch: [107/120]Loss: 0.0001\n",
      "Epoch: [108/120]Loss: 0.0001\n",
      "Epoch: [109/120]Loss: 0.0001\n",
      "Epoch: [110/120]Loss: 0.0001\n",
      "Epoch: [111/120]Loss: 0.0001\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 100.0 %\n",
      "Loss: 0.0000\n",
      "29 <class 'numpy.int32'>\n",
      "[28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25]\n",
      "41\n",
      "[29]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.8663\n",
      "Epoch: [1/120]Loss: 0.5870\n",
      "Epoch: [2/120]Loss: 0.3556\n",
      "Epoch: [3/120]Loss: 0.1821\n",
      "Epoch: [4/120]Loss: 0.1008\n",
      "Epoch: [5/120]Loss: 0.0500\n",
      "Epoch: [6/120]Loss: 0.0183\n",
      "Epoch: [7/120]Loss: 0.0065\n",
      "Epoch: [8/120]Loss: 0.0038\n",
      "Epoch: [9/120]Loss: 0.0026\n",
      "Epoch: [10/120]Loss: 0.0021\n",
      "Epoch: [11/120]Loss: 0.0017\n",
      "Epoch: [12/120]Loss: 0.0014\n",
      "Epoch: [13/120]Loss: 0.0012\n",
      "Epoch: [14/120]Loss: 0.0011\n",
      "Epoch: [15/120]Loss: 0.0010\n",
      "Epoch: [16/120]Loss: 0.0009\n",
      "Epoch: [17/120]Loss: 0.0008\n",
      "Epoch: [18/120]Loss: 0.0007\n",
      "Epoch: [19/120]Loss: 0.0007\n",
      "Epoch: [20/120]Loss: 0.0006\n",
      "Epoch: [21/120]Loss: 0.0006\n",
      "Epoch: [22/120]Loss: 0.0005\n",
      "Epoch: [23/120]Loss: 0.0005\n",
      "Epoch: [24/120]Loss: 0.0005\n",
      "Epoch: [25/120]Loss: 0.0004\n",
      "Epoch: [26/120]Loss: 0.0004\n",
      "Epoch: [27/120]Loss: 0.0004\n",
      "Epoch: [28/120]Loss: 0.0004\n",
      "Epoch: [29/120]Loss: 0.0004\n",
      "Epoch: [30/120]Loss: 0.0003\n",
      "Epoch: [31/120]Loss: 0.0003\n",
      "Epoch: [32/120]Loss: 0.0003\n",
      "Epoch: [33/120]Loss: 0.0003\n",
      "Epoch: [34/120]Loss: 0.0003\n",
      "Epoch: [35/120]Loss: 0.0003\n",
      "Epoch: [36/120]Loss: 0.0003\n",
      "Epoch: [37/120]Loss: 0.0002\n",
      "Epoch: [38/120]Loss: 0.0002\n",
      "Epoch: [39/120]Loss: 0.0002\n",
      "Epoch: [40/120]Loss: 0.0002\n",
      "Epoch: [41/120]Loss: 0.0002\n",
      "Epoch: [42/120]Loss: 0.0002\n",
      "Epoch: [43/120]Loss: 0.0002\n",
      "Epoch: [44/120]Loss: 0.0002\n",
      "Epoch: [45/120]Loss: 0.0002\n",
      "Epoch: [46/120]Loss: 0.0002\n",
      "Epoch: [47/120]Loss: 0.0002\n",
      "Epoch: [48/120]Loss: 0.0002\n",
      "Epoch: [49/120]Loss: 0.0002\n",
      "Epoch: [50/120]Loss: 0.0002\n",
      "Epoch: [51/120]Loss: 0.0002\n",
      "Epoch: [52/120]Loss: 0.0001\n",
      "Epoch: [53/120]Loss: 0.0001\n",
      "Epoch: [54/120]Loss: 0.0001\n",
      "Epoch: [55/120]Loss: 0.0001\n",
      "Epoch: [56/120]Loss: 0.0001\n",
      "Epoch: [57/120]Loss: 0.0001\n",
      "Epoch: [58/120]Loss: 0.0001\n",
      "Epoch: [59/120]Loss: 0.0001\n",
      "Epoch: [60/120]Loss: 0.0001\n",
      "Epoch: [61/120]Loss: 0.0001\n",
      "Epoch: [62/120]Loss: 0.0001\n",
      "Epoch: [63/120]Loss: 0.0001\n",
      "Epoch: [64/120]Loss: 0.0001\n",
      "Epoch: [65/120]Loss: 0.0001\n",
      "Epoch: [66/120]Loss: 0.0001\n",
      "Epoch: [67/120]Loss: 0.0001\n",
      "Epoch: [68/120]Loss: 0.0001\n",
      "Epoch: [69/120]Loss: 0.0001\n",
      "Epoch: [70/120]Loss: 0.0001\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0000\n",
      "145 <class 'numpy.int32'>\n",
      "[125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "494\n",
      "[145]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.7137\n",
      "Epoch: [1/120]Loss: 0.3750\n",
      "Epoch: [2/120]Loss: 0.2616\n",
      "Epoch: [3/120]Loss: 0.2391\n",
      "Epoch: [4/120]Loss: 0.2290\n",
      "Epoch: [5/120]Loss: 0.2214\n",
      "Epoch: [6/120]Loss: 0.2146\n",
      "Epoch: [7/120]Loss: 0.2071\n",
      "Epoch: [8/120]Loss: 0.1966\n",
      "Epoch: [9/120]Loss: 0.1786\n",
      "Epoch: [10/120]Loss: 0.1479\n",
      "Epoch: [11/120]Loss: 0.1302\n",
      "Epoch: [12/120]Loss: 0.1595\n",
      "Epoch: [13/120]Loss: 0.1328\n",
      "Epoch: [14/120]Loss: 0.0557\n",
      "Epoch: [15/120]Loss: 0.0151\n",
      "Epoch: [16/120]Loss: 0.0710\n",
      "Epoch: [17/120]Loss: 0.0292\n",
      "Epoch: [18/120]Loss: 0.0102\n",
      "Epoch: [19/120]Loss: 0.0064\n",
      "Epoch: [20/120]Loss: 0.0048\n",
      "Epoch: [21/120]Loss: 0.0039\n",
      "Epoch: [22/120]Loss: 0.0032\n",
      "Epoch: [23/120]Loss: 0.0027\n",
      "Epoch: [24/120]Loss: 0.0024\n",
      "Epoch: [25/120]Loss: 0.0021\n",
      "Epoch: [26/120]Loss: 0.0019\n",
      "Epoch: [27/120]Loss: 0.0017\n",
      "Epoch: [28/120]Loss: 0.0015\n",
      "Epoch: [29/120]Loss: 0.0014\n",
      "Epoch: [30/120]Loss: 0.0013\n",
      "Epoch: [31/120]Loss: 0.0012\n",
      "Epoch: [32/120]Loss: 0.0011\n",
      "Epoch: [33/120]Loss: 0.0010\n",
      "Epoch: [34/120]Loss: 0.0009\n",
      "Epoch: [35/120]Loss: 0.0009\n",
      "Epoch: [36/120]Loss: 0.0008\n",
      "Epoch: [37/120]Loss: 0.0008\n",
      "Epoch: [38/120]Loss: 0.0007\n",
      "Epoch: [39/120]Loss: 0.0007\n",
      "Epoch: [40/120]Loss: 0.0007\n",
      "Epoch: [41/120]Loss: 0.0006\n",
      "Epoch: [42/120]Loss: 0.0006\n",
      "Epoch: [43/120]Loss: 0.0006\n",
      "Epoch: [44/120]Loss: 0.0005\n",
      "Epoch: [45/120]Loss: 0.0005\n",
      "Epoch: [46/120]Loss: 0.0005\n",
      "Epoch: [47/120]Loss: 0.0005\n",
      "Epoch: [48/120]Loss: 0.0004\n",
      "Epoch: [49/120]Loss: 0.0004\n",
      "Epoch: [50/120]Loss: 0.0004\n",
      "Epoch: [51/120]Loss: 0.0004\n",
      "Epoch: [52/120]Loss: 0.0004\n",
      "Epoch: [53/120]Loss: 0.0004\n",
      "Epoch: [54/120]Loss: 0.0003\n",
      "Epoch: [55/120]Loss: 0.0003\n",
      "Epoch: [56/120]Loss: 0.0003\n",
      "Epoch: [57/120]Loss: 0.0003\n",
      "Epoch: [58/120]Loss: 0.0003\n",
      "Epoch: [59/120]Loss: 0.0003\n",
      "Epoch: [60/120]Loss: 0.0003\n",
      "Epoch: [61/120]Loss: 0.0003\n",
      "Epoch: [62/120]Loss: 0.0003\n",
      "Epoch: [63/120]Loss: 0.0002\n",
      "Epoch: [64/120]Loss: 0.0002\n",
      "Epoch: [65/120]Loss: 0.0002\n",
      "Epoch: [66/120]Loss: 0.0002\n",
      "Epoch: [67/120]Loss: 0.0002\n",
      "Epoch: [68/120]Loss: 0.0002\n",
      "Epoch: [69/120]Loss: 0.0002\n",
      "Epoch: [70/120]Loss: 0.0002\n",
      "Epoch: [71/120]Loss: 0.0002\n",
      "Epoch: [72/120]Loss: 0.0002\n",
      "Epoch: [73/120]Loss: 0.0002\n",
      "Epoch: [74/120]Loss: 0.0002\n",
      "Epoch: [75/120]Loss: 0.0002\n",
      "Epoch: [76/120]Loss: 0.0002\n",
      "Epoch: [77/120]Loss: 0.0002\n",
      "Epoch: [78/120]Loss: 0.0002\n",
      "Epoch: [79/120]Loss: 0.0002\n",
      "Epoch: [80/120]Loss: 0.0002\n",
      "Epoch: [81/120]Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0001\n",
      "Epoch: [101/120]Loss: 0.0001\n",
      "Epoch: [102/120]Loss: 0.0001\n",
      "Epoch: [103/120]Loss: 0.0001\n",
      "Epoch: [104/120]Loss: 0.0001\n",
      "Epoch: [105/120]Loss: 0.0001\n",
      "Epoch: [106/120]Loss: 0.0001\n",
      "Epoch: [107/120]Loss: 0.0001\n",
      "Epoch: [108/120]Loss: 0.0001\n",
      "Epoch: [109/120]Loss: 0.0001\n",
      "Epoch: [110/120]Loss: 0.0001\n",
      "Epoch: [111/120]Loss: 0.0001\n",
      "Epoch: [112/120]Loss: 0.0001\n",
      "Epoch: [113/120]Loss: 0.0001\n",
      "Epoch: [114/120]Loss: 0.0001\n",
      "Epoch: [115/120]Loss: 0.0001\n",
      "Epoch: [116/120]Loss: 0.0001\n",
      "Epoch: [117/120]Loss: 0.0001\n",
      "Epoch: [118/120]Loss: 0.0001\n",
      "Epoch: [119/120]Loss: 0.0001\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0001\n",
      "105 <class 'numpy.int32'>\n",
      "47 <class 'numpy.int32'>\n",
      "76 <class 'numpy.int32'>\n",
      "84 <class 'numpy.int32'>\n",
      "26 <class 'numpy.int32'>\n",
      "128 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "833\n",
      "[105, 47, 76, 84, 26, 128]\n",
      "72 72 42 42\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71] [114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185]\n",
      "[ 39   7  23  51  37  14   8  42  69  68  57  38  56  47  21  31  17  19\n",
      "  59  29  62  63  58  28  26  55   4  46   1  41  45  15  24  64  71  43\n",
      "  44   9  70  20  16  65  50  32  30  33  66  36  35  60  18  61  12  40\n",
      "  53   0  10  54  11  34  25  13   5  52  49  22  48  67   3   2   6  27\n",
      " 153 121 137 165 151 128 122 156 183 182 171 152 170 161 135 145 131 133\n",
      " 173 143 176 177 172 142 140 169 118 160 115 155 159 129 138 178 185 157\n",
      " 158 123 184 134 130 179 164 146 144 147 180 150 149 174 132 175 126 154\n",
      " 167 114 124 168 125 148 139 127 119 166 163 136 162 181 117 116 120 141\n",
      " 100 101  79  89 105 103 112  96  95  81  86  91  88  87 111 102  98  73\n",
      "  92  76 108  90 104 107  80  93  72  82 106 113 110  97  85  77  94  84\n",
      " 109  75  74  78  99  83 214 215 193 203 219 217 226 210 209 195 200 205\n",
      " 202 201 225 216 212 187 206 190 222 204 218 221 194 207 186 196 220 227\n",
      " 224 211 199 191 208 198 223 189 188 192 213 197]\n",
      "[47, 105, 105, 47, 105, 105, 105, 47, 47, 47, 47, 47, 47, 47, 105, 105, 105, 105, 47, 105, 47, 47, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 47, 47, 47, 105, 47, 105, 105, 47, 47, 105, 105, 105, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 105, 105, 105, 105, 105, 47, 47, 105, 47, 47, 105, 105, 105, 105, 26, 84, 84, 26, 84, 84, 84, 26, 26, 26, 26, 26, 26, 26, 84, 84, 84, 84, 26, 84, 26, 26, 26, 84, 84, 26, 84, 26, 84, 26, 26, 84, 84, 26, 26, 26, 26, 84, 26, 84, 84, 26, 26, 84, 84, 84, 26, 84, 84, 26, 84, 26, 84, 26, 26, 84, 84, 26, 84, 84, 84, 84, 84, 26, 26, 84, 26, 26, 84, 84, 84, 84, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 47, 76, 76, 76, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 26, 128, 128, 128]\n",
      "144\n",
      "Epoch: [0/120]Loss: 0.0173\n",
      "Epoch: [1/120]Loss: 0.1225\n",
      "Epoch: [2/120]Loss: 0.2945\n",
      "Epoch: [3/120]Loss: 0.4021\n",
      "Epoch: [4/120]Loss: 0.4298\n",
      "Epoch: [5/120]Loss: 0.4864\n",
      "Epoch: [6/120]Loss: 0.5157\n",
      "Epoch: [7/120]Loss: 0.3927\n",
      "Epoch: [8/120]Loss: 0.5499\n",
      "Epoch: [9/120]Loss: 0.5767\n",
      "Epoch: [10/120]Loss: 0.6020\n",
      "Epoch: [11/120]Loss: 0.5996\n",
      "Epoch: [12/120]Loss: 0.6385\n",
      "Epoch: [13/120]Loss: 0.4212\n",
      "Epoch: [14/120]Loss: 0.6501\n",
      "Epoch: [15/120]Loss: 0.6523\n",
      "Epoch: [16/120]Loss: 0.3491\n",
      "Epoch: [17/120]Loss: 0.0755\n",
      "Epoch: [18/120]Loss: 0.0416\n",
      "Epoch: [19/120]Loss: 0.1011\n",
      "Epoch: [20/120]Loss: 0.0777\n",
      "Epoch: [21/120]Loss: 0.0717\n",
      "Epoch: [22/120]Loss: 0.0504\n",
      "Epoch: [23/120]Loss: 0.0412\n",
      "Epoch: [24/120]Loss: 0.0753\n",
      "Epoch: [25/120]Loss: 0.0545\n",
      "Epoch: [26/120]Loss: 0.0993\n",
      "Epoch: [27/120]Loss: 0.1084\n",
      "Epoch: [28/120]Loss: 0.1299\n",
      "Epoch: [29/120]Loss: 0.1268\n",
      "Epoch: [30/120]Loss: 0.1692\n",
      "Epoch: [31/120]Loss: 0.3500\n",
      "Epoch: [32/120]Loss: 0.4201\n",
      "Epoch: [33/120]Loss: 0.4611\n",
      "Epoch: [34/120]Loss: 0.4647\n",
      "Epoch: [35/120]Loss: 0.0250\n",
      "Epoch: [36/120]Loss: 0.1053\n",
      "Epoch: [37/120]Loss: 0.4280\n",
      "Epoch: [38/120]Loss: 0.5228\n",
      "Epoch: [39/120]Loss: 0.5813\n",
      "Epoch: [40/120]Loss: 0.0405\n",
      "Epoch: [41/120]Loss: 0.0470\n",
      "Epoch: [42/120]Loss: 0.0609\n",
      "Epoch: [43/120]Loss: 0.0684\n",
      "Epoch: [44/120]Loss: 0.0736\n",
      "Epoch: [45/120]Loss: 0.0857\n",
      "Epoch: [46/120]Loss: 0.1126\n",
      "Epoch: [47/120]Loss: 0.1232\n",
      "Epoch: [48/120]Loss: 0.1374\n",
      "Epoch: [49/120]Loss: 0.1497\n",
      "Epoch: [50/120]Loss: 0.2326\n",
      "Epoch: [51/120]Loss: 0.1307\n",
      "Epoch: [52/120]Loss: 0.1821\n",
      "Epoch: [53/120]Loss: 0.2513\n",
      "Epoch: [54/120]Loss: 0.2638\n",
      "Epoch: [55/120]Loss: 0.2326\n",
      "Epoch: [56/120]Loss: 0.2803\n",
      "Epoch: [57/120]Loss: 0.2102\n",
      "Epoch: [58/120]Loss: 0.1269\n",
      "Epoch: [59/120]Loss: 0.0412\n",
      "Epoch: [60/120]Loss: 0.0647\n",
      "Epoch: [61/120]Loss: 0.1082\n",
      "Epoch: [62/120]Loss: 0.1318\n",
      "Epoch: [63/120]Loss: 0.5166\n",
      "Epoch: [64/120]Loss: 0.5605\n",
      "Epoch: [65/120]Loss: 0.1924\n",
      "Epoch: [66/120]Loss: 0.6510\n",
      "Epoch: [67/120]Loss: 0.6731\n",
      "Epoch: [68/120]Loss: 0.7184\n",
      "Epoch: [69/120]Loss: 0.7569\n",
      "Epoch: [70/120]Loss: 0.7413\n",
      "Epoch: [71/120]Loss: 0.2239\n",
      "Epoch: [72/120]Loss: 0.7752\n",
      "Epoch: [73/120]Loss: 0.7623\n",
      "Epoch: [74/120]Loss: 0.7923\n",
      "Epoch: [75/120]Loss: 0.8135\n",
      "Epoch: [76/120]Loss: 0.8346\n",
      "Epoch: [77/120]Loss: 0.7579\n",
      "Epoch: [78/120]Loss: 0.4536\n",
      "Epoch: [79/120]Loss: 0.3902\n",
      "Epoch: [80/120]Loss: 0.5333\n",
      "Epoch: [81/120]Loss: 1.4616\n",
      "Epoch: [82/120]Loss: 0.0417\n",
      "Epoch: [83/120]Loss: 0.2616\n",
      "Epoch: [84/120]Loss: 0.0748\n",
      "Epoch: [85/120]Loss: 0.5082\n",
      "Epoch: [86/120]Loss: 0.2827\n",
      "Epoch: [87/120]Loss: 0.0786\n",
      "Epoch: [88/120]Loss: 0.3084\n",
      "Epoch: [89/120]Loss: 0.3626\n",
      "Epoch: [90/120]Loss: 0.7779\n",
      "Epoch: [91/120]Loss: 0.4090\n",
      "Epoch: [92/120]Loss: 0.2879\n",
      "Epoch: [93/120]Loss: 0.6810\n",
      "Epoch: [94/120]Loss: 0.3089\n",
      "Epoch: [95/120]Loss: 0.0478\n",
      "Epoch: [96/120]Loss: 0.0853\n",
      "Epoch: [97/120]Loss: 0.4131\n",
      "Epoch: [98/120]Loss: 0.7852\n",
      "Epoch: [99/120]Loss: 0.3203\n",
      "Epoch: [100/120]Loss: 0.2073\n",
      "Epoch: [101/120]Loss: 0.0667\n",
      "Epoch: [102/120]Loss: 0.1113\n",
      "Epoch: [103/120]Loss: 0.5524\n",
      "Epoch: [104/120]Loss: 0.3558\n",
      "Epoch: [105/120]Loss: 0.2599\n",
      "Epoch: [106/120]Loss: 0.1835\n",
      "Epoch: [107/120]Loss: 0.2454\n",
      "Epoch: [108/120]Loss: 0.1492\n",
      "Epoch: [109/120]Loss: 0.0869\n",
      "Epoch: [110/120]Loss: 0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [111/120]Loss: 0.0593\n",
      "Epoch: [112/120]Loss: 0.0699\n",
      "Epoch: [113/120]Loss: 0.0283\n",
      "Epoch: [114/120]Loss: 0.1026\n",
      "Epoch: [115/120]Loss: 0.0237\n",
      "Epoch: [116/120]Loss: 0.0149\n",
      "Epoch: [117/120]Loss: 0.0323\n",
      "Epoch: [118/120]Loss: 0.0109\n",
      "Epoch: [119/120]Loss: 0.0276\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 84 test images: 57.142857142857146 %\n",
      "Loss: 0.0276\n",
      "74 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72]\n",
      "102\n",
      "[74]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.9349\n",
      "Epoch: [1/120]Loss: 0.7044\n",
      "Epoch: [2/120]Loss: 0.4778\n",
      "Epoch: [3/120]Loss: 0.2525\n",
      "Epoch: [4/120]Loss: 0.1516\n",
      "Epoch: [5/120]Loss: 0.1235\n",
      "Epoch: [6/120]Loss: 0.1129\n",
      "Epoch: [7/120]Loss: 0.1055\n",
      "Epoch: [8/120]Loss: 0.0995\n",
      "Epoch: [9/120]Loss: 0.0942\n",
      "Epoch: [10/120]Loss: 0.0891\n",
      "Epoch: [11/120]Loss: 0.0841\n",
      "Epoch: [12/120]Loss: 0.0788\n",
      "Epoch: [13/120]Loss: 0.0733\n",
      "Epoch: [14/120]Loss: 0.0675\n",
      "Epoch: [15/120]Loss: 0.0614\n",
      "Epoch: [16/120]Loss: 0.0551\n",
      "Epoch: [17/120]Loss: 0.0488\n",
      "Epoch: [18/120]Loss: 0.0428\n",
      "Epoch: [19/120]Loss: 0.0375\n",
      "Epoch: [20/120]Loss: 0.0328\n",
      "Epoch: [21/120]Loss: 0.0284\n",
      "Epoch: [22/120]Loss: 0.0282\n",
      "Epoch: [23/120]Loss: 0.0119\n",
      "Epoch: [24/120]Loss: 0.0158\n",
      "Epoch: [25/120]Loss: 0.0112\n",
      "Epoch: [26/120]Loss: 0.0430\n",
      "Epoch: [27/120]Loss: 0.0330\n",
      "Epoch: [28/120]Loss: 0.0201\n",
      "Epoch: [29/120]Loss: 0.0125\n",
      "Epoch: [30/120]Loss: 0.0081\n",
      "Epoch: [31/120]Loss: 0.0053\n",
      "Epoch: [32/120]Loss: 0.0036\n",
      "Epoch: [33/120]Loss: 0.0023\n",
      "Epoch: [34/120]Loss: 0.0014\n",
      "Epoch: [35/120]Loss: 0.0009\n",
      "Epoch: [36/120]Loss: 0.0005\n",
      "Epoch: [37/120]Loss: 0.0003\n",
      "Epoch: [38/120]Loss: 0.0002\n",
      "Epoch: [39/120]Loss: 0.0002\n",
      "Epoch: [40/120]Loss: 0.0001\n",
      "Epoch: [41/120]Loss: 0.0001\n",
      "Epoch: [42/120]Loss: 0.0001\n",
      "Epoch: [43/120]Loss: 0.0001\n",
      "Epoch: [44/120]Loss: 0.0001\n",
      "Epoch: [45/120]Loss: 0.0001\n",
      "Epoch: [46/120]Loss: 0.0001\n",
      "Epoch: [47/120]Loss: 0.0001\n",
      "Epoch: [48/120]Loss: 0.0001\n",
      "Epoch: [49/120]Loss: 0.0001\n",
      "Epoch: [50/120]Loss: 0.0001\n",
      "Epoch: [51/120]Loss: 0.0001\n",
      "Epoch: [52/120]Loss: 0.0001\n",
      "Epoch: [53/120]Loss: 0.0000\n",
      "Epoch: [54/120]Loss: 0.0000\n",
      "Epoch: [55/120]Loss: 0.0000\n",
      "Epoch: [56/120]Loss: 0.0000\n",
      "Epoch: [57/120]Loss: 0.0000\n",
      "Epoch: [58/120]Loss: 0.0000\n",
      "Epoch: [59/120]Loss: 0.0000\n",
      "Epoch: [60/120]Loss: 0.0000\n",
      "Epoch: [61/120]Loss: 0.0000\n",
      "Epoch: [62/120]Loss: 0.0000\n",
      "Epoch: [63/120]Loss: 0.0000\n",
      "Epoch: [64/120]Loss: 0.0000\n",
      "Epoch: [65/120]Loss: 0.0000\n",
      "Epoch: [66/120]Loss: 0.0000\n",
      "Epoch: [67/120]Loss: 0.0000\n",
      "Epoch: [68/120]Loss: 0.0000\n",
      "Epoch: [69/120]Loss: 0.0000\n",
      "Epoch: [70/120]Loss: 0.0000\n",
      "Epoch: [71/120]Loss: 0.0000\n",
      "Epoch: [72/120]Loss: 0.0000\n",
      "Epoch: [73/120]Loss: 0.0000\n",
      "Epoch: [74/120]Loss: 0.0000\n",
      "Epoch: [75/120]Loss: 0.0000\n",
      "Epoch: [76/120]Loss: 0.0000\n",
      "Epoch: [77/120]Loss: 0.0000\n",
      "Epoch: [78/120]Loss: 0.0000\n",
      "Epoch: [79/120]Loss: 0.0000\n",
      "Epoch: [80/120]Loss: 0.0000\n",
      "Epoch: [81/120]Loss: 0.0000\n",
      "Epoch: [82/120]Loss: 0.0000\n",
      "Epoch: [83/120]Loss: 0.0000\n",
      "Epoch: [84/120]Loss: 0.0000\n",
      "Epoch: [85/120]Loss: 0.0000\n",
      "Epoch: [86/120]Loss: 0.0000\n",
      "Epoch: [87/120]Loss: 0.0000\n",
      "Epoch: [88/120]Loss: 0.0000\n",
      "Epoch: [89/120]Loss: 0.0000\n",
      "Epoch: [90/120]Loss: 0.0000\n",
      "Epoch: [91/120]Loss: 0.0000\n",
      "Epoch: [92/120]Loss: 0.0000\n",
      "Epoch: [93/120]Loss: 0.0000\n",
      "Epoch: [94/120]Loss: 0.0000\n",
      "Epoch: [95/120]Loss: 0.0000\n",
      "Epoch: [96/120]Loss: 0.0000\n",
      "Epoch: [97/120]Loss: 0.0000\n",
      "Epoch: [98/120]Loss: 0.0000\n",
      "Epoch: [99/120]Loss: 0.0000\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 78.57142857142857 %\n",
      "Loss: 0.0000\n",
      "51 <class 'numpy.int32'>\n",
      "[46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43]\n",
      "69\n",
      "[51]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.9230\n",
      "Epoch: [1/120]Loss: 0.7478\n",
      "Epoch: [2/120]Loss: 0.6789\n",
      "Epoch: [3/120]Loss: 0.5994\n",
      "Epoch: [4/120]Loss: 0.4842\n",
      "Epoch: [5/120]Loss: 0.3759\n",
      "Epoch: [6/120]Loss: 0.3072\n",
      "Epoch: [7/120]Loss: 0.2649\n",
      "Epoch: [8/120]Loss: 0.2365\n",
      "Epoch: [9/120]Loss: 0.2181\n",
      "Epoch: [10/120]Loss: 0.2019\n",
      "Epoch: [11/120]Loss: 0.1893\n",
      "Epoch: [12/120]Loss: 0.1751\n",
      "Epoch: [13/120]Loss: 0.1618\n",
      "Epoch: [14/120]Loss: 0.1436\n",
      "Epoch: [15/120]Loss: 0.1250\n",
      "Epoch: [16/120]Loss: 0.0966\n",
      "Epoch: [17/120]Loss: 0.0758\n",
      "Epoch: [18/120]Loss: 0.0518\n",
      "Epoch: [19/120]Loss: 0.0430\n",
      "Epoch: [20/120]Loss: 0.0308\n",
      "Epoch: [21/120]Loss: 0.0226\n",
      "Epoch: [22/120]Loss: 0.0127\n",
      "Epoch: [23/120]Loss: 0.0098\n",
      "Epoch: [24/120]Loss: 0.0299\n",
      "Epoch: [25/120]Loss: 0.0249\n",
      "Epoch: [26/120]Loss: 0.0422\n",
      "Epoch: [27/120]Loss: 0.0312\n",
      "Epoch: [28/120]Loss: 0.0178\n",
      "Epoch: [29/120]Loss: 0.0138\n",
      "Epoch: [30/120]Loss: 0.0108\n",
      "Epoch: [31/120]Loss: 0.0087\n",
      "Epoch: [32/120]Loss: 0.0072\n",
      "Epoch: [33/120]Loss: 0.0061\n",
      "Epoch: [34/120]Loss: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35/120]Loss: 0.0045\n",
      "Epoch: [36/120]Loss: 0.0040\n",
      "Epoch: [37/120]Loss: 0.0035\n",
      "Epoch: [38/120]Loss: 0.0032\n",
      "Epoch: [39/120]Loss: 0.0029\n",
      "Epoch: [40/120]Loss: 0.0026\n",
      "Epoch: [41/120]Loss: 0.0024\n",
      "Epoch: [42/120]Loss: 0.0022\n",
      "Epoch: [43/120]Loss: 0.0020\n",
      "Epoch: [44/120]Loss: 0.0019\n",
      "Epoch: [45/120]Loss: 0.0018\n",
      "Epoch: [46/120]Loss: 0.0016\n",
      "Epoch: [47/120]Loss: 0.0015\n",
      "Epoch: [48/120]Loss: 0.0014\n",
      "Epoch: [49/120]Loss: 0.0014\n",
      "Epoch: [50/120]Loss: 0.0013\n",
      "Epoch: [51/120]Loss: 0.0012\n",
      "Epoch: [52/120]Loss: 0.0011\n",
      "Epoch: [53/120]Loss: 0.0011\n",
      "Epoch: [54/120]Loss: 0.0010\n",
      "Epoch: [55/120]Loss: 0.0010\n",
      "Epoch: [56/120]Loss: 0.0009\n",
      "Epoch: [57/120]Loss: 0.0009\n",
      "Epoch: [58/120]Loss: 0.0008\n",
      "Epoch: [59/120]Loss: 0.0008\n",
      "Epoch: [60/120]Loss: 0.0008\n",
      "Epoch: [61/120]Loss: 0.0007\n",
      "Epoch: [62/120]Loss: 0.0007\n",
      "Epoch: [63/120]Loss: 0.0007\n",
      "Epoch: [64/120]Loss: 0.0007\n",
      "Epoch: [65/120]Loss: 0.0006\n",
      "Epoch: [66/120]Loss: 0.0006\n",
      "Epoch: [67/120]Loss: 0.0006\n",
      "Epoch: [68/120]Loss: 0.0006\n",
      "Epoch: [69/120]Loss: 0.0005\n",
      "Epoch: [70/120]Loss: 0.0005\n",
      "Epoch: [71/120]Loss: 0.0005\n",
      "Epoch: [72/120]Loss: 0.0005\n",
      "Epoch: [73/120]Loss: 0.0005\n",
      "Epoch: [74/120]Loss: 0.0005\n",
      "Epoch: [75/120]Loss: 0.0004\n",
      "Epoch: [76/120]Loss: 0.0004\n",
      "Epoch: [77/120]Loss: 0.0004\n",
      "Epoch: [78/120]Loss: 0.0004\n",
      "Epoch: [79/120]Loss: 0.0004\n",
      "Epoch: [80/120]Loss: 0.0004\n",
      "Epoch: [81/120]Loss: 0.0004\n",
      "Epoch: [82/120]Loss: 0.0004\n",
      "Epoch: [83/120]Loss: 0.0003\n",
      "Epoch: [84/120]Loss: 0.0003\n",
      "Epoch: [85/120]Loss: 0.0003\n",
      "Epoch: [86/120]Loss: 0.0003\n",
      "Epoch: [87/120]Loss: 0.0003\n",
      "Epoch: [88/120]Loss: 0.0003\n",
      "Epoch: [89/120]Loss: 0.0003\n",
      "Epoch: [90/120]Loss: 0.0003\n",
      "Epoch: [91/120]Loss: 0.0003\n",
      "Epoch: [92/120]Loss: 0.0003\n",
      "Epoch: [93/120]Loss: 0.0003\n",
      "Epoch: [94/120]Loss: 0.0002\n",
      "Epoch: [95/120]Loss: 0.0002\n",
      "Epoch: [96/120]Loss: 0.0002\n",
      "Epoch: [97/120]Loss: 0.0002\n",
      "Epoch: [98/120]Loss: 0.0002\n",
      "Epoch: [99/120]Loss: 0.0002\n",
      "Epoch: [100/120]Loss: 0.0002\n",
      "Epoch: [101/120]Loss: 0.0002\n",
      "Epoch: [102/120]Loss: 0.0002\n",
      "Epoch: [103/120]Loss: 0.0002\n",
      "Epoch: [104/120]Loss: 0.0002\n",
      "Epoch: [105/120]Loss: 0.0002\n",
      "Epoch: [106/120]Loss: 0.0002\n",
      "Epoch: [107/120]Loss: 0.0002\n",
      "Epoch: [108/120]Loss: 0.0002\n",
      "Epoch: [109/120]Loss: 0.0002\n",
      "Epoch: [110/120]Loss: 0.0002\n",
      "Epoch: [111/120]Loss: 0.0002\n",
      "Epoch: [112/120]Loss: 0.0002\n",
      "Epoch: [113/120]Loss: 0.0002\n",
      "Epoch: [114/120]Loss: 0.0002\n",
      "Epoch: [115/120]Loss: 0.0002\n",
      "Epoch: [116/120]Loss: 0.0001\n",
      "Epoch: [117/120]Loss: 0.0001\n",
      "Epoch: [118/120]Loss: 0.0001\n",
      "Epoch: [119/120]Loss: 0.0001\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 64.28571428571429 %\n",
      "Loss: 0.0001\n",
      "112 <class 'numpy.int32'>\n",
      "[492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76]\n",
      "833\n",
      "[112]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.8549\n",
      "Epoch: [1/120]Loss: 0.5401\n",
      "Epoch: [2/120]Loss: 0.1990\n",
      "Epoch: [3/120]Loss: 0.2403\n",
      "Epoch: [4/120]Loss: 0.2636\n",
      "Epoch: [5/120]Loss: 0.1874\n",
      "Epoch: [6/120]Loss: 0.1628\n",
      "Epoch: [7/120]Loss: 0.1438\n",
      "Epoch: [8/120]Loss: 0.1350\n",
      "Epoch: [9/120]Loss: 0.1280\n",
      "Epoch: [10/120]Loss: 0.1322\n",
      "Epoch: [11/120]Loss: 0.1341\n",
      "Epoch: [12/120]Loss: 0.1273\n",
      "Epoch: [13/120]Loss: 0.1297\n",
      "Epoch: [14/120]Loss: 0.1279\n",
      "Epoch: [15/120]Loss: 0.1293\n",
      "Epoch: [16/120]Loss: 0.1242\n",
      "Epoch: [17/120]Loss: 0.1280\n",
      "Epoch: [18/120]Loss: 0.1287\n",
      "Epoch: [19/120]Loss: 0.1231\n",
      "Epoch: [20/120]Loss: 0.1237\n",
      "Epoch: [21/120]Loss: 0.1132\n",
      "Epoch: [22/120]Loss: 0.1220\n",
      "Epoch: [23/120]Loss: 0.1305\n",
      "Epoch: [24/120]Loss: 0.1044\n",
      "Epoch: [25/120]Loss: 0.1220\n",
      "Epoch: [26/120]Loss: 0.1306\n",
      "Epoch: [27/120]Loss: 0.1268\n",
      "Epoch: [28/120]Loss: 0.0801\n",
      "Epoch: [29/120]Loss: 0.0969\n",
      "Epoch: [30/120]Loss: 0.0787\n",
      "Epoch: [31/120]Loss: 0.0919\n",
      "Epoch: [32/120]Loss: 0.1112\n",
      "Epoch: [33/120]Loss: 0.0428\n",
      "Epoch: [34/120]Loss: 0.0812\n",
      "Epoch: [35/120]Loss: 0.1120\n",
      "Epoch: [36/120]Loss: 0.1125\n",
      "Epoch: [37/120]Loss: 0.0481\n",
      "Epoch: [38/120]Loss: 0.1140\n",
      "Epoch: [39/120]Loss: 0.1519\n",
      "Epoch: [40/120]Loss: 0.1443\n",
      "Epoch: [41/120]Loss: 0.1009\n",
      "Epoch: [42/120]Loss: 0.1090\n",
      "Epoch: [43/120]Loss: 0.1136\n",
      "Epoch: [44/120]Loss: 0.1046\n",
      "Epoch: [45/120]Loss: 0.0763\n",
      "Epoch: [46/120]Loss: 0.0877\n",
      "Epoch: [47/120]Loss: 0.0566\n",
      "Epoch: [48/120]Loss: 0.0699\n",
      "Epoch: [49/120]Loss: 0.0901\n",
      "Epoch: [50/120]Loss: 0.0494\n",
      "Epoch: [51/120]Loss: 0.0401\n",
      "Epoch: [52/120]Loss: 0.0247\n",
      "Epoch: [53/120]Loss: 0.0235\n",
      "Epoch: [54/120]Loss: 0.0103\n",
      "Epoch: [55/120]Loss: 0.0053\n",
      "Epoch: [56/120]Loss: 0.0040\n",
      "Epoch: [57/120]Loss: 0.0032\n",
      "Epoch: [58/120]Loss: 0.0027\n",
      "Epoch: [59/120]Loss: 0.0023\n",
      "Epoch: [60/120]Loss: 0.0021\n",
      "Epoch: [61/120]Loss: 0.0018\n",
      "Epoch: [62/120]Loss: 0.0017\n",
      "Epoch: [63/120]Loss: 0.0015\n",
      "Epoch: [64/120]Loss: 0.0014\n",
      "Epoch: [65/120]Loss: 0.0013\n",
      "Epoch: [66/120]Loss: 0.0012\n",
      "Epoch: [67/120]Loss: 0.0011\n",
      "Epoch: [68/120]Loss: 0.0010\n",
      "Epoch: [69/120]Loss: 0.0010\n",
      "Epoch: [70/120]Loss: 0.0009\n",
      "Epoch: [71/120]Loss: 0.0009\n",
      "Epoch: [72/120]Loss: 0.0008\n",
      "Epoch: [73/120]Loss: 0.0008\n",
      "Epoch: [74/120]Loss: 0.0008\n",
      "Epoch: [75/120]Loss: 0.0007\n",
      "Epoch: [76/120]Loss: 0.0007\n",
      "Epoch: [77/120]Loss: 0.0007\n",
      "Epoch: [78/120]Loss: 0.0006\n",
      "Epoch: [79/120]Loss: 0.0006\n",
      "Epoch: [80/120]Loss: 0.0006\n",
      "Epoch: [81/120]Loss: 0.0006\n",
      "Epoch: [82/120]Loss: 0.0005\n",
      "Epoch: [83/120]Loss: 0.0005\n",
      "Epoch: [84/120]Loss: 0.0005\n",
      "Epoch: [85/120]Loss: 0.0005\n",
      "Epoch: [86/120]Loss: 0.0005\n",
      "Epoch: [87/120]Loss: 0.0005\n",
      "Epoch: [88/120]Loss: 0.0004\n",
      "Epoch: [89/120]Loss: 0.0004\n",
      "Epoch: [90/120]Loss: 0.0004\n",
      "Epoch: [91/120]Loss: 0.0004\n",
      "Epoch: [92/120]Loss: 0.0004\n",
      "Epoch: [93/120]Loss: 0.0004\n",
      "Epoch: [94/120]Loss: 0.0004\n",
      "Epoch: [95/120]Loss: 0.0004\n",
      "Epoch: [96/120]Loss: 0.0003\n",
      "Epoch: [97/120]Loss: 0.0003\n",
      "Epoch: [98/120]Loss: 0.0003\n",
      "Epoch: [99/120]Loss: 0.0003\n",
      "Epoch: [100/120]Loss: 0.0003\n",
      "Epoch: [101/120]Loss: 0.0003\n",
      "Epoch: [102/120]Loss: 0.0003\n",
      "Epoch: [103/120]Loss: 0.0003\n",
      "Epoch: [104/120]Loss: 0.0003\n",
      "Epoch: [105/120]Loss: 0.0003\n",
      "Epoch: [106/120]Loss: 0.0003\n",
      "Epoch: [107/120]Loss: 0.0003\n",
      "Epoch: [108/120]Loss: 0.0003\n",
      "Epoch: [109/120]Loss: 0.0002\n",
      "Epoch: [110/120]Loss: 0.0002\n",
      "Epoch: [111/120]Loss: 0.0002\n",
      "Epoch: [112/120]Loss: 0.0002\n",
      "Epoch: [113/120]Loss: 0.0002\n",
      "Epoch: [114/120]Loss: 0.0002\n",
      "Epoch: [115/120]Loss: 0.0002\n",
      "Epoch: [116/120]Loss: 0.0002\n",
      "Epoch: [117/120]Loss: 0.0002\n",
      "Epoch: [118/120]Loss: 0.0002\n",
      "Epoch: [119/120]Loss: 0.0002\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 100.0 %\n",
      "Loss: 0.0002\n",
      "98 <class 'numpy.int32'>\n",
      "[111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84]\n",
      "140\n",
      "[98]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.7304\n",
      "Epoch: [1/120]Loss: 0.3658\n",
      "Epoch: [2/120]Loss: 0.0843\n",
      "Epoch: [3/120]Loss: 0.0319\n",
      "Epoch: [4/120]Loss: 0.0228\n",
      "Epoch: [5/120]Loss: 0.0169\n",
      "Epoch: [6/120]Loss: 0.0122\n",
      "Epoch: [7/120]Loss: 0.0088\n",
      "Epoch: [8/120]Loss: 0.0063\n",
      "Epoch: [9/120]Loss: 0.0043\n",
      "Epoch: [10/120]Loss: 0.0027\n",
      "Epoch: [11/120]Loss: 0.0017\n",
      "Epoch: [12/120]Loss: 0.0011\n",
      "Epoch: [13/120]Loss: 0.0009\n",
      "Epoch: [14/120]Loss: 0.0008\n",
      "Epoch: [15/120]Loss: 0.0007\n",
      "Epoch: [16/120]Loss: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/120]Loss: 0.0006\n",
      "Epoch: [18/120]Loss: 0.0006\n",
      "Epoch: [19/120]Loss: 0.0005\n",
      "Epoch: [20/120]Loss: 0.0005\n",
      "Epoch: [21/120]Loss: 0.0005\n",
      "Epoch: [22/120]Loss: 0.0004\n",
      "Epoch: [23/120]Loss: 0.0004\n",
      "Epoch: [24/120]Loss: 0.0004\n",
      "Epoch: [25/120]Loss: 0.0004\n",
      "Epoch: [26/120]Loss: 0.0003\n",
      "Epoch: [27/120]Loss: 0.0003\n",
      "Epoch: [28/120]Loss: 0.0003\n",
      "Epoch: [29/120]Loss: 0.0003\n",
      "Epoch: [30/120]Loss: 0.0003\n",
      "Epoch: [31/120]Loss: 0.0003\n",
      "Epoch: [32/120]Loss: 0.0003\n",
      "Epoch: [33/120]Loss: 0.0002\n",
      "Epoch: [34/120]Loss: 0.0002\n",
      "Epoch: [35/120]Loss: 0.0002\n",
      "Epoch: [36/120]Loss: 0.0002\n",
      "Epoch: [37/120]Loss: 0.0002\n",
      "Epoch: [38/120]Loss: 0.0002\n",
      "Epoch: [39/120]Loss: 0.0002\n",
      "Epoch: [40/120]Loss: 0.0002\n",
      "Epoch: [41/120]Loss: 0.0002\n",
      "Epoch: [42/120]Loss: 0.0002\n",
      "Epoch: [43/120]Loss: 0.0002\n",
      "Epoch: [44/120]Loss: 0.0002\n",
      "Epoch: [45/120]Loss: 0.0002\n",
      "Epoch: [46/120]Loss: 0.0002\n",
      "Epoch: [47/120]Loss: 0.0002\n",
      "Epoch: [48/120]Loss: 0.0001\n",
      "Epoch: [49/120]Loss: 0.0001\n",
      "Epoch: [50/120]Loss: 0.0001\n",
      "Epoch: [51/120]Loss: 0.0001\n",
      "Epoch: [52/120]Loss: 0.0001\n",
      "Epoch: [53/120]Loss: 0.0001\n",
      "Epoch: [54/120]Loss: 0.0001\n",
      "Epoch: [55/120]Loss: 0.0001\n",
      "Epoch: [56/120]Loss: 0.0001\n",
      "Epoch: [57/120]Loss: 0.0001\n",
      "Epoch: [58/120]Loss: 0.0001\n",
      "Epoch: [59/120]Loss: 0.0001\n",
      "Epoch: [60/120]Loss: 0.0001\n",
      "Epoch: [61/120]Loss: 0.0001\n",
      "Epoch: [62/120]Loss: 0.0001\n",
      "Epoch: [63/120]Loss: 0.0001\n",
      "Epoch: [64/120]Loss: 0.0001\n",
      "Epoch: [65/120]Loss: 0.0001\n",
      "Epoch: [66/120]Loss: 0.0001\n",
      "Epoch: [67/120]Loss: 0.0001\n",
      "Epoch: [68/120]Loss: 0.0001\n",
      "Epoch: [69/120]Loss: 0.0001\n",
      "Epoch: [70/120]Loss: 0.0001\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0000\n",
      "Epoch: [98/120]Loss: 0.0000\n",
      "Epoch: [99/120]Loss: 0.0000\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 100.0 %\n",
      "Loss: 0.0000\n",
      "29 <class 'numpy.int32'>\n",
      "[28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25]\n",
      "41\n",
      "[29]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]\n",
      "24\n",
      "Epoch: [0/120]Loss: 0.8519\n",
      "Epoch: [1/120]Loss: 0.6702\n",
      "Epoch: [2/120]Loss: 0.5841\n",
      "Epoch: [3/120]Loss: 0.4348\n",
      "Epoch: [4/120]Loss: 0.2731\n",
      "Epoch: [5/120]Loss: 0.1892\n",
      "Epoch: [6/120]Loss: 0.1510\n",
      "Epoch: [7/120]Loss: 0.1297\n",
      "Epoch: [8/120]Loss: 0.1141\n",
      "Epoch: [9/120]Loss: 0.1012\n",
      "Epoch: [10/120]Loss: 0.0887\n",
      "Epoch: [11/120]Loss: 0.0762\n",
      "Epoch: [12/120]Loss: 0.0631\n",
      "Epoch: [13/120]Loss: 0.0477\n",
      "Epoch: [14/120]Loss: 0.0298\n",
      "Epoch: [15/120]Loss: 0.0116\n",
      "Epoch: [16/120]Loss: 0.0044\n",
      "Epoch: [17/120]Loss: 0.0014\n",
      "Epoch: [18/120]Loss: 0.0004\n",
      "Epoch: [19/120]Loss: 0.0002\n",
      "Epoch: [20/120]Loss: 0.0012\n",
      "Epoch: [21/120]Loss: 0.0049\n",
      "Epoch: [22/120]Loss: 0.0042\n",
      "Epoch: [23/120]Loss: 0.0026\n",
      "Epoch: [24/120]Loss: 0.0021\n",
      "Epoch: [25/120]Loss: 0.0016\n",
      "Epoch: [26/120]Loss: 0.0013\n",
      "Epoch: [27/120]Loss: 0.0011\n",
      "Epoch: [28/120]Loss: 0.0010\n",
      "Epoch: [29/120]Loss: 0.0009\n",
      "Epoch: [30/120]Loss: 0.0008\n",
      "Epoch: [31/120]Loss: 0.0008\n",
      "Epoch: [32/120]Loss: 0.0007\n",
      "Epoch: [33/120]Loss: 0.0007\n",
      "Epoch: [34/120]Loss: 0.0006\n",
      "Epoch: [35/120]Loss: 0.0006\n",
      "Epoch: [36/120]Loss: 0.0005\n",
      "Epoch: [37/120]Loss: 0.0005\n",
      "Epoch: [38/120]Loss: 0.0005\n",
      "Epoch: [39/120]Loss: 0.0005\n",
      "Epoch: [40/120]Loss: 0.0005\n",
      "Epoch: [41/120]Loss: 0.0004\n",
      "Epoch: [42/120]Loss: 0.0004\n",
      "Epoch: [43/120]Loss: 0.0004\n",
      "Epoch: [44/120]Loss: 0.0004\n",
      "Epoch: [45/120]Loss: 0.0004\n",
      "Epoch: [46/120]Loss: 0.0003\n",
      "Epoch: [47/120]Loss: 0.0003\n",
      "Epoch: [48/120]Loss: 0.0003\n",
      "Epoch: [49/120]Loss: 0.0003\n",
      "Epoch: [50/120]Loss: 0.0003\n",
      "Epoch: [51/120]Loss: 0.0003\n",
      "Epoch: [52/120]Loss: 0.0003\n",
      "Epoch: [53/120]Loss: 0.0003\n",
      "Epoch: [54/120]Loss: 0.0003\n",
      "Epoch: [55/120]Loss: 0.0002\n",
      "Epoch: [56/120]Loss: 0.0002\n",
      "Epoch: [57/120]Loss: 0.0002\n",
      "Epoch: [58/120]Loss: 0.0002\n",
      "Epoch: [59/120]Loss: 0.0002\n",
      "Epoch: [60/120]Loss: 0.0002\n",
      "Epoch: [61/120]Loss: 0.0002\n",
      "Epoch: [62/120]Loss: 0.0002\n",
      "Epoch: [63/120]Loss: 0.0002\n",
      "Epoch: [64/120]Loss: 0.0002\n",
      "Epoch: [65/120]Loss: 0.0002\n",
      "Epoch: [66/120]Loss: 0.0002\n",
      "Epoch: [67/120]Loss: 0.0002\n",
      "Epoch: [68/120]Loss: 0.0002\n",
      "Epoch: [69/120]Loss: 0.0002\n",
      "Epoch: [70/120]Loss: 0.0002\n",
      "Epoch: [71/120]Loss: 0.0001\n",
      "Epoch: [72/120]Loss: 0.0001\n",
      "Epoch: [73/120]Loss: 0.0001\n",
      "Epoch: [74/120]Loss: 0.0001\n",
      "Epoch: [75/120]Loss: 0.0001\n",
      "Epoch: [76/120]Loss: 0.0001\n",
      "Epoch: [77/120]Loss: 0.0001\n",
      "Epoch: [78/120]Loss: 0.0001\n",
      "Epoch: [79/120]Loss: 0.0001\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0001\n",
      "Epoch: [90/120]Loss: 0.0001\n",
      "Epoch: [91/120]Loss: 0.0001\n",
      "Epoch: [92/120]Loss: 0.0001\n",
      "Epoch: [93/120]Loss: 0.0001\n",
      "Epoch: [94/120]Loss: 0.0001\n",
      "Epoch: [95/120]Loss: 0.0001\n",
      "Epoch: [96/120]Loss: 0.0001\n",
      "Epoch: [97/120]Loss: 0.0001\n",
      "Epoch: [98/120]Loss: 0.0001\n",
      "Epoch: [99/120]Loss: 0.0001\n",
      "Epoch: [100/120]Loss: 0.0001\n",
      "Epoch: [101/120]Loss: 0.0001\n",
      "Epoch: [102/120]Loss: 0.0001\n",
      "Epoch: [103/120]Loss: 0.0001\n",
      "Epoch: [104/120]Loss: 0.0001\n",
      "Epoch: [105/120]Loss: 0.0001\n",
      "Epoch: [106/120]Loss: 0.0001\n",
      "Epoch: [107/120]Loss: 0.0001\n",
      "Epoch: [108/120]Loss: 0.0001\n",
      "Epoch: [109/120]Loss: 0.0001\n",
      "Epoch: [110/120]Loss: 0.0001\n",
      "Epoch: [111/120]Loss: 0.0001\n",
      "Epoch: [112/120]Loss: 0.0001\n",
      "Epoch: [113/120]Loss: 0.0001\n",
      "Epoch: [114/120]Loss: 0.0001\n",
      "Epoch: [115/120]Loss: 0.0001\n",
      "Epoch: [116/120]Loss: 0.0001\n",
      "Epoch: [117/120]Loss: 0.0001\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0000\n",
      "145 <class 'numpy.int32'>\n",
      "[125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "494\n",
      "[145]\n",
      "12 12 7 7\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] [19 20 21 22 23 24 25 26 27 28 29 30]\n",
      "[10  5  9  8  0  4  7  3  2  1  6 11 29 24 28 27 19 23 26 22 21 20 25 30\n",
      " 16 17 12 14 13 18 15 35 36 31 33 32 37 34]\n",
      "[145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145, 145]\n",
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/120]Loss: 0.8043\n",
      "Epoch: [1/120]Loss: 0.5150\n",
      "Epoch: [2/120]Loss: 0.2518\n",
      "Epoch: [3/120]Loss: 0.2324\n",
      "Epoch: [4/120]Loss: 0.2272\n",
      "Epoch: [5/120]Loss: 0.2208\n",
      "Epoch: [6/120]Loss: 0.2171\n",
      "Epoch: [7/120]Loss: 0.2147\n",
      "Epoch: [8/120]Loss: 0.2128\n",
      "Epoch: [9/120]Loss: 0.2110\n",
      "Epoch: [10/120]Loss: 0.2095\n",
      "Epoch: [11/120]Loss: 0.2081\n",
      "Epoch: [12/120]Loss: 0.2067\n",
      "Epoch: [13/120]Loss: 0.2054\n",
      "Epoch: [14/120]Loss: 0.2042\n",
      "Epoch: [15/120]Loss: 0.2030\n",
      "Epoch: [16/120]Loss: 0.2017\n",
      "Epoch: [17/120]Loss: 0.2004\n",
      "Epoch: [18/120]Loss: 0.1989\n",
      "Epoch: [19/120]Loss: 0.1973\n",
      "Epoch: [20/120]Loss: 0.1954\n",
      "Epoch: [21/120]Loss: 0.1931\n",
      "Epoch: [22/120]Loss: 0.1902\n",
      "Epoch: [23/120]Loss: 0.1867\n",
      "Epoch: [24/120]Loss: 0.1815\n",
      "Epoch: [25/120]Loss: 0.1747\n",
      "Epoch: [26/120]Loss: 0.1641\n",
      "Epoch: [27/120]Loss: 0.1508\n",
      "Epoch: [28/120]Loss: 0.1312\n",
      "Epoch: [29/120]Loss: 0.1142\n",
      "Epoch: [30/120]Loss: 0.1217\n",
      "Epoch: [31/120]Loss: 0.0681\n",
      "Epoch: [32/120]Loss: 0.0921\n",
      "Epoch: [33/120]Loss: 0.1743\n",
      "Epoch: [34/120]Loss: 0.1804\n",
      "Epoch: [35/120]Loss: 0.1760\n",
      "Epoch: [36/120]Loss: 0.1719\n",
      "Epoch: [37/120]Loss: 0.1657\n",
      "Epoch: [38/120]Loss: 0.1497\n",
      "Epoch: [39/120]Loss: 0.0969\n",
      "Epoch: [40/120]Loss: 0.0475\n",
      "Epoch: [41/120]Loss: 0.0563\n",
      "Epoch: [42/120]Loss: 0.0639\n",
      "Epoch: [43/120]Loss: 0.0622\n",
      "Epoch: [44/120]Loss: 0.0595\n",
      "Epoch: [45/120]Loss: 0.0575\n",
      "Epoch: [46/120]Loss: 0.0556\n",
      "Epoch: [47/120]Loss: 0.0535\n",
      "Epoch: [48/120]Loss: 0.0512\n",
      "Epoch: [49/120]Loss: 0.0487\n",
      "Epoch: [50/120]Loss: 0.0457\n",
      "Epoch: [51/120]Loss: 0.0422\n",
      "Epoch: [52/120]Loss: 0.0383\n",
      "Epoch: [53/120]Loss: 0.0341\n",
      "Epoch: [54/120]Loss: 0.0297\n",
      "Epoch: [55/120]Loss: 0.0254\n",
      "Epoch: [56/120]Loss: 0.0218\n",
      "Epoch: [57/120]Loss: 0.0191\n",
      "Epoch: [58/120]Loss: 0.0167\n",
      "Epoch: [59/120]Loss: 0.0165\n",
      "Epoch: [60/120]Loss: 0.0090\n",
      "Epoch: [61/120]Loss: 0.2252\n",
      "Epoch: [62/120]Loss: 0.0250\n",
      "Epoch: [63/120]Loss: 0.0154\n",
      "Epoch: [64/120]Loss: 0.0566\n",
      "Epoch: [65/120]Loss: 0.0092\n",
      "Epoch: [66/120]Loss: 0.1276\n",
      "Epoch: [67/120]Loss: 0.0113\n",
      "Epoch: [68/120]Loss: 0.0068\n",
      "Epoch: [69/120]Loss: 0.2849\n",
      "Epoch: [70/120]Loss: 0.0242\n",
      "Epoch: [71/120]Loss: 0.0079\n",
      "Epoch: [72/120]Loss: 0.1386\n",
      "Epoch: [73/120]Loss: 0.0242\n",
      "Epoch: [74/120]Loss: 0.0072\n",
      "Epoch: [75/120]Loss: 0.0486\n",
      "Epoch: [76/120]Loss: 0.0242\n",
      "Epoch: [77/120]Loss: 0.0076\n",
      "Epoch: [78/120]Loss: 0.0056\n",
      "Epoch: [79/120]Loss: 0.0107\n",
      "Epoch: [80/120]Loss: 0.0048\n",
      "Epoch: [81/120]Loss: 0.1590\n",
      "Epoch: [82/120]Loss: 0.0165\n",
      "Epoch: [83/120]Loss: 0.0046\n",
      "Epoch: [84/120]Loss: 0.0048\n",
      "Epoch: [85/120]Loss: 0.0037\n",
      "Epoch: [86/120]Loss: 0.1558\n",
      "Epoch: [87/120]Loss: 0.0136\n",
      "Epoch: [88/120]Loss: 0.0039\n",
      "Epoch: [89/120]Loss: 0.0028\n",
      "Epoch: [90/120]Loss: 0.3387\n",
      "Epoch: [91/120]Loss: 0.0154\n",
      "Epoch: [92/120]Loss: 0.0043\n",
      "Epoch: [93/120]Loss: 0.0024\n",
      "Epoch: [94/120]Loss: 0.1209\n",
      "Epoch: [95/120]Loss: 0.0147\n",
      "Epoch: [96/120]Loss: 0.0039\n",
      "Epoch: [97/120]Loss: 0.0021\n",
      "Epoch: [98/120]Loss: 0.0208\n",
      "Epoch: [99/120]Loss: 0.0211\n",
      "Epoch: [100/120]Loss: 0.0063\n",
      "Epoch: [101/120]Loss: 0.0024\n",
      "Epoch: [102/120]Loss: 0.0019\n",
      "Epoch: [103/120]Loss: 0.0033\n",
      "Epoch: [104/120]Loss: 0.0019\n",
      "Epoch: [105/120]Loss: 0.0440\n",
      "Epoch: [106/120]Loss: 0.0238\n",
      "Epoch: [107/120]Loss: 0.0049\n",
      "Epoch: [108/120]Loss: 0.0018\n",
      "Epoch: [109/120]Loss: 0.0015\n",
      "Epoch: [110/120]Loss: 0.0032\n",
      "Epoch: [111/120]Loss: 0.0015\n",
      "Epoch: [112/120]Loss: 0.0319\n",
      "Epoch: [113/120]Loss: 0.0106\n",
      "Epoch: [114/120]Loss: 0.0022\n",
      "Epoch: [115/120]Loss: 0.0013\n",
      "Epoch: [116/120]Loss: 0.0152\n",
      "Epoch: [117/120]Loss: 0.0030\n",
      "Epoch: [118/120]Loss: 0.0013\n",
      "Epoch: [119/120]Loss: 0.0029\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "Accuracy of the network on the 14 test images: 85.71428571428571 %\n",
      "Loss: 0.0029\n",
      "105 <class 'numpy.int32'>\n",
      "47 <class 'numpy.int32'>\n",
      "76 <class 'numpy.int32'>\n",
      "84 <class 'numpy.int32'>\n",
      "26 <class 'numpy.int32'>\n",
      "128 <class 'numpy.int32'>\n",
      "[72, 71, 78, 91, 68, 69, 75, 84, 76, 79, 97, 102, 101, 89, 63, 74, 80, 69, 78, 46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 492, 214, 318, 311, 429, 102, 73, 77, 124, 94, 121, 218, 833, 695, 110, 90, 80, 329, 73, 111, 98, 105, 88, 115, 105, 112, 95, 94, 108, 127, 140, 135, 99, 97, 86, 90, 111, 97, 28, 27, 26, 27, 31, 31, 30, 30, 34, 30, 41, 36, 37, 33, 36, 29, 28, 31, 25, 125, 148, 151, 146, 129, 147, 145, 131, 145, 146, 154, 150, 194, 156, 183, 136, 142, 121, 494, 68, 64, 64, 71, 68, 65, 66, 66, 67, 66, 72, 66, 67, 70, 68, 62, 68, 66, 72, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43, 71, 68, 69, 67, 68, 81, 69, 69, 72, 77, 69, 70, 79, 71, 78, 69, 113, 77, 76, 87, 86, 86, 84, 81, 81, 111, 88, 80, 78, 77, 77, 84, 80, 77, 79, 79, 80, 84, 25, 26, 26, 26, 27, 25, 25, 26, 26, 25, 25, 25, 25, 26, 25, 25, 25, 25, 25, 123, 132, 124, 125, 117, 126, 129, 119, 126, 122, 133, 126, 128, 125, 138, 117, 127, 133, 131]\n",
      "833\n",
      "[105, 47, 76, 84, 26, 128]\n",
      "72 72 42 42\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71] [114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131\n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185]\n",
      "[ 39   7  23  51  37  14   8  42  69  68  57  38  56  47  21  31  17  19\n",
      "  59  29  62  63  58  28  26  55   4  46   1  41  45  15  24  64  71  43\n",
      "  44   9  70  20  16  65  50  32  30  33  66  36  35  60  18  61  12  40\n",
      "  53   0  10  54  11  34  25  13   5  52  49  22  48  67   3   2   6  27\n",
      " 153 121 137 165 151 128 122 156 183 182 171 152 170 161 135 145 131 133\n",
      " 173 143 176 177 172 142 140 169 118 160 115 155 159 129 138 178 185 157\n",
      " 158 123 184 134 130 179 164 146 144 147 180 150 149 174 132 175 126 154\n",
      " 167 114 124 168 125 148 139 127 119 166 163 136 162 181 117 116 120 141\n",
      " 100 101  79  89 105 103 112  96  95  81  86  91  88  87 111 102  98  73\n",
      "  92  76 108  90 104 107  80  93  72  82 106 113 110  97  85  77  94  84\n",
      " 109  75  74  78  99  83 214 215 193 203 219 217 226 210 209 195 200 205\n",
      " 202 201 225 216 212 187 206 190 222 204 218 221 194 207 186 196 220 227\n",
      " 224 211 199 191 208 198 223 189 188 192 213 197]\n",
      "[47, 105, 105, 47, 105, 105, 105, 47, 47, 47, 47, 47, 47, 47, 105, 105, 105, 105, 47, 105, 47, 47, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 47, 47, 47, 105, 47, 105, 105, 47, 47, 105, 105, 105, 47, 105, 105, 47, 105, 47, 105, 47, 47, 105, 105, 47, 105, 105, 105, 105, 105, 47, 47, 105, 47, 47, 105, 105, 105, 105, 26, 84, 84, 26, 84, 84, 84, 26, 26, 26, 26, 26, 26, 26, 84, 84, 84, 84, 26, 84, 26, 26, 26, 84, 84, 26, 84, 26, 84, 26, 26, 84, 84, 26, 26, 26, 26, 84, 26, 84, 84, 26, 26, 84, 84, 84, 26, 84, 84, 26, 84, 26, 84, 26, 26, 84, 84, 26, 84, 84, 84, 84, 84, 26, 26, 84, 26, 26, 84, 84, 84, 84, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 47, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 47, 47, 76, 76, 76, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 26, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 26, 26, 128, 128, 128]\n",
      "144\n",
      "Epoch: [0/120]Loss: 0.0185\n",
      "Epoch: [1/120]Loss: 0.0858\n",
      "Epoch: [2/120]Loss: 0.4356\n",
      "Epoch: [3/120]Loss: 0.6234\n",
      "Epoch: [4/120]Loss: 0.6038\n",
      "Epoch: [5/120]Loss: 0.5550\n",
      "Epoch: [6/120]Loss: 0.4990\n",
      "Epoch: [7/120]Loss: 0.4178\n",
      "Epoch: [8/120]Loss: 0.3835\n",
      "Epoch: [9/120]Loss: 0.3764\n",
      "Epoch: [10/120]Loss: 0.3414\n",
      "Epoch: [11/120]Loss: 0.3894\n",
      "Epoch: [12/120]Loss: 0.4036\n",
      "Epoch: [13/120]Loss: 0.1865\n",
      "Epoch: [14/120]Loss: 0.4126\n",
      "Epoch: [15/120]Loss: 0.3411\n",
      "Epoch: [16/120]Loss: 0.3813\n",
      "Epoch: [17/120]Loss: 0.3754\n",
      "Epoch: [18/120]Loss: 0.0039\n",
      "Epoch: [19/120]Loss: 0.3396\n",
      "Epoch: [20/120]Loss: 0.2482\n",
      "Epoch: [21/120]Loss: 0.0784\n",
      "Epoch: [22/120]Loss: 0.0242\n",
      "Epoch: [23/120]Loss: 0.1317\n",
      "Epoch: [24/120]Loss: 0.4151\n",
      "Epoch: [25/120]Loss: 0.2018\n",
      "Epoch: [26/120]Loss: 0.0213\n",
      "Epoch: [27/120]Loss: 0.0166\n",
      "Epoch: [28/120]Loss: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [29/120]Loss: 0.0209\n",
      "Epoch: [30/120]Loss: 0.0179\n",
      "Epoch: [31/120]Loss: 0.0845\n",
      "Epoch: [32/120]Loss: 0.0387\n",
      "Epoch: [33/120]Loss: 0.0172\n",
      "Epoch: [34/120]Loss: 0.0493\n",
      "Epoch: [35/120]Loss: 0.0758\n",
      "Epoch: [36/120]Loss: 0.0604\n",
      "Epoch: [37/120]Loss: 0.0644\n",
      "Epoch: [38/120]Loss: 0.0708\n",
      "Epoch: [39/120]Loss: 0.0616\n",
      "Epoch: [40/120]Loss: 0.0548\n",
      "Epoch: [41/120]Loss: 0.0023\n",
      "Epoch: [42/120]Loss: 0.0633\n",
      "Epoch: [43/120]Loss: 0.0592\n",
      "Epoch: [44/120]Loss: 0.0587\n",
      "Epoch: [45/120]Loss: 0.0623\n",
      "Epoch: [46/120]Loss: 0.0358\n",
      "Epoch: [47/120]Loss: 0.0122\n",
      "Epoch: [48/120]Loss: 0.0010\n",
      "Epoch: [49/120]Loss: 0.0506\n",
      "Epoch: [50/120]Loss: 0.0220\n",
      "Epoch: [51/120]Loss: 0.0591\n",
      "Epoch: [52/120]Loss: 0.0656\n",
      "Epoch: [53/120]Loss: 0.0536\n",
      "Epoch: [54/120]Loss: 0.0393\n",
      "Epoch: [55/120]Loss: 0.0213\n",
      "Epoch: [56/120]Loss: 0.0106\n",
      "Epoch: [57/120]Loss: 0.0269\n",
      "Epoch: [58/120]Loss: 0.0257\n",
      "Epoch: [59/120]Loss: 0.0132\n",
      "Epoch: [60/120]Loss: 0.0188\n",
      "Epoch: [61/120]Loss: 0.0140\n",
      "Epoch: [62/120]Loss: 0.0082\n",
      "Epoch: [63/120]Loss: 0.0051\n",
      "Epoch: [64/120]Loss: 0.0035\n",
      "Epoch: [65/120]Loss: 0.0025\n",
      "Epoch: [66/120]Loss: 0.0019\n",
      "Epoch: [67/120]Loss: 0.0015\n",
      "Epoch: [68/120]Loss: 0.0012\n",
      "Epoch: [69/120]Loss: 0.0009\n",
      "Epoch: [70/120]Loss: 0.0007\n",
      "Epoch: [71/120]Loss: 0.0006\n",
      "Epoch: [72/120]Loss: 0.0005\n",
      "Epoch: [73/120]Loss: 0.0004\n",
      "Epoch: [74/120]Loss: 0.0004\n",
      "Epoch: [75/120]Loss: 0.0003\n",
      "Epoch: [76/120]Loss: 0.0003\n",
      "Epoch: [77/120]Loss: 0.0002\n",
      "Epoch: [78/120]Loss: 0.0002\n",
      "Epoch: [79/120]Loss: 0.0002\n",
      "Epoch: [80/120]Loss: 0.0001\n",
      "Epoch: [81/120]Loss: 0.0001\n",
      "Epoch: [82/120]Loss: 0.0001\n",
      "Epoch: [83/120]Loss: 0.0001\n",
      "Epoch: [84/120]Loss: 0.0001\n",
      "Epoch: [85/120]Loss: 0.0001\n",
      "Epoch: [86/120]Loss: 0.0001\n",
      "Epoch: [87/120]Loss: 0.0001\n",
      "Epoch: [88/120]Loss: 0.0001\n",
      "Epoch: [89/120]Loss: 0.0000\n",
      "Epoch: [90/120]Loss: 0.0000\n",
      "Epoch: [91/120]Loss: 0.0000\n",
      "Epoch: [92/120]Loss: 0.0000\n",
      "Epoch: [93/120]Loss: 0.0000\n",
      "Epoch: [94/120]Loss: 0.0000\n",
      "Epoch: [95/120]Loss: 0.0000\n",
      "Epoch: [96/120]Loss: 0.0000\n",
      "Epoch: [97/120]Loss: 0.0000\n",
      "Epoch: [98/120]Loss: 0.0000\n",
      "Epoch: [99/120]Loss: 0.0000\n",
      "Epoch: [100/120]Loss: 0.0000\n",
      "Epoch: [101/120]Loss: 0.0000\n",
      "Epoch: [102/120]Loss: 0.0000\n",
      "Epoch: [103/120]Loss: 0.0000\n",
      "Epoch: [104/120]Loss: 0.0000\n",
      "Epoch: [105/120]Loss: 0.0000\n",
      "Epoch: [106/120]Loss: 0.0000\n",
      "Epoch: [107/120]Loss: 0.0000\n",
      "Epoch: [108/120]Loss: 0.0000\n",
      "Epoch: [109/120]Loss: 0.0000\n",
      "Epoch: [110/120]Loss: 0.0000\n",
      "Epoch: [111/120]Loss: 0.0000\n",
      "Epoch: [112/120]Loss: 0.0000\n",
      "Epoch: [113/120]Loss: 0.0000\n",
      "Epoch: [114/120]Loss: 0.0000\n",
      "Epoch: [115/120]Loss: 0.0000\n",
      "Epoch: [116/120]Loss: 0.0000\n",
      "Epoch: [117/120]Loss: 0.0000\n",
      "Epoch: [118/120]Loss: 0.0000\n",
      "Epoch: [119/120]Loss: 0.0000\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([1])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([1]) tensor([1])\n",
      "tensor([1]) tensor([0])\n",
      "Accuracy of the network on the 84 test images: 48.80952380952381 %\n",
      "Loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_list = [0,1,2,3,4,5,0]\n",
    "number_of_corner_list = [1,2,3,4,5,6,6]\n",
    "d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "df2 = pd.DataFrame(data=d2)\n",
    "feature_list = [0, 1]\n",
    "for i in range(2):\n",
    "    feature = feature_list[i]\n",
    "    for i in range(7):\n",
    "        start = start_list[i]\n",
    "        number_of_corner = number_of_corner_list[i]\n",
    "        df_begin = []\n",
    "        num_row = []\n",
    "        num_row_corner = []\n",
    "        percent = []\n",
    "    #     start = 0\n",
    "    #     number_of_corner = 1\n",
    "        f_1 = 'beginner_expert_processedData/beginner/beginner_'\n",
    "        f_3 = '.csv'\n",
    "        num_begin = 19\n",
    "        curveList = [[103.9, 209.3], [316.6, 399.6], [425.3, 517.9], [590.5, 756.9], [1048.7, 1110.5], [1212.3, 1437.1]]\n",
    "\n",
    "        df_concat = pd.DataFrame()\n",
    "\n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "        #     print(num_row)\n",
    "            for idx in range(1, num_begin+1):\n",
    "                tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "                df = pd.read_csv(tmp_file)\n",
    "                df = df.dropna()\n",
    "\n",
    "                tmp = df.astype(float)\n",
    "                tmp['level'] =0\n",
    "                tmp['curve_number'] = curve_num\n",
    "                tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "\n",
    "\n",
    "                num_row.append(np.size(tmpcorner,0)) \n",
    "                num_row_corner.append(np.size(tmpcorner,0)) \n",
    "                df_begin.append(tmpcorner)\n",
    "                df_concat = pd.concat([df_concat,df_begin[idx-1]])      \n",
    "\n",
    "            df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_begin'+'.csv')\n",
    "            df_concat = pd.DataFrame()\n",
    "            df_begin = []\n",
    "\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "        df_exp = []\n",
    "        f_1 = 'beginner_expert_processedData/expert/expert_'\n",
    "        f_3 = '.csv'\n",
    "        num_exp = 19\n",
    "\n",
    "        df_concat = pd.DataFrame()\n",
    "\n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "            for idx in range(1, num_exp+1):\n",
    "                tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "                df = pd.read_csv(tmp_file)\n",
    "                df = df.dropna()\n",
    "\n",
    "                tmp = df.astype(float)\n",
    "                tmp['level'] =1\n",
    "                tmp['curve_number'] = curve_num\n",
    "\n",
    "                tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "                num_row.append(np.size(tmpcorner,0))\n",
    "                num_row_corner.append(np.size(tmpcorner,0)) \n",
    "\n",
    "                df_exp.append(tmpcorner)\n",
    "                df_concat = pd.concat([df_concat,df_exp[idx-1]])\n",
    "            df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_expert'+'.csv')\n",
    "            df_concat = pd.DataFrame()\n",
    "            df_exp = []\n",
    "            num_row_corner = np.array(num_row_corner)\n",
    "            per = np.percentile(num_row_corner, 70).astype('int')\n",
    "        #     np.ndarray.tolist(per)\n",
    "            print(per,type(per))\n",
    "            percent.append(per)\n",
    "            num_row_corner = []\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "\n",
    "        print(num_row)\n",
    "        sequence_length = max(num_row)\n",
    "        print(sequence_length)\n",
    "        mean_row = round(np.mean(num_row))\n",
    "        mean_row = min(num_row)\n",
    "        print(percent)\n",
    "\n",
    "\n",
    "          #######  #######  #######  #######  #######  #######  #######  #######  #######  \n",
    "        if feature == 0:\n",
    "            left_column = [\n",
    "            #'Time',\n",
    "            #     'Distance',\n",
    "            #     'Session Time Left',\n",
    "            #     'Corr Dist','Corr Dist (Unstretched)',\n",
    "                'GPS Latitude','GPS Longitude',\n",
    "                'CG Distance',\n",
    "                'Damper Velocity (Calc) FL','Damper Velocity (Calc) FR','Damper Velocity (Calc) RL',\n",
    "            'Damper Velocity (Calc) RR','Corr Speed','Brake Pos',\n",
    "            'CG Accel Lateral','CG Accel Longitudinal','CG Accel Vertical','CG Height','Camber FL','Camber FR','Camber RL','Camber RR','Car Coord X',\n",
    "            'Car Coord Y','Car Coord Z','Car Pos Norm','Chassis Pitch Angle','Chassis Pitch Rate','Chassis Roll Angle','Chassis Roll Rate',\n",
    "            'Chassis Velocity X','Chassis Velocity Y','Chassis Velocity Z','Chassis Yaw Rate','Drive Train Speed','Engine RPM','Ground Speed',\n",
    "            'Ride Height FL','Ride Height FR','Ride Height RL','Ride Height RR','Road Temp','Self Align Torque FL','Self Align Torque FR',\n",
    "            'Self Align Torque RL','Self Align Torque RR','Steering Angle','Suspension Travel FL','Suspension Travel FR',\n",
    "            'Suspension Travel RL','Suspension Travel RR','Tire Load FL','Tire Load FR','Tire Load RL','Tire Load RR','Tire Loaded Radius FL',\n",
    "            'Tire Loaded Radius FR','Tire Loaded Radius RL','Tire Loaded Radius RR','Tire Pressure FL','Tire Pressure FR','Tire Pressure RL','Tire Pressure RR',\n",
    "            'Tire Rubber Grip FL','Tire Rubber Grip FR','Tire Rubber Grip RL','Tire Rubber Grip RR','Tire Slip Angle FL','Tire Slip Angle FR',\n",
    "            'Tire Slip Angle RL','Tire Slip Angle RR','Tire Slip Ratio FL','Tire Slip Ratio FR','Tire Slip Ratio RL','Tire Slip Ratio RR',\n",
    "            'Tire Temp Core FL','Tire Temp Core FR','Tire Temp Core RL','Tire Temp Core RR','Tire Temp Inner FL','Tire Temp Inner FR',\n",
    "            'Tire Temp Inner RL','Tire Temp Inner RR','Tire Temp Middle FL','Tire Temp Middle FR','Tire Temp Middle RL',\n",
    "            'Tire Temp Middle RR','Tire Temp Outer FL','Tire Temp Outer FR','Tire Temp Outer RL','Tire Temp Outer RR','Toe In FL',\n",
    "            'Toe In FR','Toe In RL','Toe In RR','Wheel Angular Speed FL','Wheel Angular Speed FR','Wheel Angular Speed RL','Wheel Angular Speed RR',\n",
    "            'Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration','level']\n",
    "\n",
    "        else:\n",
    "            left_column = ['Brake Pos', 'Ground Speed', 'Steering Angle', 'Throttle Pos', 'Chassis Yaw Rate', 'Chassis Velocity X',\n",
    "                               'Chassis Velocity Y','Chassis Velocity Z','Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration',\n",
    "                               'CG Distance',\n",
    "                           'level']\n",
    "\n",
    "        #Hyper-parameters\n",
    "        num_epochs = 120\n",
    "        batches = 1\n",
    "        learning_rate = 0.001\n",
    "        input_size = len(left_column)-1 # left column except 'level'\n",
    "        output_size = 2 # Expert and Beginner\n",
    "        hidden_size = 62 # ?\n",
    "        num_layers = 2\n",
    "        num_begin_train = round(num_begin*0.65)*(number_of_corner-start)\n",
    "        num_exp_train = round(num_exp*0.65)*(number_of_corner-start)\n",
    "        num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "        num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "\n",
    "        print(num_begin_train, num_exp_train,num_begin_test,num_exp_test)\n",
    "        aug = 1\n",
    "        ## Define GRU, Loss func and Optimizer\n",
    "        class GRU(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "                super(GRU, self).__init__()\n",
    "                self.num_layers = num_layers\n",
    "                self.hidden_size = hidden_size\n",
    "    #             self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "                self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "                self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            def forward(self, x):\n",
    "                h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "                c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "                out, _ = self.gru(x, h0)\n",
    "    #             out, _ = self.lstm(x, (h0,c0)) \n",
    "                out = out[:, -1, :]\n",
    "                out = self.fc(out)\n",
    "                return out\n",
    "\n",
    "        gru = GRU(input_size, hidden_size, num_layers, output_size)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)  \n",
    "\n",
    "        # gru.fc.weight.data.fill_(1)\n",
    "        # gru.fc.bias.data.fill_(1)\n",
    "    #     print(gru.fc.weight,gru.fc.bias)\n",
    "\n",
    "        ## Data Processing\n",
    "        array_x = []\n",
    "        array_y = []\n",
    "        input_x = []\n",
    "        input_y = []\n",
    "        n_row = []\n",
    "\n",
    "        df_tmp_begin = pd.DataFrame() \n",
    "        df_tmp_exp = pd.DataFrame() \n",
    "        for curve_num in range(start,number_of_corner):\n",
    "        # for curve_num in [0,3]:\n",
    "            df_tmp_begin = pd.concat([df_tmp_begin,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_begin.csv')])\n",
    "            df_tmp_exp   = pd.concat([df_tmp_exp,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_expert.csv')])    \n",
    "        df_curve1 = pd.concat([df_tmp_begin, df_tmp_exp], ignore_index=True) \n",
    "        df_curve1 = df_curve1.loc[:,left_column]\n",
    "        df_curve1_saved = df_curve1.loc[:,left_column] # data backup\n",
    "        df_curve1.to_csv('cornerData/corner_'+'_dfcurve1'+'.csv')\n",
    "\n",
    "\n",
    "\n",
    "        datum = df_curve1_saved\n",
    "        yyy = datum.pop('level')\n",
    "        left = left_column.remove('level')\n",
    "        for i in range(0,num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "        #     x = df_curve1_saved.loc[0:num_row[i]-1\n",
    "            y = yyy.loc[0:num_row[i]-1]\n",
    "        #     y = y.iloc[0]\n",
    "            x_original = datum.loc[0:num_row[i]-1]\n",
    "\n",
    "        #     print(x_original)\n",
    "        #     print(num_row[i],y[0],x_original.iloc[-1,0])\n",
    "\n",
    "        #     scaler = StandardScaler()\n",
    "            scaler = MinMaxScaler()\n",
    "        #     scaler.fit(x_original)\n",
    "        #     scaler.mean_\n",
    "            x_normal = scaler.fit_transform(x_original)\n",
    "            x_normal = scaler.transform(x_original)\n",
    "\n",
    "\n",
    "            x_normal = np.pad(x_normal,[(0,sequence_length-num_row[i]),(0,0)]) #post padding\n",
    "        #     x_normal = np.pad(x_normal,[(sequence_length-num_row[i],0),(0,0)]) #pre padding\n",
    "\n",
    "\n",
    "            x = pd.DataFrame(x_normal,columns=left)\n",
    "            p = i//(num_begin*2)\n",
    "            x = x.truncate(after=percent[p]-1)\n",
    "        #     print(x.shape)\n",
    "        #     print(datum)\n",
    "        #     print(i)\n",
    "        #     print(num_row)\n",
    "        #     print(num_row[i])\n",
    "            datum.drop(range(0,num_row[i]),inplace=True)\n",
    "            datum.reset_index(drop=True, inplace=True)\n",
    "            yyy.drop(range(0,num_row[i]),inplace=True)\n",
    "            yyy.reset_index(drop=True, inplace=True)\n",
    "            # y = x.pop('level')\n",
    "\n",
    "        #     # DATA Augmentation\n",
    "        #     nan = pd.DataFrame(np.nan,columns=range(x.shape[1]),index=range(x.shape[0]))\n",
    "        #     alter = pd.concat([x,nan]).sort_index()\n",
    "        #     alter = alter.interpolate()\n",
    "        #     alter.reset_index(drop=True, inplace=True)\n",
    "        #     x_aug = alter[alter.index%2==1]\n",
    "\n",
    "\n",
    "            array_x.append(x)\n",
    "        #     array_x.append(x_aug)\n",
    "            array_y.append(y)\n",
    "        #     array_y.append(y)\n",
    "\n",
    "\n",
    "        ## Randomize sequence \n",
    "        # sequence = np.arange((num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug/2)\n",
    "        seq_train_begin = np.arange(num_begin_train)\n",
    "        seq_test_begin = np.arange(num_begin_test) + num_begin_train\n",
    "        seq_train_exp = seq_train_begin + num_begin*(number_of_corner-start)\n",
    "        seq_test_exp = seq_test_begin + num_begin*(number_of_corner-start)\n",
    "        print(seq_train_begin,seq_train_exp)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_train_begin)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_test_begin)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_train_exp)\n",
    "        np.random.seed(12)\n",
    "        np.random.shuffle(seq_test_exp)\n",
    "        # seq_train2 = seq_test\n",
    "\n",
    "\n",
    "        sequence = np.concatenate((seq_train_begin, seq_train_exp, seq_test_begin, seq_test_exp), axis=None)\n",
    "        sequence = sequence.astype('int')\n",
    "        # sequence = [0,1,2,15,4,5,6,7,8,9,18,11,12,13,14,19,20,21,34,23,24,25,26,27,28,37,30,31,32,33,3,16,17,10,22,35,36,29]\n",
    "        print(sequence)\n",
    "\n",
    "        # # Data Augmentation\n",
    "        # num_row = pd.Series(num_row)\n",
    "        # num_row = num_row.repeat(2)\n",
    "        # # sequence = pd.Series(sequence)\n",
    "        # # sequence = sequence.repeat(2)\n",
    "        # num_row.reset_index(drop=True, inplace=True)\n",
    "        # # sequence.reset_index(drop=True, inplace=True)\n",
    "        # print(num_row, sequence)\n",
    "\n",
    "        # for i in range(len(percent)):\n",
    "        #     n_row = n_row + [percent[i]]*num_begin*2\n",
    "        for i in sequence:\n",
    "            input_x.append(array_x[i])\n",
    "            input_y.append(array_y[i])\n",
    "            p = i//(num_begin*2)\n",
    "        #     print(p)\n",
    "            n_row = n_row + [percent[p]]\n",
    "\n",
    "\n",
    "        #     n_row.append(num_row[i])\n",
    "        #     n_row.append(sequence_length)\n",
    "        #     n_row.append(mean_row+1-20)\n",
    "        # input_x = np.array(input_x)\n",
    "        # input_y = np.array(input_y)\n",
    "        print(n_row)\n",
    "\n",
    "        ## Train \n",
    "        loss_list = []\n",
    "        iteration_list = []\n",
    "        accuracy_list = []\n",
    "        test_list=[]\n",
    "        count = 0\n",
    "        # torch.backends.cudnn.benchmark = True\n",
    "        print((num_begin_train + num_exp_train)*aug)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i in range(0,(num_begin_train + num_exp_train)*aug):\n",
    "\n",
    "        #         print(i)\n",
    "        #         print(len(input_x))\n",
    "                # array type (numpy) 앞\n",
    "                X = np.array(input_x[i])\n",
    "        #         print(X.shape)\n",
    "        #         X = input_x[i]\n",
    "                X = X.reshape(-1,n_row[i],input_size)\n",
    "\n",
    "                Y = np.array(input_y[i])\n",
    "\n",
    "        #         Y = input_y[i]\n",
    "        #         print(X,X.shape,Y[0])\n",
    "        #         time.sleep(300)\n",
    "                # tensor type (pytorch)\n",
    "                X = torch.from_numpy(X)\n",
    "                X = X.float()\n",
    "                Y = torch.tensor([Y[0]])\n",
    "        #         Y = torch.tensor([Y])\n",
    "                Y = Y.type(torch.LongTensor)\n",
    "        #         Y = Y.float()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = gru(X)\n",
    "                loss = criterion(output, Y)\n",
    "\n",
    "                # Backward and optimize\n",
    "        #         optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            print (f'Epoch: [{epoch}/{num_epochs}]' f'Loss: {loss.item():.4f}')\n",
    "        ## Test\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_samples = 0\n",
    "\n",
    "            for i in range((num_begin_train + num_exp_train)*aug, (num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))*aug):\n",
    "\n",
    "                # array type (numpy)\n",
    "                X = np.array(input_x[i])\n",
    "        #         X = input_x[i]\n",
    "                X = X.reshape(-1,n_row[i],input_size)\n",
    "                Y = np.array(input_y[i])\n",
    "        #         Y = input_y[i]\n",
    "\n",
    "                # tensor type (pytorch)\n",
    "                X = torch.from_numpy(X)\n",
    "                X = X.float()\n",
    "                Y = torch.tensor([Y[0]])\n",
    "        #         Y = torch.tensor(Y)\n",
    "                Y = Y.type(torch.LongTensor)\n",
    "        #         Y = Y.float()\n",
    "                output = gru(X)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                n_samples += Y.size(0)\n",
    "                n_correct += (predicted == Y).sum().item()\n",
    "                print(Y, predicted)\n",
    "\n",
    "\n",
    "\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "        #     print(f'Accuracy of the network on the {(num_begin_test + num_exp_test)*aug} test images: {acc} %')\n",
    "\n",
    "        plt.plot(iteration_list,loss_list)\n",
    "        plt.xlabel(\"Number of iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "    #     plt.show()\n",
    "        if feature == 0:\n",
    "            plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_allFeat.png')\n",
    "        else:\n",
    "            plt.savefig(f'cornerData/loss_VS_epoch_corner{number_of_corner}_{number_of_corner-start}_selectedFeat.png')\n",
    "        print(f'Accuracy of the network on the {num_begin_test + num_exp_test} test images: {acc} %')\n",
    "        print(f'Loss: {loss.item():.4f}')\n",
    "\n",
    "        d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df2 = df2.append(df)\n",
    "\n",
    "    if feature == 0:\n",
    "        df2.to_csv('cornerData/result_gru_allFeature.csv')\n",
    "    else:\n",
    "        df2.to_csv('cornerData/result_gru_selectedFeature.csv')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f472f6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test sample      loss    accuracy  epoch  batch  learning rate  \\\n",
      "0         14.0  0.000028   85.714286  120.0    1.0          0.001   \n",
      "0         14.0  0.000063   92.857143  120.0    1.0          0.001   \n",
      "0         14.0  0.000218   78.571429  120.0    1.0          0.001   \n",
      "0         14.0  0.000044  100.000000  120.0    1.0          0.001   \n",
      "0         14.0  0.000036   85.714286  120.0    1.0          0.001   \n",
      "0         14.0  0.000061   78.571429  120.0    1.0          0.001   \n",
      "0         84.0  0.027570   57.142857  120.0    1.0          0.001   \n",
      "0         14.0  0.000011   78.571429  120.0    1.0          0.001   \n",
      "0         14.0  0.000138   64.285714  120.0    1.0          0.001   \n",
      "0         14.0  0.000196  100.000000  120.0    1.0          0.001   \n",
      "0         14.0  0.000034  100.000000  120.0    1.0          0.001   \n",
      "0         14.0  0.000049   85.714286  120.0    1.0          0.001   \n",
      "0         14.0  0.002862   85.714286  120.0    1.0          0.001   \n",
      "0         84.0  0.000002   48.809524  120.0    1.0          0.001   \n",
      "0         88.0  4.000002   52.809524  124.0    5.0          4.001   \n",
      "\n",
      "   hidden size  hidden_layer  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         62.0           2.0  \n",
      "0         66.0           6.0  \n"
     ]
    }
   ],
   "source": [
    "# df2.to_csv('cornerData/result_gru.csv')\n",
    "# d2 = {'test sample': [], 'loss': [], 'accuracy': [], 'epoch' : [], 'batch':[],'learning rate' :[], 'hidden size':[],'hidden_layer':[]}\n",
    "# df2 = pd.DataFrame(data=d2)\n",
    "d = {'test sample': [num_begin_test + num_exp_test], 'loss': [loss.item()], 'accuracy': [acc], 'epoch' : [num_epochs], 'batch':[batches],'learning rate' :[learning_rate], 'hidden size':[hidden_size],'hidden_layer':[num_layers]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df2 = df2.append(df+4)\n",
    "print(df2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
