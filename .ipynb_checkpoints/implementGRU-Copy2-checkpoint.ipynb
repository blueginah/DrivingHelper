{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make each level to each Curve CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_begin = []\n",
    "num_row = []\n",
    "start = 1\n",
    "number_of_corner = 2\n",
    "f_1 = 'beginner_expert_processedData/beginner/beginner_'\n",
    "f_3 = '.csv'\n",
    "num_begin = 19\n",
    "curveList = [[103.9, 209.3], [316.6, 399.6], [425.3, 517.9], [590.5, 756.9], [1048.7, 1110.5], [1212.3, 1437.1]]\n",
    "\n",
    "df_concat = pd.DataFrame()\n",
    "\n",
    "for curve_num in range(start,number_of_corner):\n",
    "#     print(num_row)\n",
    "    for idx in range(1, num_begin+1):\n",
    "        tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "        df = pd.read_csv(tmp_file)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        tmp = df.astype(float)\n",
    "        tmp['level'] =0\n",
    "        \n",
    "        tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "        num_row.append(np.size(tmpcorner,0)) \n",
    "        \n",
    "        df_begin.append(tmpcorner)\n",
    "        df_concat = pd.concat([df_concat,df_begin[idx-1]])      \n",
    "        \n",
    "    df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_begin'+'.csv')\n",
    "    df_concat = pd.DataFrame()\n",
    "    df_begin = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = []\n",
    "f_1 = 'beginner_expert_processedData/expert/expert_'\n",
    "f_3 = '.csv'\n",
    "num_exp = 19\n",
    "\n",
    "df_concat = pd.DataFrame()\n",
    "\n",
    "for curve_num in range(start,number_of_corner):\n",
    "    for idx in range(1, num_exp+1):\n",
    "        tmp_file = f_1+str(idx)+'_new2'+f_3\n",
    "        df = pd.read_csv(tmp_file)\n",
    "        df = df.dropna()\n",
    "\n",
    "        tmp = df.astype(float)\n",
    "        tmp['level'] =1\n",
    "\n",
    "        tmpcorner = tmp[(tmp['Distance'] >= curveList[curve_num][0]) & (tmp['Distance'] <= curveList[curve_num][1])]\n",
    "        num_row.append(np.size(tmpcorner,0)) \n",
    "\n",
    "        df_exp.append(tmpcorner)\n",
    "        df_concat = pd.concat([df_concat,df_exp[idx-1]])\n",
    "    \n",
    "    df_concat.to_csv('cornerData/corner_'+str(curve_num+1)+'_expert'+'.csv')\n",
    "    df_concat = pd.DataFrame()\n",
    "    df_exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 57, 49, 43, 50, 54, 61, 58, 50, 51, 59, 68, 50, 48, 69, 59, 60, 48, 52, 51, 45, 46, 50, 53, 48, 47, 46, 44, 45, 52, 47, 45, 46, 47, 47, 43, 44, 43]\n"
     ]
    }
   ],
   "source": [
    "print(num_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  2  7 33 21 22 29 24  8 18  0 11  3 31  9 27 19 26 30 20  1 35 10 12\n",
      " 13 28 17  5 25 14 16 32 37  6 34 23 15 36]\n",
      "Loss: 0.7007\n",
      "Loss: 0.3655\n",
      "Loss: 0.2331\n",
      "Loss: 1.7054\n",
      "Loss: 2.0704\n",
      "Loss: 2.2956\n",
      "Loss: 1.9491\n",
      "Loss: 1.2760\n",
      "Loss: 0.7138\n",
      "Loss: 0.6095\n",
      "Loss: 0.5020\n",
      "Loss: 0.4944\n",
      "Loss: 0.8530\n",
      "Loss: 0.5867\n",
      "Loss: 1.0179\n",
      "Loss: 0.4854\n",
      "Loss: 0.7423\n",
      "Loss: 0.3736\n",
      "Loss: 0.7807\n",
      "Loss: 0.5351\n",
      "Loss: 0.8525\n",
      "Loss: 0.3171\n",
      "Loss: 0.7174\n",
      "Loss: 1.0213\n",
      "Loss: 1.1083\n",
      "Loss: 0.9507\n",
      "Loss: 0.8403\n",
      "Loss: 0.7235\n",
      "Loss: 0.3633\n",
      "Loss: 0.9992\n",
      "Loss: 0.6053\n",
      "Loss: 0.6167\n",
      "Loss: 0.3612\n",
      "Loss: 0.4663\n",
      "Loss: 0.7488\n",
      "Loss: 0.6114\n",
      "Loss: 0.7996\n",
      "Loss: 1.3145\n",
      "Loss: 1.3917\n",
      "Loss: 0.8773\n",
      "Loss: 0.7526\n",
      "Loss: 0.4542\n",
      "Loss: 0.3393\n",
      "Loss: 0.3123\n",
      "Loss: 0.5537\n",
      "Loss: 0.8810\n",
      "Loss: 0.7946\n",
      "Loss: 0.5366\n",
      "Loss: 0.9303\n",
      "Loss: 0.5470\n",
      "Loss: 0.9809\n",
      "Loss: 0.7785\n",
      "Loss: 0.4608\n",
      "Loss: 0.3525\n",
      "Loss: 0.4263\n",
      "Loss: 0.6468\n",
      "Loss: 0.6790\n",
      "Loss: 1.0809\n",
      "Loss: 0.5733\n",
      "Loss: 0.5836\n",
      "Loss: 0.3533\n",
      "Loss: 1.0891\n",
      "Loss: 0.5964\n",
      "Loss: 0.6148\n",
      "Loss: 0.3699\n",
      "Loss: 0.5506\n",
      "Loss: 0.7818\n",
      "Loss: 0.4367\n",
      "Loss: 0.7293\n",
      "Loss: 1.2282\n",
      "Loss: 1.3113\n",
      "Loss: 0.8235\n",
      "Loss: 0.8138\n",
      "Loss: 0.6404\n",
      "Loss: 0.3219\n",
      "Loss: 0.3344\n",
      "Loss: 0.5999\n",
      "Loss: 0.9733\n",
      "Loss: 0.6232\n",
      "Loss: 0.5915\n",
      "Loss: 0.7962\n",
      "Loss: 0.5960\n",
      "Loss: 0.9471\n",
      "Loss: 0.6909\n",
      "Loss: 0.4587\n",
      "Loss: 0.3862\n",
      "Loss: 0.5655\n",
      "Loss: 0.6929\n",
      "Loss: 0.7578\n",
      "Loss: 0.9630\n",
      "Loss: 0.5157\n",
      "Loss: 0.5888\n",
      "Loss: 0.4169\n",
      "Loss: 1.1525\n",
      "Loss: 0.5408\n",
      "Loss: 0.4469\n",
      "Loss: 0.3547\n",
      "Loss: 0.4336\n",
      "Loss: 0.6256\n",
      "Loss: 0.4515\n",
      "Loss: 0.8448\n",
      "Loss: 1.5202\n",
      "Loss: 1.5558\n",
      "Loss: 0.7127\n",
      "Loss: 0.8634\n",
      "Loss: 0.6917\n",
      "Loss: 0.2881\n",
      "Loss: 0.2478\n",
      "Loss: 0.6118\n",
      "Loss: 0.7496\n",
      "Loss: 0.7808\n",
      "Loss: 0.4076\n",
      "Loss: 0.7074\n",
      "Loss: 0.5308\n",
      "Loss: 0.7392\n",
      "Loss: 0.7179\n",
      "Loss: 0.4864\n",
      "Loss: 0.2745\n",
      "Loss: 0.5571\n",
      "Loss: 0.7176\n",
      "Loss: 0.5779\n",
      "Loss: 0.9203\n",
      "Loss: 0.4810\n",
      "Loss: 0.4198\n",
      "Loss: 0.3973\n",
      "Loss: 1.1091\n",
      "Loss: 0.5167\n",
      "Loss: 0.4489\n",
      "Loss: 0.3043\n",
      "Loss: 0.3717\n",
      "Loss: 0.6318\n",
      "Loss: 0.5855\n",
      "Loss: 0.9938\n",
      "Loss: 1.6419\n",
      "Loss: 1.5549\n",
      "Loss: 0.9029\n",
      "Loss: 0.8962\n",
      "Loss: 0.7967\n",
      "Loss: 0.3610\n",
      "Loss: 0.2214\n",
      "Loss: 0.5518\n",
      "Loss: 0.8973\n",
      "Loss: 0.9348\n",
      "Loss: 0.2844\n",
      "Loss: 0.6821\n",
      "Loss: 0.4519\n",
      "Loss: 0.8559\n",
      "Loss: 0.6796\n",
      "Loss: 0.4629\n",
      "Loss: 0.2354\n",
      "Loss: 0.4407\n",
      "Loss: 0.6448\n",
      "Loss: 0.5977\n",
      "Loss: 0.8930\n",
      "Loss: 0.5464\n",
      "Loss: 0.4222\n",
      "Loss: 0.3367\n",
      "Loss: 1.2508\n",
      "Loss: 0.4623\n",
      "Loss: 0.4288\n",
      "Loss: 0.3467\n",
      "Loss: 0.5072\n",
      "Loss: 0.7504\n",
      "Loss: 0.4344\n",
      "Loss: 0.8201\n",
      "Loss: 1.5082\n",
      "Loss: 1.4582\n",
      "Loss: 0.6747\n",
      "Loss: 0.9437\n",
      "Loss: 0.7790\n",
      "Loss: 0.2985\n",
      "Loss: 0.1917\n",
      "Loss: 0.5020\n",
      "Loss: 0.9092\n",
      "Loss: 0.8438\n",
      "Loss: 0.3920\n",
      "Loss: 0.7763\n",
      "Loss: 0.4969\n",
      "Loss: 0.8205\n",
      "Loss: 0.7918\n",
      "Loss: 0.3517\n",
      "Loss: 0.2682\n",
      "Loss: 0.4101\n",
      "Loss: 0.5988\n",
      "Loss: 0.5149\n",
      "Loss: 0.7771\n",
      "Loss: 0.6043\n",
      "Loss: 0.4586\n",
      "Loss: 0.3609\n",
      "Loss: 1.1069\n",
      "Loss: 0.4819\n",
      "Loss: 0.4773\n",
      "Loss: 0.4046\n",
      "Loss: 0.5567\n",
      "Loss: 0.7952\n",
      "Loss: 0.3619\n",
      "Loss: 0.7375\n",
      "Loss: 1.5812\n",
      "Loss: 1.3494\n",
      "Loss: 0.5687\n",
      "Loss: 1.0394\n",
      "Loss: 0.9219\n",
      "Loss: 0.2650\n",
      "Loss: 0.2146\n",
      "Loss: 0.8192\n",
      "Loss: 0.7521\n",
      "Loss: 0.9392\n",
      "Loss: 0.3387\n",
      "Loss: 0.7614\n",
      "Loss: 0.4442\n",
      "Loss: 0.9178\n",
      "Loss: 0.8143\n",
      "Loss: 0.3000\n",
      "Loss: 0.2211\n",
      "Loss: 0.3272\n",
      "Loss: 0.4969\n",
      "Loss: 0.2976\n",
      "Loss: 1.1149\n",
      "Loss: 0.4425\n",
      "Loss: 0.3690\n",
      "Loss: 0.3031\n",
      "Loss: 1.3076\n",
      "Loss: 0.4533\n",
      "Loss: 0.5648\n",
      "Loss: 0.2963\n",
      "Loss: 0.4759\n",
      "Loss: 0.8726\n",
      "Loss: 0.4236\n",
      "Loss: 0.6655\n",
      "Loss: 1.5013\n",
      "Loss: 1.4031\n",
      "Loss: 0.7133\n",
      "Loss: 1.0574\n",
      "Loss: 0.8146\n",
      "Loss: 0.2592\n",
      "Loss: 0.1969\n",
      "Loss: 0.5861\n",
      "Loss: 0.7369\n",
      "Loss: 0.8812\n",
      "Loss: 0.2437\n",
      "Loss: 0.7170\n",
      "Loss: 0.3444\n",
      "Loss: 0.7770\n",
      "Loss: 0.7615\n",
      "Loss: 0.3979\n",
      "Loss: 0.1977\n",
      "Loss: 0.3987\n",
      "Loss: 0.5446\n",
      "Loss: 0.3656\n",
      "Loss: 0.8841\n",
      "Loss: 0.5333\n",
      "Loss: 0.3807\n",
      "Loss: 0.3002\n",
      "Loss: 1.1055\n",
      "Loss: 0.4250\n",
      "Loss: 0.4060\n",
      "Loss: 0.3015\n",
      "Loss: 0.4746\n",
      "Loss: 0.7017\n",
      "Loss: 0.4171\n",
      "Loss: 0.5333\n",
      "Loss: 1.2911\n",
      "Loss: 1.5400\n",
      "Loss: 0.6383\n",
      "Loss: 1.1322\n",
      "Loss: 1.0018\n",
      "Loss: 0.2639\n",
      "Loss: 0.2528\n",
      "Loss: 0.7601\n",
      "Loss: 0.7342\n",
      "Loss: 0.9085\n",
      "Loss: 0.3020\n",
      "Loss: 0.7869\n",
      "Loss: 0.3103\n",
      "Loss: 0.7308\n",
      "Loss: 0.7417\n",
      "Loss: 0.3646\n",
      "Loss: 0.2351\n",
      "Loss: 0.2731\n",
      "Loss: 0.5293\n",
      "Loss: 0.4015\n",
      "Loss: 0.9761\n",
      "Loss: 0.5126\n",
      "Loss: 0.2797\n",
      "Loss: 0.3114\n",
      "Loss: 1.0826\n",
      "Loss: 0.3853\n",
      "Loss: 0.5508\n",
      "Loss: 0.2201\n",
      "Loss: 0.4308\n",
      "Loss: 0.6675\n",
      "Loss: 0.2945\n",
      "Loss: 0.7172\n",
      "Loss: 1.3877\n",
      "Loss: 1.3012\n",
      "Loss: 0.5656\n",
      "Loss: 1.0038\n",
      "Loss: 0.8877\n",
      "Loss: 0.2380\n",
      "Loss: 0.2338\n",
      "Loss: 0.7167\n",
      "Loss: 0.6782\n",
      "Loss: 0.7840\n",
      "Loss: 0.3065\n",
      "Loss: 0.6309\n",
      "Loss: 0.2818\n",
      "Loss: 0.6215\n",
      "Loss: 0.6926\n",
      "Loss: 0.3717\n",
      "Loss: 0.1990\n",
      "Loss: 0.3035\n",
      "Loss: 0.6413\n",
      "Loss: 0.2865\n",
      "Loss: 0.8635\n",
      "Loss: 0.5930\n",
      "Loss: 0.3404\n",
      "Loss: 0.3419\n",
      "Loss: 0.9577\n",
      "Loss: 0.3274\n",
      "Loss: 0.5713\n",
      "Loss: 0.1513\n",
      "Loss: 0.4211\n",
      "Loss: 0.5877\n",
      "Loss: 0.2798\n",
      "Loss: 0.7657\n",
      "Loss: 1.4230\n",
      "Loss: 1.4660\n",
      "Loss: 0.6270\n",
      "Loss: 0.8289\n",
      "Loss: 0.8809\n",
      "Loss: 0.1748\n",
      "Loss: 0.1383\n",
      "Loss: 0.7952\n",
      "Loss: 0.6310\n",
      "Loss: 0.6602\n",
      "Loss: 0.2419\n",
      "Loss: 0.6821\n",
      "Loss: 0.2277\n",
      "Loss: 0.5356\n",
      "Loss: 0.9173\n",
      "Loss: 0.3832\n",
      "Loss: 0.2018\n",
      "Loss: 0.2757\n",
      "Loss: 0.6167\n",
      "Loss: 0.1772\n",
      "Loss: 0.8141\n",
      "Loss: 0.4766\n",
      "Loss: 0.3141\n",
      "Loss: 0.4258\n",
      "Loss: 0.9951\n",
      "Loss: 0.4720\n",
      "Loss: 0.5834\n",
      "Loss: 0.2201\n",
      "Loss: 0.5890\n",
      "Loss: 0.5586\n",
      "Loss: 0.6954\n",
      "Loss: 0.9007\n",
      "Loss: 1.2191\n",
      "Loss: 1.2059\n",
      "Loss: 0.6112\n",
      "Loss: 0.9588\n",
      "Loss: 0.9113\n",
      "Loss: 0.2832\n",
      "Loss: 0.2761\n",
      "Loss: 1.1906\n",
      "Loss: 0.4643\n",
      "Loss: 1.1604\n",
      "Loss: 0.2437\n",
      "Loss: 0.6866\n",
      "Loss: 0.2550\n",
      "Loss: 0.7766\n",
      "Loss: 0.5864\n",
      "Loss: 0.4126\n",
      "Loss: 0.2079\n",
      "Loss: 0.2538\n",
      "Loss: 0.7390\n",
      "Loss: 0.1466\n",
      "Loss: 0.7433\n",
      "Loss: 0.3320\n",
      "Loss: 0.2475\n",
      "Loss: 0.2727\n",
      "Loss: 1.4674\n",
      "Loss: 0.3902\n",
      "Loss: 0.3530\n",
      "Loss: 0.1323\n",
      "Loss: 0.3869\n",
      "Loss: 0.7073\n",
      "Loss: 0.3830\n",
      "Loss: 0.7036\n",
      "Loss: 1.7144\n",
      "Loss: 0.9152\n",
      "Loss: 0.3136\n",
      "Loss: 0.5936\n",
      "Loss: 0.2884\n",
      "Loss: 0.1522\n",
      "Loss: 0.2167\n",
      "Loss: 1.1007\n",
      "Loss: 1.5463\n",
      "Loss: 1.3640\n",
      "Loss: 0.3636\n",
      "Loss: 0.9422\n",
      "Loss: 0.6611\n",
      "Loss: 0.9796\n",
      "Loss: 0.6839\n",
      "Loss: 0.3315\n",
      "Loss: 0.3675\n",
      "Loss: 0.3523\n",
      "Loss: 1.0216\n",
      "Loss: 0.3257\n",
      "Loss: 0.8127\n",
      "Loss: 0.5254\n",
      "Loss: 0.4192\n",
      "Loss: 0.2800\n",
      "Loss: 1.4601\n",
      "Loss: 0.3767\n",
      "Loss: 0.4705\n",
      "Loss: 0.2023\n",
      "Loss: 0.4576\n",
      "Loss: 0.5462\n",
      "Loss: 0.6484\n",
      "Loss: 0.8694\n",
      "Loss: 1.8569\n",
      "Loss: 1.8786\n",
      "Loss: 0.6577\n",
      "Loss: 1.0119\n",
      "Loss: 0.8407\n",
      "Loss: 0.2911\n",
      "Loss: 0.2093\n",
      "Loss: 0.8478\n",
      "Loss: 0.6986\n",
      "Loss: 1.0926\n",
      "Loss: 0.4225\n",
      "Loss: 0.9316\n",
      "Loss: 0.4397\n",
      "Loss: 0.9342\n",
      "Loss: 0.6701\n",
      "Loss: 0.5827\n",
      "Loss: 0.2531\n",
      "Loss: 0.5119\n",
      "Loss: 0.9791\n",
      "Loss: 0.3208\n",
      "Loss: 0.5986\n",
      "Loss: 0.5892\n",
      "Loss: 0.5163\n",
      "Loss: 0.2751\n",
      "Loss: 1.1833\n",
      "Loss: 0.4502\n",
      "Loss: 0.4306\n",
      "Loss: 0.2553\n",
      "Loss: 0.5931\n",
      "Loss: 0.6518\n",
      "Loss: 0.5932\n",
      "Loss: 0.9601\n",
      "Loss: 1.4992\n",
      "Loss: 1.7071\n",
      "Loss: 0.7000\n",
      "Loss: 0.7411\n",
      "Loss: 0.8166\n",
      "Loss: 0.2495\n",
      "Loss: 0.1496\n",
      "Loss: 0.7360\n",
      "Loss: 0.7388\n",
      "Loss: 0.9697\n",
      "Loss: 0.4489\n",
      "Loss: 0.8880\n",
      "Loss: 0.4679\n",
      "Loss: 0.9685\n",
      "Loss: 0.6442\n",
      "Loss: 0.4924\n",
      "Loss: 0.2719\n",
      "Loss: 0.4139\n",
      "Loss: 1.0142\n",
      "Loss: 0.1911\n",
      "Loss: 0.6041\n",
      "Loss: 0.5171\n",
      "Loss: 0.4604\n",
      "Loss: 0.2548\n",
      "Loss: 1.4220\n",
      "Loss: 0.4608\n",
      "Loss: 0.3702\n",
      "Loss: 0.2519\n",
      "Loss: 0.6459\n",
      "Loss: 0.7127\n",
      "Loss: 0.5117\n",
      "Loss: 0.7269\n",
      "Loss: 1.4816\n",
      "Loss: 1.6949\n",
      "Loss: 0.6880\n",
      "Loss: 0.7125\n",
      "Loss: 0.7391\n",
      "Loss: 0.2205\n",
      "Loss: 0.1193\n",
      "Loss: 0.6701\n",
      "Loss: 0.7766\n",
      "Loss: 0.9386\n",
      "Loss: 0.4443\n",
      "Loss: 0.8771\n",
      "Loss: 0.4752\n",
      "Loss: 0.9715\n",
      "Loss: 0.6898\n",
      "Loss: 0.4426\n",
      "Loss: 0.2749\n",
      "Loss: 0.3694\n",
      "Loss: 0.9671\n",
      "Loss: 0.1514\n",
      "Loss: 0.5817\n",
      "Loss: 0.4987\n",
      "Loss: 0.4492\n",
      "Loss: 0.2491\n",
      "Loss: 1.4365\n",
      "Loss: 0.5013\n",
      "Loss: 0.3432\n",
      "Loss: 0.2739\n",
      "Loss: 0.6960\n",
      "Loss: 0.7688\n",
      "Loss: 0.4556\n",
      "Loss: 0.6399\n",
      "Loss: 1.3094\n",
      "Loss: 1.4925\n",
      "Loss: 0.6211\n",
      "Loss: 0.7506\n",
      "Loss: 0.7632\n",
      "Loss: 0.2242\n",
      "Loss: 0.1101\n",
      "Loss: 0.6526\n",
      "Loss: 0.7548\n",
      "Loss: 0.9533\n",
      "Loss: 0.4339\n",
      "Loss: 0.8175\n",
      "Loss: 0.4151\n",
      "Loss: 0.9818\n",
      "Loss: 0.7553\n",
      "Loss: 0.3742\n",
      "Loss: 0.2812\n",
      "Loss: 0.3125\n",
      "Loss: 0.8808\n",
      "Loss: 0.1033\n",
      "Loss: 0.5505\n",
      "Loss: 0.3977\n",
      "Loss: 0.3870\n",
      "Loss: 0.2502\n",
      "Loss: 1.4128\n",
      "Loss: 0.4769\n",
      "Loss: 0.3366\n",
      "Loss: 0.2395\n",
      "Loss: 0.6582\n",
      "Loss: 0.7301\n",
      "Loss: 0.4343\n",
      "Loss: 0.6332\n",
      "Loss: 1.3606\n",
      "Loss: 1.5210\n",
      "Loss: 0.5737\n",
      "Loss: 0.7851\n",
      "Loss: 0.8196\n",
      "Loss: 0.2161\n",
      "Loss: 0.1013\n",
      "Loss: 0.7064\n",
      "Loss: 0.6801\n",
      "Loss: 1.0485\n",
      "Loss: 0.3721\n",
      "Loss: 0.7071\n",
      "Loss: 0.3727\n",
      "Loss: 0.9029\n",
      "Loss: 0.7511\n",
      "Loss: 0.3545\n",
      "Loss: 0.2645\n",
      "Loss: 0.3244\n",
      "Loss: 0.8578\n",
      "Loss: 0.0826\n",
      "Loss: 0.4989\n",
      "Loss: 0.3719\n",
      "Loss: 0.3714\n",
      "Loss: 0.2620\n",
      "Loss: 1.3526\n",
      "Loss: 0.4456\n",
      "Loss: 0.3454\n",
      "Loss: 0.2143\n",
      "Loss: 0.6689\n",
      "Loss: 0.6800\n",
      "Loss: 0.3993\n",
      "Loss: 0.6459\n",
      "Loss: 1.3073\n",
      "Loss: 1.4876\n",
      "Loss: 0.5673\n",
      "Loss: 0.7339\n",
      "Loss: 0.8511\n",
      "Loss: 0.1892\n",
      "Loss: 0.0915\n",
      "Loss: 0.7511\n",
      "Loss: 0.6306\n",
      "Loss: 0.9985\n",
      "Loss: 0.3639\n",
      "Loss: 0.6697\n",
      "Loss: 0.3730\n",
      "Loss: 0.8408\n",
      "Loss: 0.7924\n",
      "Loss: 0.3214\n",
      "Loss: 0.2570\n",
      "Loss: 0.2814\n",
      "Loss: 0.9036\n",
      "Loss: 0.0609\n",
      "Loss: 0.4456\n",
      "Loss: 0.3015\n",
      "Loss: 0.3228\n",
      "Loss: 0.2574\n",
      "Loss: 1.2927\n",
      "Loss: 0.4515\n",
      "Loss: 0.3532\n",
      "Loss: 0.1742\n",
      "Loss: 0.6011\n",
      "Loss: 0.6406\n",
      "Loss: 0.4275\n",
      "Loss: 0.6471\n",
      "Loss: 1.2984\n",
      "Loss: 1.5090\n",
      "Loss: 0.5809\n",
      "Loss: 0.7287\n",
      "Loss: 0.9042\n",
      "Loss: 0.1623\n",
      "Loss: 0.0734\n",
      "Loss: 0.7036\n",
      "Loss: 0.5873\n",
      "Loss: 1.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2988\n",
      "Loss: 0.6475\n",
      "Loss: 0.3189\n",
      "Loss: 0.7490\n",
      "Loss: 0.7424\n",
      "Loss: 0.3003\n",
      "Loss: 0.2168\n",
      "Loss: 0.2454\n",
      "Loss: 0.8308\n",
      "Loss: 0.0449\n",
      "Loss: 0.3198\n",
      "Loss: 0.2786\n",
      "Loss: 0.3181\n",
      "Loss: 0.2528\n",
      "Loss: 1.3001\n",
      "Loss: 0.4239\n",
      "Loss: 0.3896\n",
      "Loss: 0.1607\n",
      "Loss: 0.4782\n",
      "Loss: 0.5569\n",
      "Loss: 0.4353\n",
      "Loss: 0.6617\n",
      "Loss: 1.4498\n",
      "Loss: 1.5429\n",
      "Loss: 0.5917\n",
      "Loss: 0.6981\n",
      "Loss: 0.8006\n",
      "Loss: 0.1861\n",
      "Loss: 0.0763\n",
      "Loss: 0.7355\n",
      "Loss: 0.5348\n",
      "Loss: 1.2486\n",
      "Loss: 0.2596\n",
      "Loss: 0.5422\n",
      "Loss: 0.2812\n",
      "Loss: 0.5868\n",
      "Loss: 0.7612\n",
      "Loss: 0.3198\n",
      "Loss: 0.2059\n",
      "Loss: 0.2442\n",
      "Loss: 0.8276\n",
      "Loss: 0.0367\n",
      "Loss: 0.2237\n",
      "Loss: 0.2478\n",
      "Loss: 0.2776\n",
      "Loss: 0.2468\n",
      "Loss: 1.1994\n",
      "Loss: 0.4274\n",
      "Loss: 0.3682\n",
      "Loss: 0.1493\n",
      "Loss: 0.4938\n",
      "Loss: 0.5442\n",
      "Loss: 0.3925\n",
      "Loss: 0.6253\n",
      "Loss: 1.4310\n",
      "Loss: 1.5334\n",
      "Loss: 0.5542\n",
      "Loss: 0.6419\n",
      "Loss: 0.7732\n",
      "Loss: 0.1984\n",
      "Loss: 0.0614\n",
      "Loss: 0.7323\n",
      "Loss: 0.4725\n",
      "Loss: 1.2172\n",
      "Loss: 0.2336\n",
      "Loss: 0.6335\n",
      "Loss: 0.2841\n",
      "Loss: 0.5457\n",
      "Loss: 0.6887\n",
      "Loss: 0.3340\n",
      "Loss: 0.1812\n",
      "Loss: 0.2879\n",
      "Loss: 0.9674\n",
      "Loss: 0.0264\n",
      "Loss: 0.1523\n",
      "Loss: 0.2219\n",
      "Loss: 0.2705\n",
      "Loss: 0.2088\n",
      "Loss: 0.7783\n",
      "Loss: 0.3315\n",
      "Loss: 0.3574\n",
      "Loss: 0.1024\n",
      "Loss: 0.4530\n",
      "Loss: 0.4446\n",
      "Loss: 0.3391\n",
      "Loss: 0.9364\n",
      "Loss: 1.4116\n",
      "Loss: 1.5115\n",
      "Loss: 0.5658\n",
      "Loss: 0.6334\n",
      "Loss: 0.8876\n",
      "Loss: 0.1454\n",
      "Loss: 0.0556\n",
      "Loss: 0.8634\n",
      "Loss: 0.3484\n",
      "Loss: 1.3052\n",
      "Loss: 0.1737\n",
      "Loss: 0.3187\n",
      "Loss: 0.2443\n",
      "Loss: 0.5413\n",
      "Loss: 0.7197\n",
      "Loss: 0.2518\n",
      "Loss: 0.2024\n",
      "Loss: 0.1251\n",
      "Loss: 1.1554\n",
      "Loss: 0.0196\n",
      "Loss: 0.1580\n",
      "Loss: 0.2811\n",
      "Loss: 0.1889\n",
      "Loss: 0.1486\n",
      "Loss: 1.5785\n",
      "Loss: 0.2873\n",
      "Loss: 0.1504\n",
      "Loss: 0.0694\n",
      "Loss: 0.4982\n",
      "Loss: 0.9862\n",
      "Loss: 1.1629\n",
      "Loss: 0.9127\n",
      "Loss: 1.9578\n",
      "Loss: 1.8440\n",
      "Loss: 0.6070\n",
      "Loss: 0.4619\n",
      "Loss: 0.6688\n",
      "Loss: 0.1638\n",
      "Loss: 0.0714\n",
      "Loss: 0.7486\n",
      "Loss: 0.6834\n",
      "Loss: 0.7621\n",
      "Loss: 0.2985\n",
      "Loss: 0.3843\n",
      "Loss: 0.3206\n",
      "Loss: 0.4853\n",
      "Loss: 0.5656\n",
      "Loss: 0.4174\n",
      "Loss: 0.1952\n",
      "Loss: 0.2060\n",
      "Loss: 0.8689\n",
      "Loss: 0.0569\n",
      "Loss: 0.4742\n",
      "Loss: 0.3312\n",
      "Loss: 0.4302\n",
      "Loss: 0.3618\n",
      "Loss: 1.3265\n",
      "Loss: 0.4314\n",
      "Loss: 0.4664\n",
      "Loss: 0.1575\n",
      "Loss: 0.5933\n",
      "Loss: 0.7775\n",
      "Loss: 0.6308\n",
      "Loss: 0.8077\n",
      "Loss: 1.2392\n",
      "Loss: 1.2505\n",
      "Loss: 0.6727\n",
      "Loss: 1.2089\n",
      "Loss: 0.8714\n",
      "Loss: 0.1786\n",
      "Loss: 0.0425\n",
      "Loss: 0.8850\n",
      "Loss: 0.6066\n",
      "Loss: 0.7691\n",
      "Loss: 0.4109\n",
      "Loss: 0.2927\n",
      "Loss: 0.4774\n",
      "Loss: 0.5493\n",
      "Loss: 0.6115\n",
      "Loss: 0.2668\n",
      "Loss: 0.2350\n",
      "Loss: 0.0973\n",
      "Loss: 0.6937\n",
      "Loss: 0.0285\n",
      "Loss: 0.3548\n",
      "Loss: 0.2936\n",
      "Loss: 0.2773\n",
      "Loss: 0.2263\n",
      "Loss: 1.7271\n",
      "Loss: 0.3469\n",
      "Loss: 0.2413\n",
      "Loss: 0.1046\n",
      "Loss: 0.8407\n",
      "Loss: 1.4599\n",
      "Loss: 0.2895\n",
      "Loss: 0.4035\n",
      "Loss: 0.9479\n",
      "Loss: 1.3629\n",
      "Loss: 0.4590\n",
      "Loss: 1.0900\n",
      "Loss: 1.2341\n",
      "Loss: 0.0678\n",
      "Loss: 0.0392\n",
      "Loss: 0.9045\n",
      "Loss: 0.6132\n",
      "Loss: 0.7106\n",
      "Loss: 0.4233\n",
      "Loss: 0.3426\n",
      "Loss: 0.6755\n",
      "Loss: 0.4451\n",
      "Loss: 0.6590\n",
      "Loss: 0.2382\n",
      "Loss: 0.4558\n",
      "Loss: 0.0889\n",
      "Loss: 0.5749\n",
      "Loss: 0.0173\n",
      "Loss: 0.1996\n",
      "Loss: 0.2386\n",
      "Loss: 0.2623\n",
      "Loss: 0.4109\n",
      "Loss: 1.1491\n",
      "Loss: 0.3463\n",
      "Loss: 0.4965\n",
      "Loss: 0.1224\n",
      "Loss: 0.4403\n",
      "Loss: 0.8551\n",
      "Loss: 0.5224\n",
      "Loss: 0.6656\n",
      "Loss: 0.8763\n",
      "Loss: 1.2174\n",
      "Loss: 0.5556\n",
      "Loss: 0.9894\n",
      "Loss: 1.2222\n",
      "Loss: 0.1246\n",
      "Loss: 0.0344\n",
      "Loss: 1.0121\n",
      "Loss: 0.5348\n",
      "Loss: 0.9847\n",
      "Loss: 0.2385\n",
      "Loss: 0.4781\n",
      "Loss: 0.5555\n",
      "Loss: 0.2584\n",
      "Loss: 0.4733\n",
      "Loss: 0.2644\n",
      "Loss: 0.2831\n",
      "Loss: 0.0828\n",
      "Loss: 0.6066\n",
      "Loss: 0.0144\n",
      "Loss: 0.1293\n",
      "Loss: 0.1996\n",
      "Loss: 0.1957\n",
      "Loss: 0.4192\n",
      "Loss: 1.0917\n",
      "Loss: 0.2559\n",
      "Loss: 0.5177\n",
      "Loss: 0.0960\n",
      "Loss: 0.3384\n",
      "Loss: 0.7930\n",
      "Loss: 0.5565\n",
      "Loss: 0.7152\n",
      "Loss: 0.8276\n",
      "Loss: 1.3556\n",
      "Loss: 0.5630\n",
      "Loss: 0.9969\n",
      "Loss: 1.1763\n",
      "Loss: 0.0993\n",
      "Loss: 0.0273\n",
      "Loss: 1.0659\n",
      "Loss: 0.4710\n",
      "Loss: 0.8449\n",
      "Loss: 0.2677\n",
      "Loss: 0.4357\n",
      "Loss: 0.4348\n",
      "Loss: 0.1810\n",
      "Loss: 0.3625\n",
      "Loss: 0.1608\n",
      "Loss: 0.2406\n",
      "Loss: 0.0596\n",
      "Loss: 0.5015\n",
      "Loss: 0.0130\n",
      "Loss: 0.0833\n",
      "Loss: 0.1481\n",
      "Loss: 0.1827\n",
      "Loss: 0.2270\n",
      "Loss: 1.0090\n",
      "Loss: 0.1936\n",
      "Loss: 0.4551\n",
      "Loss: 0.1329\n",
      "Loss: 0.1577\n",
      "Loss: 1.6839\n",
      "Loss: 1.2052\n",
      "Loss: 0.2875\n",
      "Loss: 0.5349\n",
      "Loss: 0.7914\n",
      "Loss: 0.2594\n",
      "Loss: 1.8086\n",
      "Loss: 2.3235\n",
      "Loss: 0.2493\n",
      "Loss: 0.0101\n",
      "Loss: 0.5538\n",
      "Loss: 1.7398\n",
      "Loss: 0.1816\n",
      "Loss: 0.1624\n",
      "Loss: 1.2429\n",
      "Loss: 0.3958\n",
      "Loss: 0.8945\n",
      "Loss: 1.0600\n",
      "Loss: 0.1710\n",
      "Loss: 0.2861\n",
      "Loss: 0.1411\n",
      "Loss: 0.8103\n",
      "Loss: 0.0156\n",
      "Loss: 0.2233\n",
      "Loss: 0.2081\n",
      "Loss: 0.3794\n",
      "Loss: 0.2241\n",
      "Loss: 1.5298\n",
      "Loss: 0.4053\n",
      "Loss: 0.3884\n",
      "Loss: 0.0979\n",
      "Loss: 0.5715\n",
      "Loss: 0.7341\n",
      "Loss: 0.3865\n",
      "Loss: 0.9521\n",
      "Loss: 1.3143\n",
      "Loss: 1.4209\n",
      "Loss: 0.6437\n",
      "Loss: 1.1014\n",
      "Loss: 1.2935\n",
      "Loss: 0.1540\n",
      "Loss: 0.0316\n",
      "Loss: 0.9180\n",
      "Loss: 0.5603\n",
      "Loss: 0.7018\n",
      "Loss: 0.2439\n",
      "Loss: 0.3526\n",
      "Loss: 0.4054\n",
      "Loss: 0.3519\n",
      "Loss: 0.5953\n",
      "Loss: 0.1950\n",
      "Loss: 0.2412\n",
      "Loss: 0.1276\n",
      "Loss: 0.7457\n",
      "Loss: 0.0119\n",
      "Loss: 0.2440\n",
      "Loss: 0.1393\n",
      "Loss: 0.2877\n",
      "Loss: 0.3334\n",
      "Loss: 1.0452\n",
      "Loss: 0.2199\n",
      "Loss: 0.4562\n",
      "Loss: 0.0787\n",
      "Loss: 0.3315\n",
      "Loss: 0.6132\n",
      "Loss: 0.4049\n",
      "Loss: 0.7754\n",
      "Loss: 1.0240\n",
      "Loss: 1.1692\n",
      "Loss: 0.6061\n",
      "Loss: 1.1747\n",
      "Loss: 1.5384\n",
      "Loss: 0.1775\n",
      "Loss: 0.0274\n",
      "Loss: 1.0384\n",
      "Loss: 0.5384\n",
      "Loss: 0.7937\n",
      "Loss: 0.3103\n",
      "Loss: 0.3380\n",
      "Loss: 0.3571\n",
      "Loss: 0.3208\n",
      "Loss: 0.4856\n",
      "Loss: 0.1917\n",
      "Loss: 0.2488\n",
      "Loss: 0.1050\n",
      "Loss: 0.7495\n",
      "Loss: 0.0078\n",
      "Loss: 0.1675\n",
      "Loss: 0.0746\n",
      "Loss: 0.2284\n",
      "Loss: 0.5702\n",
      "Loss: 1.1868\n",
      "Loss: 0.2399\n",
      "Loss: 0.5541\n",
      "Loss: 0.0524\n",
      "Loss: 0.3382\n",
      "Loss: 0.6982\n",
      "Loss: 0.7363\n",
      "Loss: 0.9467\n",
      "Loss: 0.8440\n",
      "Loss: 0.9211\n",
      "Loss: 0.5647\n",
      "Loss: 1.1644\n",
      "Loss: 1.3131\n",
      "Loss: 0.1752\n",
      "Loss: 0.0250\n",
      "Loss: 1.1799\n",
      "Loss: 0.4470\n",
      "Loss: 0.8764\n",
      "Loss: 0.2552\n",
      "Loss: 0.2795\n",
      "Loss: 0.3718\n",
      "Loss: 0.2683\n",
      "Loss: 0.4541\n",
      "Loss: 0.1618\n",
      "Loss: 0.2170\n",
      "Loss: 0.0846\n",
      "Loss: 0.7303\n",
      "Loss: 0.0087\n",
      "Loss: 0.1225\n",
      "Loss: 0.0598\n",
      "Loss: 0.2065\n",
      "Loss: 0.4723\n",
      "Loss: 1.0602\n",
      "Loss: 0.1940\n",
      "Loss: 0.5729\n",
      "Loss: 0.0414\n",
      "Loss: 0.2489\n",
      "Loss: 0.6513\n",
      "Loss: 0.5928\n",
      "Loss: 0.8745\n",
      "Loss: 0.6991\n",
      "Loss: 0.9048\n",
      "Loss: 0.5984\n",
      "Loss: 1.1404\n",
      "Loss: 1.2636\n",
      "Loss: 0.1353\n",
      "Loss: 0.0179\n",
      "Loss: 1.1104\n",
      "Loss: 0.5023\n",
      "Loss: 0.8392\n",
      "Loss: 0.2664\n",
      "Loss: 0.2553\n",
      "Loss: 0.2991\n",
      "Loss: 0.2505\n",
      "Loss: 0.4061\n",
      "Loss: 0.1635\n",
      "Loss: 0.1721\n",
      "Loss: 0.0900\n",
      "Loss: 0.7627\n",
      "Loss: 0.0058\n",
      "Loss: 0.0826\n",
      "Loss: 0.0441\n",
      "Loss: 0.2044\n",
      "Loss: 0.5703\n",
      "Loss: 0.9082\n",
      "Loss: 0.1837\n",
      "Loss: 0.6753\n",
      "Loss: 0.0311\n",
      "Loss: 0.1610\n",
      "Loss: 0.6819\n",
      "Loss: 0.5899\n",
      "Loss: 0.7856\n",
      "Loss: 0.6232\n",
      "Loss: 0.7805\n",
      "Loss: 0.5317\n",
      "Loss: 1.1509\n",
      "Loss: 1.2264\n",
      "Loss: 0.1041\n",
      "Loss: 0.0120\n",
      "Loss: 1.0309\n",
      "Loss: 0.6458\n",
      "Loss: 0.8834\n",
      "Loss: 0.2489\n",
      "Loss: 0.1895\n",
      "Loss: 0.2989\n",
      "Loss: 0.1706\n",
      "Loss: 0.3192\n",
      "Loss: 0.1255\n",
      "Loss: 0.2393\n",
      "Loss: 0.0770\n",
      "Loss: 0.9021\n",
      "Loss: 0.0038\n",
      "Loss: 0.0456\n",
      "Loss: 0.0205\n",
      "Loss: 0.1488\n",
      "Loss: 0.5342\n",
      "Loss: 0.9890\n",
      "Loss: 0.1553\n",
      "Loss: 0.7371\n",
      "Loss: 0.0235\n",
      "Loss: 0.1439\n",
      "Loss: 0.6334\n",
      "Loss: 0.6089\n",
      "Loss: 0.8515\n",
      "Loss: 0.6471\n",
      "Loss: 0.9828\n",
      "Loss: 0.5315\n",
      "Loss: 1.1760\n",
      "Loss: 1.4027\n",
      "Loss: 0.0887\n",
      "Loss: 0.0101\n",
      "Loss: 1.2535\n",
      "Loss: 0.4434\n",
      "Loss: 0.8820\n",
      "Loss: 0.2743\n",
      "Loss: 0.2769\n",
      "Loss: 0.3420\n",
      "Loss: 0.1828\n",
      "Loss: 0.3902\n",
      "Loss: 0.1027\n",
      "Loss: 0.2832\n",
      "Loss: 0.0780\n",
      "Loss: 1.0249\n",
      "Loss: 0.0041\n",
      "Loss: 0.0970\n",
      "Loss: 0.0248\n",
      "Loss: 0.1392\n",
      "Loss: 0.4977\n",
      "Loss: 0.9777\n",
      "Loss: 0.2220\n",
      "Loss: 0.6232\n",
      "Loss: 0.0247\n",
      "Loss: 0.3264\n",
      "Loss: 0.6130\n",
      "Loss: 0.7100\n",
      "Loss: 1.1001\n",
      "Loss: 0.6049\n",
      "Loss: 0.3570\n",
      "Loss: 0.5592\n",
      "Loss: 1.0344\n",
      "Loss: 1.1623\n",
      "Loss: 0.0506\n",
      "Loss: 0.0063\n",
      "Loss: 1.0720\n",
      "Loss: 0.5215\n",
      "Loss: 0.8513\n",
      "Loss: 0.2838\n",
      "Loss: 0.2953\n",
      "Loss: 0.3328\n",
      "Loss: 0.1898\n",
      "Loss: 0.3964\n",
      "Loss: 0.0944\n",
      "Loss: 0.1990\n",
      "Loss: 0.2942\n",
      "Loss: 1.0389\n",
      "Loss: 0.0031\n",
      "Loss: 0.1371\n",
      "Loss: 0.0200\n",
      "Loss: 0.0572\n",
      "Loss: 0.7085\n",
      "Loss: 0.9279\n",
      "Loss: 0.1851\n",
      "Loss: 0.8615\n",
      "Loss: 0.0335\n",
      "Loss: 0.1939\n",
      "Loss: 0.5236\n",
      "Loss: 0.7119\n",
      "Loss: 0.9519\n",
      "Loss: 0.3300\n",
      "Loss: 0.5696\n",
      "Loss: 0.5729\n",
      "Loss: 1.0722\n",
      "Loss: 1.2177\n",
      "Loss: 0.0403\n",
      "Loss: 0.0070\n",
      "Loss: 1.1217\n",
      "Loss: 0.4854\n",
      "Loss: 0.7679\n",
      "Loss: 0.2795\n",
      "Loss: 0.3102\n",
      "Loss: 0.3366\n",
      "Loss: 0.1554\n",
      "Loss: 0.3336\n",
      "Loss: 0.0324\n",
      "Loss: 0.2553\n",
      "Loss: 0.0459\n",
      "Loss: 0.7307\n",
      "Loss: 0.0036\n",
      "Loss: 0.0663\n",
      "Loss: 0.0147\n",
      "Loss: 0.0441\n",
      "Loss: 0.4924\n",
      "Loss: 1.1869\n",
      "Loss: 0.2456\n",
      "Loss: 0.5640\n",
      "Loss: 0.0233\n",
      "Loss: 0.2073\n",
      "Loss: 0.7155\n",
      "Loss: 0.3325\n",
      "Loss: 0.5318\n",
      "Loss: 0.1979\n",
      "Loss: 0.1823\n",
      "Loss: 0.5592\n",
      "Loss: 0.7348\n",
      "Loss: 0.8916\n",
      "Loss: 0.0121\n",
      "Loss: 0.0031\n",
      "Loss: 0.5722\n",
      "Loss: 0.7891\n",
      "Loss: 0.5568\n",
      "Loss: 0.2747\n",
      "Loss: 0.4407\n",
      "Loss: 0.5755\n",
      "Loss: 0.1133\n",
      "Loss: 0.2795\n",
      "Loss: 0.0094\n",
      "Loss: 0.3197\n",
      "Loss: 0.0124\n",
      "Loss: 0.5434\n",
      "Loss: 0.0024\n",
      "Loss: 0.4500\n",
      "Loss: 0.0116\n",
      "Loss: 2.0687\n",
      "Loss: 0.0684\n",
      "Loss: 3.1920\n",
      "Loss: 2.8465\n",
      "Loss: 0.1200\n",
      "Loss: 1.0244\n",
      "Loss: 0.7303\n",
      "Loss: 1.2084\n",
      "Loss: 0.3952\n",
      "Loss: 0.7197\n",
      "Loss: 0.5765\n",
      "Loss: 0.5898\n",
      "Loss: 0.7511\n",
      "Loss: 0.7412\n",
      "Loss: 0.7683\n",
      "Loss: 0.1612\n",
      "Loss: 0.0363\n",
      "Loss: 0.6232\n",
      "Loss: 0.8654\n",
      "Loss: 0.5219\n",
      "Loss: 0.7646\n",
      "Loss: 0.7613\n",
      "Loss: 0.7195\n",
      "Loss: 0.5676\n",
      "Loss: 0.5212\n",
      "Loss: 0.2406\n",
      "Loss: 0.2732\n",
      "Loss: 0.4102\n",
      "Loss: 1.1861\n",
      "Loss: 0.0107\n",
      "Loss: 0.1799\n",
      "Loss: 0.3181\n",
      "Loss: 0.5860\n",
      "Loss: 0.2594\n",
      "Loss: 1.6864\n",
      "Loss: 0.6229\n",
      "Loss: 0.4298\n",
      "Loss: 0.1035\n",
      "Loss: 0.4150\n",
      "Loss: 0.6521\n",
      "Loss: 0.7128\n",
      "Loss: 1.0417\n",
      "Loss: 0.7341\n",
      "Loss: 0.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8774\n",
      "Loss: 0.6797\n",
      "Loss: 0.7757\n",
      "Loss: 0.0907\n",
      "Loss: 0.0197\n",
      "Loss: 0.7841\n",
      "Loss: 0.6260\n",
      "Loss: 0.7304\n",
      "Loss: 0.5177\n",
      "Loss: 0.5166\n",
      "Loss: 0.5109\n",
      "Loss: 0.3480\n",
      "Loss: 0.3466\n",
      "Loss: 0.1145\n",
      "Loss: 0.2601\n",
      "Loss: 0.1625\n",
      "Loss: 0.9803\n",
      "Loss: 0.0053\n",
      "Loss: 0.1292\n",
      "Loss: 0.0944\n",
      "Loss: 0.4088\n",
      "Loss: 0.2767\n",
      "Loss: 1.6807\n",
      "Loss: 0.5703\n",
      "Loss: 0.4189\n",
      "Loss: 0.0624\n",
      "Loss: 0.3152\n",
      "Loss: 0.7199\n",
      "Loss: 0.5852\n",
      "Loss: 0.8934\n",
      "Loss: 0.7189\n",
      "Loss: 0.7371\n",
      "Loss: 0.6829\n",
      "Loss: 0.8798\n",
      "Loss: 0.9733\n",
      "Loss: 0.0760\n",
      "Loss: 0.0080\n",
      "Loss: 0.9080\n",
      "Loss: 0.6208\n",
      "Loss: 0.8059\n",
      "Loss: 0.4442\n",
      "Loss: 0.4167\n",
      "Loss: 0.4882\n",
      "Loss: 0.3814\n",
      "Loss: 0.5507\n",
      "Loss: 0.0900\n",
      "Loss: 0.2691\n",
      "Loss: 0.0861\n",
      "Loss: 0.8378\n",
      "Loss: 0.0043\n",
      "Loss: 0.1057\n",
      "Loss: 0.0543\n",
      "Loss: 0.2500\n",
      "Loss: 0.2714\n",
      "Loss: 1.7572\n",
      "Loss: 0.4595\n",
      "Loss: 0.3800\n",
      "Loss: 0.0578\n",
      "Loss: 1.4145\n",
      "Loss: 0.8027\n",
      "Loss: 0.5487\n",
      "Loss: 1.2464\n",
      "Loss: 0.8436\n",
      "Loss: 0.8548\n",
      "Loss: 0.7731\n",
      "Loss: 0.7764\n",
      "Loss: 0.8383\n",
      "Loss: 0.0639\n",
      "Loss: 0.0107\n",
      "Loss: 0.8076\n",
      "Loss: 0.6063\n",
      "Loss: 0.7513\n",
      "Loss: 0.4701\n",
      "Loss: 0.4166\n",
      "Loss: 0.4984\n",
      "Loss: 0.2544\n",
      "Loss: 0.6094\n",
      "Loss: 0.0332\n",
      "Loss: 0.2741\n",
      "Loss: 0.0825\n",
      "Loss: 0.5152\n",
      "Loss: 0.0054\n",
      "Loss: 0.0674\n",
      "Loss: 0.0320\n",
      "Loss: 0.2069\n",
      "Loss: 0.2407\n",
      "Loss: 1.8935\n",
      "Loss: 0.1892\n",
      "Loss: 0.2857\n",
      "Loss: 0.0662\n",
      "Loss: 0.6068\n",
      "Loss: 0.3193\n",
      "Loss: 0.8491\n",
      "Loss: 1.8966\n",
      "Loss: 0.2170\n",
      "Loss: 0.2844\n",
      "Loss: 0.7936\n",
      "Loss: 1.3418\n",
      "Loss: 0.2604\n",
      "Loss: 0.0215\n",
      "Loss: 0.0105\n",
      "Loss: 0.3119\n",
      "Loss: 0.9493\n",
      "Loss: 1.8255\n",
      "Loss: 1.9252\n",
      "Loss: 0.0632\n",
      "Loss: 0.7687\n",
      "Loss: 0.4242\n",
      "Loss: 0.4145\n",
      "Loss: 0.1169\n",
      "Loss: 0.1385\n",
      "Loss: 0.3277\n",
      "Loss: 1.3732\n",
      "Loss: 0.0094\n",
      "Loss: 0.1773\n",
      "Loss: 0.0689\n",
      "Loss: 0.3455\n",
      "Loss: 0.1983\n",
      "Loss: 1.6424\n",
      "Loss: 0.3894\n",
      "Loss: 0.3671\n",
      "Loss: 0.1165\n",
      "Loss: 0.5306\n",
      "Loss: 0.6737\n",
      "Loss: 0.9642\n",
      "Loss: 1.1096\n",
      "Loss: 1.3406\n",
      "Loss: 0.8751\n",
      "Loss: 0.6375\n",
      "Loss: 1.0501\n",
      "Loss: 1.2339\n",
      "Loss: 0.1944\n",
      "Loss: 0.0274\n",
      "Loss: 1.2042\n",
      "Loss: 0.4395\n",
      "Loss: 0.9849\n",
      "Loss: 0.3670\n",
      "Loss: 0.6697\n",
      "Loss: 0.4296\n",
      "Loss: 0.5607\n",
      "Loss: 0.5091\n",
      "Loss: 0.0646\n",
      "Loss: 0.2308\n",
      "Loss: 1.1580\n",
      "Loss: 0.8013\n",
      "Loss: 0.0144\n",
      "Loss: 0.3277\n",
      "Loss: 0.0636\n",
      "Loss: 0.2270\n",
      "Loss: 0.3408\n",
      "Loss: 1.1778\n",
      "Loss: 0.2985\n",
      "Loss: 0.4398\n",
      "Loss: 0.1173\n",
      "Loss: 0.6251\n",
      "Loss: 0.7658\n",
      "Loss: 0.7400\n",
      "Loss: 0.8252\n",
      "Loss: 1.2898\n",
      "Loss: 2.1545\n",
      "Loss: 0.5899\n",
      "Loss: 1.0287\n",
      "Loss: 1.1706\n",
      "Loss: 0.1846\n",
      "Loss: 0.0251\n",
      "Loss: 1.1636\n",
      "Loss: 0.4355\n",
      "Loss: 1.0008\n",
      "Loss: 0.3343\n",
      "Loss: 0.6247\n",
      "Loss: 0.3945\n",
      "Loss: 0.5246\n",
      "Loss: 0.4898\n",
      "Loss: 0.0623\n",
      "Loss: 0.2288\n",
      "Loss: 0.2580\n",
      "Loss: 0.8361\n",
      "Loss: 0.0136\n",
      "Loss: 0.2514\n",
      "Loss: 0.0733\n",
      "Loss: 0.2399\n",
      "Loss: 0.2647\n",
      "Loss: 1.4014\n",
      "Loss: 0.4204\n",
      "Loss: 0.3322\n",
      "Loss: 0.1510\n",
      "Loss: 0.7978\n",
      "Loss: 0.9226\n",
      "Loss: 0.6132\n",
      "Loss: 0.7150\n",
      "Loss: 1.1833\n",
      "Loss: 1.9953\n",
      "Loss: 0.4152\n",
      "Loss: 1.2444\n",
      "Loss: 1.3166\n",
      "Loss: 0.1440\n",
      "Loss: 0.0158\n",
      "Loss: 1.1659\n",
      "Loss: 0.4486\n",
      "Loss: 0.9475\n",
      "Loss: 0.5157\n",
      "Loss: 0.6702\n",
      "Loss: 0.6075\n",
      "Loss: 0.5448\n",
      "Loss: 0.5239\n",
      "Loss: 0.0555\n",
      "Loss: 0.3589\n",
      "Loss: 0.2806\n",
      "Loss: 0.8021\n",
      "Loss: 0.0118\n",
      "Loss: 0.1987\n",
      "Loss: 0.0645\n",
      "Loss: 0.2770\n",
      "Loss: 0.2579\n",
      "Loss: 1.4231\n",
      "Loss: 0.4770\n",
      "Loss: 0.3108\n",
      "Loss: 0.1738\n",
      "Loss: 0.8481\n",
      "Loss: 0.9896\n",
      "Loss: 0.5540\n",
      "Loss: 0.6427\n",
      "Loss: 1.0680\n",
      "Loss: 1.6751\n",
      "Loss: 0.5899\n",
      "Loss: 0.9322\n",
      "Loss: 1.0252\n",
      "Loss: 0.1480\n",
      "Loss: 0.0217\n",
      "Loss: 0.8409\n",
      "Loss: 0.5241\n",
      "Loss: 0.7779\n",
      "Loss: 0.5919\n",
      "Loss: 0.4288\n",
      "Loss: 0.7008\n",
      "Loss: 0.3535\n",
      "Loss: 0.3373\n",
      "Loss: 0.0902\n",
      "Loss: 0.4335\n",
      "Loss: 0.2218\n",
      "Loss: 1.1187\n",
      "Loss: 0.0125\n",
      "Loss: 0.1930\n",
      "Loss: 0.0440\n",
      "Loss: 0.2313\n",
      "Loss: 0.3468\n",
      "Loss: 1.6011\n",
      "Loss: 0.4268\n",
      "Loss: 0.2256\n",
      "Loss: 0.1139\n",
      "Loss: 1.1256\n",
      "Loss: 1.1969\n",
      "Loss: 0.6580\n",
      "Loss: 0.5087\n",
      "Loss: 0.8962\n",
      "Loss: 0.8284\n",
      "Loss: 0.5126\n",
      "Loss: 0.9898\n",
      "Loss: 1.0146\n",
      "Loss: 0.0622\n",
      "Loss: 0.0106\n",
      "Loss: 0.8882\n",
      "Loss: 0.6031\n",
      "Loss: 0.7413\n",
      "Loss: 1.0524\n",
      "Loss: 0.7987\n",
      "Loss: 0.9930\n",
      "Loss: 0.5931\n",
      "Loss: 0.5110\n",
      "Loss: 0.0426\n",
      "Loss: 0.4239\n",
      "Loss: 0.6193\n",
      "Loss: 0.9779\n",
      "Loss: 0.0119\n",
      "Loss: 0.2172\n",
      "Loss: 0.0296\n",
      "Loss: 0.8840\n",
      "Loss: 0.2884\n",
      "Loss: 1.5679\n",
      "Loss: 0.9466\n",
      "Loss: 0.2899\n",
      "Loss: 0.0617\n",
      "Loss: 0.8031\n",
      "Loss: 0.9204\n",
      "Loss: 0.7641\n",
      "Loss: 0.8799\n",
      "Loss: 1.1702\n",
      "Loss: 1.1385\n",
      "Loss: 0.6107\n",
      "Loss: 0.8853\n",
      "Loss: 0.9176\n",
      "Loss: 0.2795\n",
      "Loss: 0.0095\n",
      "Loss: 0.8249\n",
      "Loss: 0.7428\n",
      "Loss: 0.5942\n",
      "Loss: 0.7406\n",
      "Loss: 0.7320\n",
      "Loss: 0.7817\n",
      "Loss: 0.5579\n",
      "Loss: 0.4768\n",
      "Loss: 0.2681\n",
      "Loss: 0.3863\n",
      "Loss: 0.4677\n",
      "Loss: 0.8519\n",
      "Loss: 0.0139\n",
      "Loss: 0.1089\n",
      "Loss: 0.1779\n",
      "Loss: 0.6901\n",
      "Loss: 0.3604\n",
      "Loss: 1.1046\n",
      "Loss: 0.7348\n",
      "Loss: 0.3508\n",
      "Loss: 0.1997\n",
      "Loss: 0.6542\n",
      "Loss: 0.6697\n",
      "Loss: 0.8293\n",
      "Loss: 0.8467\n",
      "Loss: 1.3640\n",
      "Loss: 1.2992\n",
      "Loss: 0.5306\n",
      "Loss: 1.1274\n",
      "Loss: 0.9670\n",
      "Loss: 0.1855\n",
      "Loss: 0.0095\n",
      "Loss: 0.9182\n",
      "Loss: 0.6353\n",
      "Loss: 0.8063\n",
      "Loss: 0.5412\n",
      "Loss: 0.7007\n",
      "Loss: 0.6115\n",
      "Loss: 0.5293\n",
      "Loss: 0.5543\n",
      "Loss: 0.2542\n",
      "Loss: 0.3212\n",
      "Loss: 0.3805\n",
      "Loss: 0.8425\n",
      "Loss: 0.0104\n",
      "Loss: 0.1073\n",
      "Loss: 0.1309\n",
      "Loss: 0.5414\n",
      "Loss: 0.3267\n",
      "Loss: 1.1760\n",
      "Loss: 0.6522\n",
      "Loss: 0.3407\n",
      "Accuracy of the network on the 6 test images: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "left_column = [\n",
    "#'Time',\n",
    "    'Distance','GPS Latitude','GPS Longitude','Damper Velocity (Calc) FL','Damper Velocity (Calc) FR','Damper Velocity (Calc) RL',\n",
    "'Damper Velocity (Calc) RR','Corr Dist','Corr Dist (Unstretched)','Corr Speed','Brake Pos',\n",
    "'CG Accel Lateral','CG Accel Longitudinal','CG Accel Vertical','CG Height','Camber FL','Camber FR','Camber RL','Camber RR','Car Coord X',\n",
    "'Car Coord Y','Car Coord Z','Car Pos Norm','Chassis Pitch Angle','Chassis Pitch Rate','Chassis Roll Angle','Chassis Roll Rate',\n",
    "'Chassis Velocity X','Chassis Velocity Y','Chassis Velocity Z','Chassis Yaw Rate','Drive Train Speed','Engine RPM','Ground Speed',\n",
    "'Ride Height FL','Ride Height FR','Ride Height RL','Ride Height RR','Road Temp','Self Align Torque FL','Self Align Torque FR',\n",
    "'Self Align Torque RL','Self Align Torque RR','Session Time Left','Steering Angle','Suspension Travel FL','Suspension Travel FR',\n",
    "'Suspension Travel RL','Suspension Travel RR','Tire Load FL','Tire Load FR','Tire Load RL','Tire Load RR','Tire Loaded Radius FL',\n",
    "'Tire Loaded Radius FR','Tire Loaded Radius RL','Tire Loaded Radius RR','Tire Pressure FL','Tire Pressure FR','Tire Pressure RL','Tire Pressure RR',\n",
    "'Tire Rubber Grip FL','Tire Rubber Grip FR','Tire Rubber Grip RL','Tire Rubber Grip RR','Tire Slip Angle FL','Tire Slip Angle FR',\n",
    "'Tire Slip Angle RL','Tire Slip Angle RR','Tire Slip Ratio FL','Tire Slip Ratio FR','Tire Slip Ratio RL','Tire Slip Ratio RR',\n",
    "'Tire Temp Core FL','Tire Temp Core FR','Tire Temp Core RL','Tire Temp Core RR','Tire Temp Inner FL','Tire Temp Inner FR',\n",
    "'Tire Temp Inner RL','Tire Temp Inner RR','Tire Temp Middle FL','Tire Temp Middle FR','Tire Temp Middle RL',\n",
    "'Tire Temp Middle RR','Tire Temp Outer FL','Tire Temp Outer FR','Tire Temp Outer RL','Tire Temp Outer RR','Toe In FL',\n",
    "'Toe In FR','Toe In RL','Toe In RR','Wheel Angular Speed FL','Wheel Angular Speed FR','Wheel Angular Speed RL','Wheel Angular Speed RR',\n",
    "'CG Distance','Lateral Velocity','Longitudinal Velocity','Lateral Acceleration','Longitudinal Acceleration','level']\n",
    "\n",
    "\n",
    "#Hyper-parameters\n",
    "num_epochs = 50\n",
    "batches = 1\n",
    "learning_rate = 0.001\n",
    "input_size = len(left_column)-1 # left column except 'level'\n",
    "output_size = 2 # Expert and Beginner\n",
    "hidden_size = 128 # ?\n",
    "num_layers = 2 \n",
    "num_begin_train = 16*(number_of_corner-start)\n",
    "num_exp_train = 16*(number_of_corner-start)\n",
    "num_begin_test = num_begin*(number_of_corner-start) - num_begin_train\n",
    "num_exp_test = num_exp*(number_of_corner-start) - num_exp_train\n",
    "\n",
    "## Define GRU, Loss func and Optimizer\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layer, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "gru = GRU(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)  \n",
    "\n",
    "\n",
    "## Data Processing\n",
    "array_x = []\n",
    "array_y = []\n",
    "input_x = []\n",
    "input_y = []\n",
    "n_row = []\n",
    "\n",
    "df_tmp_begin = pd.DataFrame() \n",
    "df_tmp_exp = pd.DataFrame() \n",
    "for curve_num in range(start,number_of_corner):\n",
    "    df_tmp_begin = pd.concat([df_tmp_begin,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_begin.csv')])\n",
    "    df_tmp_exp   = pd.concat([df_tmp_exp,pd.read_csv('cornerData/corner_'+str(curve_num+1)+'_expert.csv')])    \n",
    "df_curve1 = pd.concat([df_tmp_begin, df_tmp_exp], ignore_index=True) \n",
    "df_curve1 = df_curve1.loc[:,left_column]\n",
    "df_curve1_saved = df_curve1.loc[:,left_column] # data backup\n",
    "df_curve1.to_csv('cornerData/corner_'+'_dfcurve1'+'.csv')\n",
    "\n",
    "\n",
    "for i in range(0,num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "    x = df_curve1_saved.loc[0:num_row[i]-1]\n",
    "    df_curve1_saved.drop(range(0,num_row[i]),inplace=True)\n",
    "    df_curve1_saved.reset_index(drop=True, inplace=True)\n",
    "    y = x.pop('level')\n",
    "    array_x.append(x)\n",
    "    array_y.append(y)\n",
    "\n",
    "    \n",
    "## Randomize sequence \n",
    "sequence = np.arange(num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start))\n",
    "np.random.shuffle(sequence)\n",
    "print(sequence)\n",
    "\n",
    "for i in sequence:\n",
    "    input_x.append(array_x[i])\n",
    "    input_y.append(array_y[i])\n",
    "    n_row.append(num_row[i])\n",
    "\n",
    "\n",
    "\n",
    "## Train \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0,num_begin_train + num_exp_train):\n",
    "\n",
    "        # array type (numpy)\n",
    "        X = np.array(input_x[i])\n",
    "        X = X.reshape(-1,n_row[i],input_size)\n",
    "        Y = np.array(input_y[i])   \n",
    "        \n",
    "        # tensor type (pytorch)\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        Y = torch.tensor([Y[0]])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = gru(X)\n",
    "        loss = criterion(output, Y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        loss_list.append(loss.data)\n",
    "        iteration_list.append(count)\n",
    "#         accuracy_list.append(accuracy)\n",
    "        print (f'Loss: {loss.item():.4f}')\n",
    "\n",
    "## Test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for i in range(num_begin_train + num_exp_train, num_begin*(number_of_corner-start) + num_exp*(number_of_corner-start)):\n",
    "        \n",
    "        # array type (numpy)\n",
    "        X = np.array(input_x[i])\n",
    "        X = X.reshape(-1,n_row[i],input_size)\n",
    "        Y = np.array(input_y[i])   \n",
    "\n",
    "        # tensor type (pytorch)\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.float()\n",
    "        Y = torch.tensor([Y[0]])\n",
    "\n",
    "        output = gru(X)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        n_samples += Y.size(0)\n",
    "        n_correct += (predicted == Y).sum().item()\n",
    "        \n",
    "\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {num_begin_test + num_exp_test} test images: {acc} %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "# print(iteration_list)\n",
    "# # visualization accuracy \n",
    "# plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "# plt.xlabel(\"Number of iteration\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "# plt.savefig('graph.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "food = 'bread'\n",
    "vars()['cat'] = 123\n",
    "print(cat)\n",
    "print(type(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame() \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
